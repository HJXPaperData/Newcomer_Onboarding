[{
	"login": "alphaX86",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "853123364",
	"issue_number": "48394",
	"issue_state": "opened",
	"issue_title": "Redirect tensorflow/tensorflow/examples to examples repo in examples/README",
	"issue_body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n",
	"issue_comments": "0"
},
{
	"login": "DmitryUlyanov",
	"repo_name": "BVLC/caffe",
	"issue_id": "55730046",
	"issue_number": "1807",
	"issue_state": "opened",
	"issue_title": "Random freezes",
	"issue_body": "They are just exactly as described in https://github.com/BVLC/caffe/issues/1412 thread. The point where it freezes is completely random. It seems like caffe looses gpu somehow (or blocks gpu?) because gpu does not answer after caffe is frozen and before it is killed. \r\n\r\nParticularly  this happens when I try use kernel_size = 1 in convolution layers. So this issue is config dependent. ",
	"issue_comments": "0"
},
{
	"login": "keskarnitish",
	"repo_name": "Theano/Theano",
	"issue_id": "98555287",
	"issue_number": "3234",
	"issue_state": "opened",
	"issue_title": "theano.function is changing random seed",
	"issue_body": "I don't know if this issue was already reported (or if this is a design choice); a perfunctory search did not yield any hits. Here's what I noticed: calling theano.function seems to change the value of the seed for the `random` module. \r\n\r\nHere is a minimal working example:\r\n```\r\nimport theano.tensor as T\r\nimport theano\r\nimport random\r\n\r\n# Initialize random seed and print first number\r\nrandom.seed(0)\r\nfirstVal = random.random()\r\nprint firstVal\r\n# Reset seed\r\nrandom.seed(0)\r\n\r\nx = T.dscalar()\r\ny = T.square(x)\r\nf = theano.function([x],y)\r\nprint f(2)\r\n\r\nsecondVal = random.random()\r\nprint secondVal\r\n```\r\n\r\nGives:\r\n```\r\n0.844421851525\r\n4.0\r\n0.403319204953\r\n```",
	"issue_comments": "0"
},
{
	"login": "NeilGirdhar",
	"repo_name": "Theano/Theano",
	"issue_id": "156489338",
	"issue_number": "4548",
	"issue_state": "opened",
	"issue_title": "ones_like and zeros_like dtype parameter is not documented",
	"issue_body": "",
	"issue_comments": "0"
},
{
	"login": "raingo",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "118964295",
	"issue_number": "358",
	"issue_state": "opened",
	"issue_title": "SWIG signature mismatch at RecordWriter",
	"issue_body": "I tried to run the example \"tensorflow/g3doc/how_tos/reading_data/convert_to_records.py\", but there is an error saying function signature mismatch on the `bool WriteRecord(::tensorflow::StringPiece record);` call.\r\n\r\nMy swig version is `SWIG Version 1.3.40`\r\n\r\nA simple fix is to change `bool WriteRecord(::tensorflow::StringPiece record);` to `bool WriteRecord(const string &record);` for these two files,\r\n ```\r\ntensorflow/tensorflow/python/lib/io/py_record_writer.h\r\ntensorflow/tensorflow/python/lib/io/py_record_writer.cc\r\n```",
	"issue_comments": "0"
},
{
	"login": "shlens",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "120128736",
	"issue_number": "400",
	"issue_state": "closed",
	"issue_title": "Tutorial: Visual Object Recognition",
	"issue_body": "When will the 'Visual Object Recognition' part of the tutorial be released?",
	"issue_comments": "1"
},
{
	"login": "todpole3",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "220365868",
	"issue_number": "9061",
	"issue_state": "opened",
	"issue_title": "Tensorflow Training Freezes for sometime, then continue on its own, happen multiple times when training a model",
	"issue_body": "I recently upgraded to Tensorflow 0.12.1, Python3, Ubuntu 14.04, Cuda 8.0, Cudnn 5.1\r\n\r\nThen I run my old code written for Tensorflow 0.10.1, which is a simple sequence-to-sequence model and the training keeps freeze in the middle.\r\n\r\nAfter some time the training will continue normally. Sometimes it 1 or 2 minutes, and sometimes it takes about 5 to 6 hours.",
	"issue_comments": "0"
},
{
	"login": "wenwei202",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "271361138",
	"issue_number": "14271",
	"issue_state": "opened",
	"issue_title": "tf.gradients return NaN when batch_norm is in inference mode (is_training=False)?",
	"issue_body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n- **Python version**: Python 2.7.11 |Anaconda custom (64-bit)\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:/usr/local/cuda-8.0 & libcudnn.so.6.0.21\r\n- **GPU model and memory**:GeForce GTX 1080\r\n- **Exact command to reproduce**:\r\n```\r\ngit clone https://github.com/wenwei202/models.git\r\ncd models\r\ngit checkout bug-fixing\r\ncd research/slim\r\npython eval_image_classifier_bn_grad.py -alsologtostderr --checkpoint_path /tmp/resnet_v1_152.ckpt  --dataset_dir /tmp/imagenet-data \\\r\n--dataset_name imagenet \\\r\n--dataset_split_name validation \\\r\n--model_name resnet_v1_152 \\\r\n--batch_size 5 --eval_dir /tmp/bn_grad \\\r\n--labels_offset=1  --max_num_batches 1\r\n```\r\n\r\n### Describe the problem, Source code / logs\r\nI need to compute the gradients of dy/dx, where y is the max logit and x is input image. I just add a few lines to the standard [research/slim/eval_image_classifier.py](https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py):\r\n```\r\n    max_logits = tf.reduce_max(logits, axis=1)\r\n    themaps = tf.gradients(max_logits, images)\r\n    themaps = themaps[0]\r\n    with tf.control_dependencies([tf.Print(themaps,[themaps],first_n=3)]):\r\n      themaps = tf.abs(themaps)\r\n```\r\nwhich is [here](https://github.com/wenwei202/models/blob/bug-fixing/research/slim/eval_image_classifier_bn_grad.py#L155-L159).\r\nWhen I run `eval_image_classifier_bn_grad.py` to evaluate models [here](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models), vgg and lenet work well, but `tf.gradients` always return `nan` when I evaluate inception and resnet models.\r\nCommand:\r\n```\r\npython eval_image_classifier_bn_grad.py -alsologtostderr --checkpoint_path /tmp/resnet_v1_152.ckpt  --dataset_dir /tmp/imagenet-data \\\r\n--dataset_name imagenet \\\r\n--dataset_split_name validation \\\r\n--model_name resnet_v1_152 \\\r\n--batch_size 5 --eval_dir /tmp/bn_grad \\\r\n--labels_offset=1  --max_num_batches 1\r\n```\r\nOutput:\r\n```\r\n...\r\n2017-11-05 23:25:19.751859: I tensorflow/core/kernels/logging_ops.cc:79] [[[[nan nan nan]]]...]\r\n...\r\n```\r\n\r\nI guess the issue comes from the`slim.batch_norm` when it is in inference mode, and somehow, `tf.gradients` does not work anymore. Why?\r\n  1. vgg and lenet without batch_norm layers work well \r\n  2. inception and resnet with batch_norm layers return `nan`\r\n  3. inception and resnet work after I enforce the `is_training=True` of `slim.batch_norm`\r\n  4. it seems \"reasonable\" to ignore the possibility of the usage of `tf.gradients` when `batch_norm` is in inference mode.\r\n",
	"issue_comments": "0"
},
{
	"login": "agemagician",
	"repo_name": "pytorch/fairseq",
	"issue_id": "682753745",
	"issue_number": "2503",
	"issue_state": "opened",
	"issue_title": "Covid-19 Large Scale Megatron Training",
	"issue_body": "## \ud83d\udc1b Bug\r\n\r\nWe are training different language models for protein sequences, which is part of the effort to fighting Covid-19.\r\nWe already have published several pertained models trained on Summit and TPU Pods, and we are interested on training Megatron:\r\nhttps://github.com/agemagician/ProtTrans\r\n\r\nWe are testing Megatron training on Colab TPUs, but it fails. However, Roberta works fine.\r\n\r\n### To Reproduce\r\n\r\nWorks fine:\r\n```\r\n!fairseq-preprocess \\\r\n    --only-source \\\r\n    --trainpref train_data_pro.txt \\\r\n    --validpref train_data_pro.txt \\\r\n    --testpref train_data_pro.txt \\\r\n    --destdir dataset/uniref50 \\\r\n    --dataset-impl lazy \\\r\n    --workers 2\r\n```\r\n\r\nRoberta Works fine:\r\n```\r\nTOTAL_UPDATES=125000    # Total number of training steps\r\nWARMUP_UPDATES=10000    # Warmup the learning rate over this many updates\r\nPEAK_LR=0.0005          # Peak learning rate, adjust as needed\r\nTOKENS_PER_SAMPLE=512   # Max sequence length\r\nMAX_POSITIONS=512       # Num. positional embeddings (usually same as above)\r\nMAX_SENTENCES=1         # Number of sequences per batch (batch size)\r\nUPDATE_FREQ=16          # Increase the batch size 16x\r\n\r\n\r\nDATA_DIR=\"dataset/uniref50\"\r\n\r\n!fairseq-train --tpu $DATA_DIR \\\r\n    --task masked_lm --criterion masked_lm \\\r\n    --arch roberta_base --sample-break-mode complete --tokens-per-sample $TOKENS_PER_SAMPLE \\\r\n    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\r\n    --lr-scheduler polynomial_decay --lr $PEAK_LR --warmup-updates $WARMUP_UPDATES --total-num-update $TOTAL_UPDATES \\\r\n    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\r\n    --max-sentences $MAX_SENTENCES --update-freq $UPDATE_FREQ \\\r\n    --max-update $TOTAL_UPDATES --log-format simple --log-interval 1 \\\r\n    --distributed-world-size=8\r\n```\r\n\r\n\r\nMegatron fails:\r\n```\r\nDATA_DIR=\"dataset/uniref50\"\r\n\r\n!fairseq-train --tpu $DATA_DIR \\\r\n  --distributed-world-size 8  \\\r\n  --num-workers 2 \\\r\n  --model-parallel-size 8 \\\r\n  --criterion vocab_parallel_cross_entropy \\\r\n  --task language_modeling \\\r\n  --sample-break-mode none \\\r\n  --tokens-per-sample 1024 \\\r\n  --arch transformer_lm_megatron_11b \\\r\n  --share-decoder-input-output-embed \\\r\n  --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-08 --clip-norm 0.0 \\\r\n  --lr-scheduler inverse_sqrt --lr 0.00015 \\\r\n  --warmup-updates 3000 --weight-decay 0.01 \\\r\n  --dropout 0.1 --attention-dropout 0.1 \\\r\n  --max-sentences 2 \\\r\n  --max-update 300000 \\\r\n  --dataset-impl lazy\r\n```\r\n\r\n\r\nRoberta working results:\r\n\r\n```\r\n2020-08-20 12:55:49 | WARNING | root | TPU has started up successfully with version pytorch-1.6\r\n2020-08-20 12:55:57 | WARNING | root | TPU has started up successfully with version pytorch-1.6\r\n2020-08-20 12:56:08 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9,0.98)', adam_eps=1e-06, all_gather_list_size=16384, arch='roberta_base', attention_dropout=0.1, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='masked_lm', curriculum=0, data='dataset/uniref50', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=8, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, freq_weighted_replacement=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, leave_unmasked_prob=0.1, localsgd_frequency=3, log_format='simple', log_interval=1, lr=[0.0005], lr_scheduler='polynomial_decay', mask_prob=0.15, mask_whole_words=False, max_epoch=0, max_sentences=1, max_sentences_valid=1, max_tokens=None, max_tokens_valid=None, max_update=125000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=True, nprocs_per_node=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, random_token_prob=0.1, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sample_break_mode='complete', save_dir='checkpoints', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_time_hours=0, task='masked_lm', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, total_num_update=125000, tpu=True, train_subset='train', update_freq=[16], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=10000, weight_decay=0.01)\r\n2020-08-20 12:56:08 | INFO | fairseq.tasks.masked_lm | dictionary: 24 types\r\n2020-08-20 12:56:08 | INFO | fairseq.data.data_utils | loaded 144 examples from: dataset/uniref50/valid\r\n2020-08-20 12:56:08 | INFO | fairseq.tasks.masked_lm | loaded 112 blocks from: dataset/uniref50/valid\r\n2020-08-20 12:56:35 | INFO | fairseq_cli.train | RobertaModel(\r\n  (encoder): RobertaEncoder(\r\n    (sentence_encoder): TransformerSentenceEncoder(\r\n      (dropout_module): FairseqDropout()\r\n      (embed_tokens): Embedding(25, 768, padding_idx=1)\r\n      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\r\n      (layers): ModuleList(\r\n        (0): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (1): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (2): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (3): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (4): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (5): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (6): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (7): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (8): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (9): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (10): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n        (11): TransformerSentenceEncoderLayer(\r\n          (dropout_module): FairseqDropout()\r\n          (activation_dropout_module): FairseqDropout()\r\n          (self_attn): MultiheadAttention(\r\n            (dropout_module): FairseqDropout()\r\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\r\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\r\n          )\r\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\r\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\r\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n        )\r\n      )\r\n      (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n    )\r\n    (lm_head): RobertaLMHead(\r\n      (dense): Linear(in_features=768, out_features=768, bias=True)\r\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n    )\r\n  )\r\n  (classification_heads): ModuleDict()\r\n)\r\n2020-08-20 12:56:35 | INFO | fairseq_cli.train | task: masked_lm (MaskedLMTask)\r\n2020-08-20 12:56:35 | INFO | fairseq_cli.train | model: roberta_base (RobertaModel)\r\n2020-08-20 12:56:35 | INFO | fairseq_cli.train | criterion: masked_lm (MaskedLmLoss)\r\n2020-08-20 12:56:35 | INFO | fairseq_cli.train | num. model params: 86062105 (num. trained: 86062105)\r\n2020-08-20 12:56:59 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\r\n2020-08-20 12:56:59 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)\r\n2020-08-20 12:56:59 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 1\r\n2020-08-20 12:56:59 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt\r\n2020-08-20 12:56:59 | INFO | fairseq.trainer | loading train data for epoch 1\r\n2020-08-20 12:56:59 | INFO | fairseq.data.data_utils | loaded 144 examples from: dataset/uniref50/train\r\n2020-08-20 12:56:59 | INFO | fairseq.tasks.masked_lm | loaded 112 blocks from: dataset/uniref50/train\r\n2020-08-20 12:56:59 | INFO | fairseq.trainer | begin training epoch 1\r\n2020-08-20 12:59:05 | INFO | root | NOTE: XLA compilation detected; too many of these can lead to slow training, but we expect a few in the beginning\r\n2020-08-20 12:59:05 | INFO | train_inner | epoch 001:      1 / 1 loss=4.776, ppl=27.39, wps=0, ups=0, wpb=39632, bsz=112, num_updates=1, lr=5e-08, gnorm=5.505, train_wall=118, wall=126\r\n2020-08-20 12:59:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\r\n2020-08-20 13:00:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.776 | ppl 27.4 | wps 537.5 | wpb 2830.9 | bsz 8 | num_updates 1\r\n2020-08-20 13:00:26 | INFO | fairseq_cli.train | begin save checkpoint\r\n2020-08-20 13:00:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 1 updates, score 4.776) (writing took 31.607709737999812 seconds)\r\n2020-08-20 13:00:57 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\r\n2020-08-20 13:00:57 | INFO | train | epoch 001 | loss 4.776 | ppl 27.39 | wps 0 | ups 0 | wpb 39632 | bsz 112 | num_updates 1 | lr 5e-08 | gnorm 5.505 | train_wall 118 | wall 238\r\n2020-08-20 13:00:57 | INFO | fairseq.trainer | begin training epoch 2\r\n2020-08-20 13:01:55 | INFO | root | NOTE: XLA compilation detected; too many of these can lead to slow training, but we expect a few in the beginning\r\n2020-08-20 13:01:55 | INFO | train_inner | epoch 002:      1 / 1 loss=4.765, ppl=27.2, wps=233.3, ups=0.01, wpb=39632, bsz=112, num_updates=2, lr=1e-07, gnorm=5.435, train_wall=51, wall=296\r\n2020-08-20 13:01:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\r\n2020-08-20 13:02:14 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.781 | ppl 27.49 | wps 3777.8 | wpb 2830.9 | bsz 8 | num_updates 2 | best_loss 4.776\r\n2020-08-20 13:02:14 | INFO | fairseq_cli.train | begin save checkpoint\r\n```\r\n\r\nMegatron errors:\r\n\r\n```\r\n2020-08-20 14:04:40 | WARNING | root | TPU has started up successfully with version pytorch-1.6\r\n2020-08-20 14:04:48 | WARNING | root | TPU has started up successfully with version pytorch-1.6\r\nException in device=TPU:2: Default process group is not initialized\r\nException in device=TPU:4: Default process group is not initialized\r\nException in device=TPU:7: Default process group is not initialized\r\nException in device=TPU:1: Default process group is not initialized\r\nException in device=TPU:5: Default process group is not initialized\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\nAssertionError: Default process group is not initialized\r\nException in device=TPU:3: Default process group is not initialized\r\nException in device=TPU:6: Default process group is not initialized\r\nException in device=TPU:0: Default process group is not initialized\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\nAssertionError: Default process group is not initialized\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\nAssertionError: Default process group is not initialized\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\nAssertionError: Default process group is not initialized\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\nAssertionError: Default process group is not initialized\r\nAssertionError: Default process group is not initialized\r\nAssertionError: Default process group is not initialized\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\r\n    fn(gindex, *args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 150, in distributed_main\r\n    args.distributed_rank = distributed_init(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 136, in distributed_init\r\n    initialize_model_parallel(args.model_parallel_size)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/model_parallel/megatron/mpu/initialize.py\", line 49, in initialize_model_parallel\r\n    if torch.distributed.get_rank() == 0:\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 598, in get_rank\r\n    _check_default_pg()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\", line 210, in _check_default_pg\r\n    \"Default process group is not initialized\"\r\nAssertionError: Default process group is not initialized\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\r\n    sys.exit(cli_main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 333, in cli_main\r\n    distributed_utils.call_main(args, main)\r\n  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 185, in call_main\r\n    nprocs=8,  # use all 8 TPU cores\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 296, in spawn\r\n    start_method=start_method)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\r\n    while not context.join():\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 113, in join\r\n    (error_index, exitcode)\r\nException: process 0 terminated with exit code 17\r\n```\r\n\r\nAny idea how we could fix this issue ?",
	"issue_comments": "0"
},
{
	"login": "edgarriba",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "204245615",
	"issue_number": "7160",
	"issue_state": "opened",
	"issue_title": "Decrease accuracy after upgrade from v0.11 to v0.12",
	"issue_body": "Hi! I've recently updated from v0.11 to v.012 using pip with CUDA 8.0, cuDNN 5.1in a TitanX under Ubuntu 16.04 LTS.\r\n\r\nDuring the training of a small CNN triplet network with triplet margin loss I noticed that the performance in terms of accuracy went down by a factor of ~40%.  Getting around 9% and 14% FPR95 with v0.11 and v0.12 respectively, both at epoch 30th. Notice with v0.12 the accuracy gets stuck in early epoch 10th.\r\n\r\nThe optimizer that I'm using is Momentum with a LR of 1e-4 without decay policy.\r\nI've also added the regularization term with a weight decay of 1e-4.\r\n\r\nDid you introduce any change with last versions in the optimization API that could make this difference?\r\n\r\nPD: I left here the link to the code.\r\nhttps://github.com/vbalnt/tfeat/tree/master/tensorflow\r\nNotice that we are trying to reproduce from the original LuaTorch version.",
	"issue_comments": "0"
},
{
	"login": "georgesterpu",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "271233851",
	"issue_number": "14252",
	"issue_state": "opened",
	"issue_title": "[Feature request] tf.edit_distance return deletions, substitutions, insertions",
	"issue_body": "Hi,\r\nWhen analysing the performance of a speech recognition model, it is very useful to know the distribution of deletions, substitutions and insertions on the test set.\r\n\r\nCould you make `tf.edit_distance` return these three metrics too, in addition to the cheapest cost?\r\nIt appears to me that the [cpp code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/gtl/edit_distance.h#L47) already computes them. What do you think, @ebrevdo ?",
	"issue_comments": "0"
},
{
	"login": "nng555",
	"repo_name": "pytorch/fairseq",
	"issue_id": "411341172",
	"issue_number": "510",
	"issue_state": "closed",
	"issue_title": "fail to invoke fairseq-preprocess",
	"issue_body": "I try to replicate the language model example task, while when I call the command, it failed as follows.\r\n![image](https://user-images.githubusercontent.com/8109984/52935315-0c891e80-3394-11e9-91c8-fc9fc9477084.png)\r\n",
	"issue_comments": "1"
},
{
	"login": "tcervi",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "808640059",
	"issue_number": "47166",
	"issue_state": "opened",
	"issue_title": "Failed to build Tensorflow Lite for Win32 using CMake",
	"issue_body": "**System information**\r\n- OS Platform and Distribution: Windows - 10.0.19041 - AMD64\r\n- TensorFlow installed from: tag v2.4.1 (85c8b2a) or master (bf157579cf0)\r\n- TensorFlow version: 2.4.1\r\n- CMake version: 3.17.2\r\n- GCC/Compiler version: MSVC 19.27.29111.0\r\n- CUDA/cuDNN version: Not used\r\n- GPU model and memory: Not used\r\n\r\nThis is probably not relevant since I'm building with CMake, but follow my Bazel environment information:\r\n- Python version: 3.8.3 (x64 and x86)\r\n- Installed using virtualenv: tried with both Python x86 venv and with x64 venv\r\n- Bazel version: 3.1.0\r\n\r\n\r\n\r\n\r\n**My problem:**\r\nI'm currently tying to build Tensorflow Lite library to be used by my library that should support both Linux and Windows, x86 and x64. Since Bazel does not builds for x86 out of the box I was following the [documentation](https://www.tensorflow.org/lite/guide/build_cmake) to build TF Lite using CMake, including its source with _add_subdirectory()_ .\r\nIt works great for for x64 builds (-A x64) but when I change it to windows x86 (-A Win32) it always fails building _gemmlowp_.\r\nI also tried to build via cmake on command line, using the tensorflow/lite/CMakeLists.txt to build the static library, but get the same error.\r\n**I wonder if it was even supposed to be supported** and if so, if it is a issue to be handled by tensorflow or [gemmlowp](https://github.com/google/gemmlowp). I can also see some pthread releated errors on CMakeError.log\r\n\r\n\r\n**Build steps:**\r\n\r\n- \u03bb cmake -A Win32 -DCMAKE_BUILD_TYPE=Release -S ..\\tensorflow\\lite\\ -B .\r\n- \u03bb cmake --build . --config Release\r\n...\r\n  ...\r\n  expand_dims.cc\r\n  fake_quant.cc\r\n  Generating Code...\r\n**C:\\workspace\\tensorflow\\build-tflite\\gemmlowp\\internal\\output.h(176): fatal error C1001: Internal compiler error.** [C :\\workspace\\tensorflow\\build-tflite\\tensorflow-lite.vcxproj]\r\n  (compiler file 'd:\\agent\\_work\\7\\s\\src\\vctools\\Compiler\\Utc\\src\\p2\\main.c', line 195)\r\n   To work around this problem, try simplifying or changing the program near the locations listed above.\r\n  If possible please provide a repro here: https://developercommunity.visualstudio.com\r\n  Please choose the Technical Support command on the Visual C++\r\n   Help menu, or open the Technical Support help file for more information\r\n\r\n**Other logs**\r\n\r\n**CMakeError.log**\r\n\r\nDetermining if the include file pthread.h exists failed with the following output:\r\nChange Dir: C:/workspace/tensorflow/build-tflite/CMakeFiles/CMakeTmp\r\n\r\n...\r\n\r\nCopyright (C) Microsoft Corporation. All rights reserved.\r\n\r\n  Microsoft (R) C/C++ Optimizing Compiler Version 19.27.29111 for x86\r\n\r\n  CheckIncludeFile.c\r\n\r\n  Copyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n  cl /c /I\"C:\\workspace\\vcpkg\\scripts\\buildsystems\\msbuild\\..\\..\\..\\installed\\x86-windows\\include\" /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /Oy- /D WIN32 /D _WINDOWS /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_d958e.dir\\Debug\\\\\" /Fd\"cmTC_d958e.dir\\Debug\\vc142.pdb\" /Gd /TC /analyze- /errorReport:queue \"C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c\"\r\n\r\nC:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c(1,10): **fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory** [C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\cmTC_d958e.vcxproj]\r\n\r\nPerforming C++ SOURCE FILE Test EIGEN_COMPILER_SUPPORT_CPP11 failed with the following output:\r\nChange Dir: C:/workspace/tensorflow/build-tflite/CMakeFiles/CMakeTmp\r\n\r\n...\r\n\r\n  Microsoft (R) C/C++ Optimizing Compiler Version 19.27.29111 for x86\r\n  src.cxx\r\n  Copyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n  cl /c /I\"C:\\workspace\\vcpkg\\scripts\\buildsystems\\msbuild\\..\\..\\..\\installed\\x86-windows\\include\" /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /Oy- /D WIN32 /D _WINDOWS /D EIGEN_COMPILER_SUPPORT_CPP11 /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /EHsc /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /GR /Fo\"cmTC_94317.dir\\Debug\\\\\" /Fd\"cmTC_94317.dir\\Debug\\vc142.pdb\" /Gd /TP /analyze- /errorReport:queue  -std=c++11 \"C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\src.cxx\"\r\n\r\ncl : **command line warning D9002: ignoring unknown option '-std=c++11'** [C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\cmTC_94317.vcxproj]\r\n\r\nSource file was:\r\nint main(int argc, char* argv[]) { return (int)__builtin_expect(0, 0); }\r\n**Checking whether the ASM compiler is GNU using \"--version\" did not match \"(GNU assembler)|(GCC)|(Free Software Foundation)\":**\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.27.29111 for x86\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n\r\n\r\nThanks in advance, cheers!",
	"issue_comments": "0"
},
{
	"login": "zaccharieramzi",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "239093505",
	"issue_number": "11103",
	"issue_state": "opened",
	"issue_title": "Batch normalization layer has new name for each call to `__init__`",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX 10.12.5\r\n- **TensorFlow installed from (source or binary)**: `pip install`\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **CUDA/cuDNN version**: no GPU\r\n- **Exact command to reproduce**:\r\n```python\r\nimport tensorflow as tf\r\nx = tf.placeholder(tf.float32, [None, 28])\r\nx_test = tf.placeholder(tf.float32, [None, 28])\r\nnormalized_x = tf.layers.batch_normalization(x, training=True, reuse=None)\r\nnormalized_x_test = tf.layers.batch_normalization(x_test, training=False, reuse=True)\r\n```\r\n\r\n### Describe the problem\r\nThis is the error I get:\r\n```\r\nValueError: Variable batch_normalization_1/beta does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\n```\r\nHowever, I can fix it by setting the name of the batch normalization layer. I think the default behavior should not set a new name each time I create a new batch normalization layer (even if it's an easy thing to debug).\r\n\r\n### Source code / logs\r\nWorking piece of code:\r\n```python\r\nimport tensorflow as tf\r\nx = tf.placeholder(tf.float32, [None, 28])\r\nx_test = tf.placeholder(tf.float32, [None, 28])\r\nnormalized_x = tf.layers.batch_normalization(x, training=True, reuse=None, name=\"batch_normalization\")\r\nnormalized_x_test = tf.layers.batch_normalization(x_test, training=False, reuse=True, name=\"batch_normalization\")\r\n```\r\n",
	"issue_comments": "0"
},
{
	"login": "denismakogon",
	"repo_name": "hybridgroup/gocv",
	"issue_id": "310354814",
	"issue_number": "157",
	"issue_state": "opened",
	"issue_title": "[HelpWanted] More examples with tensorflow DNN models",
	"issue_body": "Would you mind to help to get the same example as with tensorflow and python \r\nhttps://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API?",
	"issue_comments": "0"
},
{
	"login": "jiafatom",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "461657050",
	"issue_number": "30208",
	"issue_state": "opened",
	"issue_title": "tf keras base layer issue for input_tensors/output_tensors in 1.14.0",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.17763\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nIn tensorflow keras, the `input_tensors`, `output_tensors`, `output_shapes` of `class Node` was a list in tensorflow 1.13.1, even if it only contains one tensor. Now the behavior changes in 1.14.0, these variables are a single tensor (not a list any more) if there is one single element. We are developing based on tf keras, then this behavior is not backward compatible .\r\n\r\n**Describe the expected behavior**\r\nCan we change them back to list for the single tensor case?\r\n\r\n**Code to reproduce the issue**\r\n`\r\nfrom tensorflow.python import keras            \r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Dense(5, input_shape=(4,), activation='sigmoid'))\r\nmodel.add(keras.layers.Dense(3, input_shape=(5,), use_bias=bias_value))\r\nmodel.compile('sgd', 'mse')\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n",
	"issue_comments": "0"
},
{
	"login": "kuza55",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "159165852",
	"issue_number": "2729",
	"issue_state": "opened",
	"issue_title": "TensorBoard inception v3 visualization is horizontal and almost unusable",
	"issue_body": "### Environment info\r\nOperating System: Linux x64 GPU\r\n\r\nInstalled version of CUDA and cuDNN: CUDA 7.5, cuDNN v4\r\n\r\nIf installed from binary pip package, provide: 0.8.0\r\n\r\nI've been trying to retrain the inception v3 network using the image_retraining example, and then the inception v3 model in the models repo.\r\n\r\nThe image_retraining model[1] seems to visualize vertically and it relatively straight forward to look at.\r\n\r\nThe model from the models repo[2] visualizes horizontally, making zooming in and exploring the model really tricky.\r\n\r\n[1] http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\r\n[2] http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz",
	"issue_comments": "0"
},
{
	"login": "ManishAradwad",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "545882087",
	"issue_number": "35616",
	"issue_state": "opened",
	"issue_title": "Typo Error in `l07c01_saving_and_loading_models.ipynb`",
	"issue_body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/ManishAradwad/examples/blob/9f7d80aff8214b358e4aea0b83f2648748990c4b/courses/udacity_intro_to_tensorflow_for_deep_learning/l07c01_saving_and_loading_models.ipynb#L579\r\n\r\n`The differnece in output should be zero:`\r\n\r\n## Description of issue (what needs changing):\r\n\r\ndiffernece should be difference\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\n",
	"issue_comments": "0"
},
{
	"login": "alanhdu",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "251801054",
	"issue_number": "12465",
	"issue_state": "opened",
	"issue_title": "Tensorflow Debugger eats disk space with RNNs",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**:  3.5\r\n\r\n### Describe the problem\r\n\r\nI have an RNN that I'm trying to debug using `LocalCLIDebugWrapperSession` which runs on very long sequences (2400 steps). Even for a basic LSTM cell using that I apply via `tf.nn.dynamic_rnn`, `tfdbg` chews up an enormous about of disk space (>50 GB sometimes!).\r\n\r\nFrom inspecting the `tfdbg` dump in `/tmp/`, it looks like this is because tfdbg` dumps out information for each time step. Combined with the `tf.contrib.layers.optimize_loss` capturing gradients, this means that there are hundreds (thousands?) of small files being created on each time step.\r\n\r\nSo I guess my questions is: is there a way to somehow compress these files or combine all these small files across time steps into one large file so that `tfdbg` doesn't chew through all my free disk space?",
	"issue_comments": "0"
},
{
	"login": "denisvnukov",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "357879979",
	"issue_number": "22130",
	"issue_state": "closed",
	"issue_title": "HLO serialization insufficiently validated on deserialization (e.g. for xrt)",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: bc7c47ccddbf351d17b0d2d61cde3d48e2d530d6\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below \r\n\r\n### Describe the problem\r\nThe new xrt ops expose serialized HLO Snapshots as an interface over the distributed TF interface. Some validation of the serialization is performed and returned as an error to the TF client. However, other format errors lead to assertions instead, killing the TF server and requiring a restart. It would be desirable to instead validate the HLO more thoroughly and return any errors to the client.\r\n\r\ncc @michaelisard \r\n\r\n### Source code / logs\r\nI have four minimal example HLO modules that trigger assertions that I encountered when using xrt. Though I encountered them using `xrt`, I'll be using `//tensorflow/compiler/xla/tools:replay_computation_cpu` for easy reproducability in these examples. For each of these examples, I'll show the textual hlo (if dump_computation_to_text was able to process the pb), the .pbtext of the HloSnapshot, and the output of `replay_computation_cpu`. To reproduce,\r\n\r\n```\r\ncd tensorflow\r\nprotoc --encode=xla.HloSnapshot -I=$PWD $PWD/tensorflow/compiler/xrt/xrt.proto < x.pbtext > x.pb\r\n./bazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu x.pb\r\n```\r\n\r\nwhere x.pbtext is the textual pb from this issue.\r\n\r\n#### Add operation with missing parameters:\r\n```\r\nHloModule test\r\n\r\nENTRY comp {\r\n  ROOT op = f64[] add()\r\n}\r\n```\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"op\"\r\n        opcode: \"add\"\r\n        shape {\r\n          element_type: F64\r\n          layout {\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      result {\r\n        element_type: F64\r\n        layout {\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\nbazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu ~/XLAHacks.jl/op_missing_args.pb\r\n2018-09-06 20:18:45.853017: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:18:45.854635: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x556b26f45230 executing computations on platform Host. Devices:\r\n2018-09-06 20:18:45.854662: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:18:45.854726: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\n2018-09-06 20:18:45.855744: F tensorflow/compiler/xla/service/hlo_instruction.cc:1931] Check failed: 2 == operand_count() (2 vs. 0)\r\nAborted\r\n```\r\n\r\n#### Parameter reference when function has no parameters\r\n```\r\nHloModule test\r\n\r\nENTRY comp {\r\n  ROOT op = f64[] parameter(0)\r\n}\r\n```\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"op\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          layout {\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      result {\r\n        element_type: F64\r\n        layout {\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\n2018-09-06 20:20:29.529757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:20:29.531397: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x562efc8c8230 executing computations on platform Host. Devices:\r\n2018-09-06 20:20:29.531425: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:20:29.531492: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\nSegmentation fault\r\n```\r\n\r\n#### Parameter reference out of bounds\r\nBasically an add of parameters 1, 2 for a one parameter function (i.e. I had an off by one in my parameter numbers):\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"parameter0\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 1\r\n          layout {\r\n            minor_to_major: 0\r\n            format: DENSE\r\n          }\r\n        }\r\n        parameter_number: 1\r\n      }\r\n      instructions {\r\n        name: \"parameter1\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 1\r\n          layout {\r\n            minor_to_major: 0\r\n            format: DENSE\r\n          }\r\n        }\r\n        parameter_number: 2\r\n        id: 1\r\n      }\r\n      instructions {\r\n        name: \"add2\"\r\n        opcode: \"add\"\r\n        shape {\r\n          element_type: F32\r\n          layout {\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n        operand_ids: 0\r\n        operand_ids: 1\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 1\r\n        layout {\r\n          minor_to_major: 0\r\n          format: DENSE\r\n        }\r\n      }\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 1\r\n        layout {\r\n          minor_to_major: 0\r\n          format: DENSE\r\n        }\r\n      }\r\n      result {\r\n        element_type: F32\r\n        layout {\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\n2018-09-06 20:25:29.866942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:25:29.868569: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x560a8b2b7230 executing computations on platform Host. Devices:\r\n2018-09-06 20:25:29.868598: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:25:29.868667: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\n2018-09-06 20:25:29.869118: F tensorflow/compiler/xla/service/hlo_computation.cc:78] Check failed: param_no >= 0 && param_no < parameter_count\r\nERROR: invalid parameter number.  Expected [0, 2), got 2\r\nAborted\r\n```\r\n\r\n#### Missing dot dimension numbers\r\n```\r\nHloModule test\r\n\r\nENTRY comp {\r\n  parameter0 = f64[2,2]{0,1} parameter(0)\r\n  parameter1 = f64[2,2]{0,1} parameter(1)\r\n  ROOT dot2 = f64[1]{0} dot(parameter0, parameter1)\r\n}\r\n```\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"parameter0\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 2\r\n          dimensions: 2\r\n          layout {\r\n            minor_to_major: 0\r\n            minor_to_major: 1\r\n            format: DENSE\r\n          }\r\n        }\r\n      }\r\n      instructions {\r\n        name: \"parameter1\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 2\r\n          dimensions: 2\r\n          layout {\r\n            minor_to_major: 0\r\n            minor_to_major: 1\r\n            format: DENSE\r\n          }\r\n        }\r\n        parameter_number: 1\r\n        id: 1\r\n      }\r\n      instructions {\r\n        name: \"dot2\"\r\n        opcode: \"dot\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 1\r\n          layout {\r\n            minor_to_major: 0\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n        operand_ids: 0\r\n        operand_ids: 1\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 2\r\n        dimensions: 2\r\n        layout {\r\n          minor_to_major: 0\r\n          minor_to_major: 1\r\n          format: DENSE\r\n        }\r\n      }\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 2\r\n        dimensions: 2\r\n        layout {\r\n          minor_to_major: 0\r\n          minor_to_major: 1\r\n          format: DENSE\r\n        }\r\n      }\r\n      result {\r\n        element_type: F64\r\n        dimensions: 1\r\n        layout {\r\n          minor_to_major: 0\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\n2018-09-06 20:30:04.934720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:30:04.936398: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x55fd5deeb230 executing computations on platform Host. Devices:\r\n2018-09-06 20:30:04.936426: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:30:04.936502: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\n2018-09-06 20:30:04.937560: F ./tensorflow/compiler/xla/service/hlo_instruction.h:1105] Check failed: dot_dimension_numbers_ != nullptr\r\nAborted\r\n```",
	"issue_comments": "7"
},
{
	"login": "malmaud",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "174820635",
	"issue_number": "4181",
	"issue_state": "opened",
	"issue_title": "Document events file format",
	"issue_body": "Hello,\r\nIn the documentation for Tensorboard, I can't find a description for the format of the events file beyond that it contains Event protobufs. Is it recordio? Are there any tools for writing event files for 3rd-party Tensorflow clients that aren't using the Python API? ",
	"issue_comments": "0"
},
{
	"login": "Nyrio",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "1060334908",
	"issue_number": "53157",
	"issue_state": "opened",
	"issue_title": "Outdated documentation for `DataFormatVecPermute`",
	"issue_body": "This came up while creating a TF-TRT converter for `DataFormatVecPermute` in #52942 \r\ncc @bixia1 \r\n\r\n## URL(s) with the issue:\r\n\r\n - Python: https://www.tensorflow.org/api_docs/python/tf/raw_ops/DataFormatVecPermute\r\n - C++: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/data-format-vec-permute\r\n - Java: https://www.tensorflow.org/jvm/api_docs/java/org/tensorflow/op/nn/DataFormatVecPermute\r\n - \r\n\r\n## Description of the issue (what needs changing):\r\n\r\n- Examples imply that an input of shape `(2, 4)` is valid, but that should be `(4, 2)`.\r\n- The format strings can be of size 4 or 5 (e.g `\"NHWC\"`, `\"NDHWC\"`).\r\n- The first dimension of the input shape vector can be `src_format.size()` or `src_format.size() - 2`, in which case it is assumed that non-spatial dimensions are omitted.\r\n\r\nAs an example, here is a valid Python code that is not covered by the documentation:\r\n\r\n```python\r\nimport tensorflow as tf\r\na = tf.constant([1, 2, 3, 4, 5])\r\nprint(tf.raw_ops.DataFormatVecPermute(x=a, src_format=\"NDHWC\", dst_format=\"NCDHW\"))\r\n```\r\nOutput:\r\n```\r\ntf.Tensor([1 5 2 3 4], shape=(5,), dtype=int32)\r\n```\r\n\r\n## Submit a pull request?\r\n\r\nI'm planning to submit a PR.",
	"issue_comments": "0"
},
{
	"login": "vishalsubbiah",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "357442068",
	"issue_number": "22102",
	"issue_state": "closed",
	"issue_title": "raw_rnns not working with xla jit compile",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7.4.1708\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.4.5\r\n- **Bazel version (if compiling from source)**: 0.16\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nTrying to run char_rnn using raw_rnns with LSTMCell using TF estimators on the shakespeare dataset. It trains when I don't use the xla jit compile. When I do try to add the xla jit compile, I run into errors.  \r\n\r\nfirst error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: Resource arguments cannot be constant (argument 3)\r\n\tEncapsulateSubgraphsPass failed\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"basic_rnn.py\", line 332, in <module>\r\n    classifier.train(input_fn, steps=args.num_steps)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\r\n    saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1207, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 987, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Resource arguments cannot be constant (argument 3)\r\n\tEncapsulateSubgraphsPass failed\r\n```\r\nI fixed this by modifying the tensorflow/compiler/tf2xla/const_analysis.cc with\r\n```\r\nStatus BackwardsConstAnalysis(const Graph& g,\r\n         int index;\r\n         status = GetNodeAttr(node->attrs(), \"index\", &index);\r\n         if (!status.ok()) return;\r\n-        compile_time_const_args->at(index) = true;\r\n+       DataType dt;\r\n+       status = GetNodeAttr(node->attrs(), \"T\", &dt);\r\n+       if (!status.ok()) return;\r\n+       if (dt != DT_RESOURCE) {\r\n+         VLOG(1) << \"HIHIH \"<< SummarizeNodeDef(node->def());\r\n+         compile_time_const_args->at(index) = true;\r\n+       }\r\n         return;\r\n       }\r\n       for (const Edge* pred : node->in_edges()) {\r\n``` \r\nI then run into this error:\r\n```\r\n (No registered '_Retval' OpKernel for XLA_CPU_JIT devices compatible with node test_conv_gradients_test_conv_rnn_while_select_1_grad_select_f_acc_0_retval_RetVal = _Retval[T=DT_RESOURCE, index=0](test_conv/gradients/test_conv/rnn/while/Select_1_grad/Select/f_acc)\r\n         (OpKernel was found, but attributes didn't match)\r\n        .  Registered:  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_HALF, DT_UINT32, DT_UINT64]\r\n  device='GPU'; T in [DT_STRING]\r\n  device='GPU'; T in [DT_RESOURCE]\r\n  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_BOOL]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='GPU'; T in [DT_INT8]\r\n  device='GPU'; T in [DT_UINT8]\r\n  device='GPU'; T in [DT_INT16]\r\n  device='GPU'; T in [DT_UINT16]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_BFLOAT16]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='CPU'\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_HALF, DT_UINT32, DT_UINT64]\r\n)\r\n```\r\n\r\nIs there a way for me to fix this? Or for the tensorflow folks to fix this? Or is there an example of using raw_rnns with the xla jit compile that I can look at? ",
	"issue_comments": "8"
},
{
	"login": "ddrevicky",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "336755932",
	"issue_number": "20387",
	"issue_state": "opened",
	"issue_title": "Tensorflow C++ not releasing GPU resources after closing the session",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code:**: No\r\n- **OS Platform and Distribution: **: Windows 10\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version (use command below)**: tensorflow r1.7\r\n- **Python version**:  N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: MSVC v140\r\n- **CUDA/cuDNN version**:  CUDA 9.0 and cuDNN v7.0.5\r\n- **GPU model and memory**:  NVIDIA GeForce GTX 1050 Ti 4095 MB\r\n- **Exact command to reproduce**: See code below\r\n```\r\n\r\n\r\n### Describe the problem\r\nCompiled tensorflow C++ with GPU support from source (branch r1.7) on Windows 10. Upon creating a new session 3GBs of memory are allocated on the GPU. Closing the session does not seem to result in the memory being released from the GPU as confirmed by the nvidia-smi command. Resources are only released when the C++ program exits.\r\n\r\n### Source code / logs\r\nint main()\r\n{\r\n    SessionOptions options;\r\n    Session* session;\r\n    tensorflow::Status status = NewSession(SessionOptions(), &session); // returns ok\r\n\r\n    status = session->Close(); // returns ok\r\n    delete session;\r\n\r\n    // GPU memory is still occupied at this point\r\n    std::string s;\r\n    std::cin >> s;\r\n\r\n    return 0;\r\n}\r\n// GPU memory is released when process exits\r\n",
	"issue_comments": "0"
},
{
	"login": "dksb",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "277401681",
	"issue_number": "14943",
	"issue_state": "closed",
	"issue_title": "Update docker images and documentation to not use nvidia-docker by default.",
	"issue_body": "`nvidia-docker` is not used anymore by the [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) project.  Rather `nvidia-docker2` should be used:\r\n\r\n```\r\n$ docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi\r\n```",
	"issue_comments": "4"
},
{
	"login": "hsgkim",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "345587046",
	"issue_number": "21229",
	"issue_state": "opened",
	"issue_title": "Default behavior of tf.layers.batch_normalization",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.5 LTS (Xenial Xerus)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: pip (binary)\r\n- **TensorFlow version (use command below)**: (tf.GIT_VERSION, tf.VERSION) == ('v1.9.0-0-g25c197e023', '1.9.0')\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.1\r\n- **GPU model and memory**: NVIDIA GeForce GTX 1080Ti 11177MiB\r\n- **Exact command to reproduce**: tf.layers.batch_normalization\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI was trying to train my network using multiple batch normalization layers(`tf.layers.batch_normalization`), only to fail the training process even though I was basically copying a published paper. I had skimmed through the documentation as it looked fairly straightforward, especially after already having had added multiple layers using `tf.layers`. Only after a couple days (as training takes quite a long time) did I realize I had missed the note part of the documentation. This is of course my fault for not reading the documentation thoroughly, but it really strikes me odd that the default behavior of this layer is not to update the ops right away. I guess it might be due to performance reasons, but if that is the case why not just have `defer_updates` argument which defaults to False? I think most beginners would expect the layer to update everything right away, and maybe not even expect everything to be fast anyway. Only power users would really want to fine-tune and optimize their network, in which case then they can set `defer_updates` to True.\r\n\r\nI think I just rambled a lot here; my point is that I think it would be better if `tf.layers.batch_normalization` would update ops without the need of `update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)` and `with tf.control_dependencies(update_ops)`, and for people who do not want this, add `defer_updates` as an argument.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n",
	"issue_comments": "0"
},
{
	"login": "smistad",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "225682815",
	"issue_number": "9593",
	"issue_state": "opened",
	"issue_title": "libtensorflow.so: undefined reference to `__cpu_model'",
	"issue_body": "When linking with the tensorflow C++ library, the following error occurs: libtensorflow.so: undefined reference to `__cpu_model'\r\n\r\nSeems to be related to issue #7223\r\n\r\nI manage to work around this error with: ( as done by https://github.com/tensorflow/tensorflow/pull/7241/commits/d7955a66088567ade60213448bbab861de9055cd)\r\n`#ifndef USE_SSE_CRC32C`\r\nin the file tensorflow/core/lib/hash/crc32c_accelerate.cc\r\n\r\nDoing this removed the error.\r\n\r\nSystem information:\r\nUbuntu 16.04 64 bit\r\nIntel i5 CPU\r\nNVIDIA GTX 980 GPU\r\nBuilt using CMake with BUILD_SHARED_LIB enabled which creates the libtensorflow.so file\r\n",
	"issue_comments": "0"
},
{
	"login": "jackd",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "430447346",
	"issue_number": "27639",
	"issue_state": "closed",
	"issue_title": "keras `Model.__call__` fails to propagate `Lambda`s with multiple outputs correctly",
	"issue_body": "\r\n## System Information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (see below)\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from: pip\r\n- TensorFlow version (use command below): ('v1.13.1-0-g6612da8951', '1.13.1')\r\n- Python version: 2.7.12\r\n- GPU model and memory: quadro 620\r\n\r\n## Current Behaviour\r\nCalls to models created using the functional interface fail to appropriately propagate `Lambda` outputs with multiple outputs. Model construction works as expected.\r\n\r\n## Expected Behaviour\r\nOutputs of intermediate layers should have the same structure during model construction as during model call.\r\n\r\n## Code to Reproduce\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\n\r\nx = tf.keras.layers.Input(shape=(), dtype=tf.float32)\r\ny = tf.keras.layers.Input(shape=(), dtype=tf.float32)\r\n\r\n\r\ndef add_and_mul(args):\r\n    x, y = args\r\n    return x + y, x * y\r\n\r\n\r\ndef add_mul_model():\r\n    x = tf.keras.layers.Input(shape=(), dtype=tf.float32)\r\n    y = tf.keras.layers.Input(shape=(), dtype=tf.float32)\r\n    s = tf.keras.layers.Lambda(lambda a: a[0] + a[1])([x, y])\r\n    p = tf.keras.layers.Lambda(lambda a: a[0] * a[1])([x, y])\r\n    return tf.keras.models.Model(inputs=[x, y], outputs=[s, p])\r\n\r\n\r\nlayer = tf.keras.layers.Lambda(add_and_mul)  # bugged\r\n# layer = add_mul_model()                    # not bugged\r\ns, p = layer([x, y])\r\n# the following gives the same output either way\r\nprint('s = %s' % s)\r\nprint('p = %s' % p)\r\n\r\n\r\ndef double(x):\r\n    print('argument to double: %s' % str(x))\r\n    # using the bugged version, this prints:\r\n    # argument to double:\r\n    #       Tensor(\"lambda/add:0\", shape=(?,), dtype=float32)\r\n    # argument to double: (\r\n    #     <tf.Tensor 'model/lambda/add:0' shape=(1,) dtype=float32>,\r\n    #     <tf.Tensor 'model/lambda/mul:0' shape=(1,) dtype=float32>)\r\n\r\n    # unbugged version prints:\r\n    # argument to double:\r\n    #       Tensor(\"model/lambda/add:0\", shape=(?,), dtype=float32)\r\n    # argument to double:\r\n    #       Tensor(\"model_1/model/lambda/add:0\", shape=(1,), dtype=float32)\r\n    return x * 2\r\n\r\n\r\ns2 = tf.keras.layers.Lambda(double)(s)\r\n\r\n\r\nmodel = tf.keras.models.Model(inputs=[x, y], outputs=s2)\r\n\r\nx = tf.constant([3.0], dtype=tf.float32)\r\ny = tf.constant([4.0], dtype=tf.float32)\r\n\r\nout = model([x, y])\r\nprint(out)\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run(out))\r\n    # (([7.], [12.]), ([7.], [12.])) for bugged version, 14. for good version\r\n```\r\n",
	"issue_comments": "1"
},
{
	"login": "TimZaman",
	"repo_name": "NVIDIA/DIGITS",
	"issue_id": "144262535",
	"issue_number": "662",
	"issue_state": "closed",
	"issue_title": "Learning rate 'Exponential Decay' policy wrong.",
	"issue_body": "Version **v3.2.0-61-g0ce28b9**\r\nI often have issues with the learning rate and the decay. Sometimes it tells me it cannot process 'nan', sometimes it's correct, sometimes it jitters a bit up and down, but most often it does this. I can reproduce this only half of the time. \r\nBase learning rate: 1.0\r\nPolicy: Exponential Decay\r\nGamma: 0.95\r\n![screen shot 2016-03-29 at 3 16 24 pm](https://cloud.githubusercontent.com/assets/7721540/14109283/8d07aa0e-f5c1-11e5-8e38-7a8fedae70a6.png)\r\n\r\nThen this happens:\r\n![screen shot 2016-03-29 at 3 16 11 pm](https://cloud.githubusercontent.com/assets/7721540/14109287/90dd9634-f5c1-11e5-8c0a-2d6637aee321.png)\r\n",
	"issue_comments": "4"
},
{
	"login": "cccntu",
	"repo_name": "huggingface/transformers",
	"issue_id": "718743604",
	"issue_number": "7702",
	"issue_state": "opened",
	"issue_title": "Trainer callback breaks old code",
	"issue_body": "https://github.com/huggingface/transformers/blob/ba4bbd92bcb55febbfa06aaa1551738388ec7eb0/src/transformers/trainer_callback.py#L438-L447\r\n\r\nCurrently it depends on the fact that evaluate() will first call `self.prediction_loop` https://github.com/huggingface/transformers/blob/ba4bbd92bcb55febbfa06aaa1551738388ec7eb0/src/transformers/trainer.py#L1181\r\n\r\nwhich will then call `.callback_handler.on_prediction_step `\r\nhttps://github.com/huggingface/transformers/blob/ba4bbd92bcb55febbfa06aaa1551738388ec7eb0/src/transformers/trainer.py#L1270\r\n\r\nBut in my old code (3.1.0), I subclass Trainer and overwrite evaluate(), without calling self.prediction_loop.\r\n\r\nAnd results in this error:\r\n```\r\nself.prediction_bar.close() \r\nAttributeError: 'NoneType' object has no attribute 'close'\r\n```\r\n\r\nI propose we add `on_predict_begin`  and `on_predict_end`.",
	"issue_comments": "0"
},
{
	"login": "nrstott",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "321608424",
	"issue_number": "19182",
	"issue_state": "opened",
	"issue_title": "pandas_input_fn taking a DataFrame or dict of Series for y",
	"issue_body": "# Pandas Input Function for Multilabel Inputs\r\n\r\n`tf.estimator.inputs.pandas_input_fn` should be able to take a DataFarme or a dict with key to Series for y. This would allow multi-label inputs. This is similar to the numpy_input_fn behavior implemented in issue #12610.\r\n\r\nI'd be happy to give the implementation a shot.",
	"issue_comments": "0"
},
{
	"login": "rmothukuru",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "467386974",
	"issue_number": "30646",
	"issue_state": "reopened",
	"issue_title": "Filling shuffle buffer, this happens before the beginning of every epoch. Is there a way to avoid it?",
	"issue_body": "I am following [this tutorial](https://www.tensorflow.org/beta/tutorials/load_data/text#split_the_dataset_into_text_and_train_batches), however I am using my own dataset stored as a csv file consisting 1265800 elements. My question is:\r\nBefore the beginning of every epoch, it shows `Filling up shuffle buffer (this may take a while)`. I think it means that it is shuffling the dataset before feeding it to the model for training. Is there a way to not to shuffle this before every epoch because it takes time before proceeding to the next epoch.\r\nAlso, this behaviour is not seen if I run the example model on Google Colab. I also read [this issue](https://github.com/tensorflow/tensorflow/issues/29957) but didn't help.\r\nThank you for your inputs.",
	"issue_comments": "3"
},
{
	"login": "rmothukuru",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "502883008",
	"issue_number": "33060",
	"issue_state": "closed",
	"issue_title": "Possible corruption in Load or freeze in TF2.0",
	"issue_body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary 2.0.0\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 7.6.4\r\n- GPU model and memory: Volta/Turing\r\n\r\n**Describe the current behavior**\r\nWhen I run load and freeze in two different python functions, I get a crash that says: \r\n\r\n```AssertionError: Called a function referencing variables which have been deleted. This likely means that function-local variables were created and not referenced elsewhere in the program. This is generally a mistake; consider storing variables in an object attribute on first call.```\r\n\r\nBut when I run both of load and freeze in the same python function, then it works as expected.\r\n\r\n**Describe the expected behavior**\r\nCalling load and freeze in different python functions should work unless there is some hidden assumption in TF 2.0. My guess is that there is a leak or some dependency between the two APIs.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport argparse\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.saved_model import signature_constants\r\nfrom tensorflow.python.saved_model import tag_constants\r\nfrom tensorflow.python.framework import convert_to_constants\r\n\r\ndef get_dataset(batch_size, input_size):\r\n  features = np.random.normal(\r\n      loc=112, scale=70,\r\n      size=(batch_size, input_size, input_size, 3)).astype(np.float32)\r\n  features = np.clip(features, 0.0, 255.0)\r\n  features = tf.convert_to_tensor(value=tf.compat.v1.get_variable(\r\n      \"features\", dtype=tf.float32, initializer=tf.constant(features)))\r\n  dataset = tf.data.Dataset.from_tensor_slices([features])\r\n  dataset = dataset.repeat()\r\n  return dataset\r\n\r\n\r\ndef run_func(saved_model_dir):\r\n\r\n  def load_model():\r\n    saved_model_loaded = tf.saved_model.load(\r\n        saved_model_dir, tags=[tag_constants.SERVING])\r\n    graph_func = saved_model_loaded.signatures[\r\n        signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n    return graph_func\r\n  graph_func = load_model()\r\n\r\n# Replace load_model function and its call with the following to make it work\r\n#  saved_model_loaded = tf.saved_model.load(\r\n#      saved_model_dir, tags=[tag_constants.SERVING])\r\n#  graph_func = saved_model_loaded.signatures[\r\n#      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n\r\n  frozen_func = convert_to_constants.convert_variables_to_constants_v2(graph_func)\r\n  def wrap_func(*args, **kwargs):\r\n    return frozen_func(*args, **kwargs)[0]\r\n  inference_graph_func = wrap_func\r\n  dataset = get_dataset(batch_size=8, input_size=224)\r\n  for i, (batch_feats) in enumerate(dataset):\r\n    batch_preds = inference_graph_func(batch_feats).numpy()\r\n    print(batch_preds)\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser(description='Evaluate model')\r\n  parser.add_argument('--saved_model_dir', type=str, default=None,\r\n                      help='Directory containing a particular saved model.')\r\n  args = parser.parse_args()\r\n\r\n  run_func(saved_model_dir=args.saved_model_dir)\r\n```\r\n\r\n**Other info / logs**\r\nCommand line to run: `python tfv2_load_issue.py --saved_model_dir path_to_saved_model`\r\n\r\n```\r\n2019-10-04 20:35:48.913525: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:734] Optimization results for grappler item: graph_to_optimize\r\n2019-10-04 20:35:48.913553: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:736]   function_optimizer: Graph size after: 1314 nodes (1044), 2670 edges (2400), time = 23.171ms.\r\n2019-10-04 20:35:48.913557: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:736]   function_optimizer: function_optimizer did nothing. time = 0.371ms.\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 51, in <module>\r\n    run_func(saved_model_dir=args.saved_model_dir)\r\n  File \"run.py\", line 35, in run_func\r\n    frozen_func = convert_to_constants.convert_variables_to_constants_v2(graph_func)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/convert_to_constants.py\", line 411, in convert_variables_to_constants_v2\r\n    tensor_data = _get_tensor_data(func)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/convert_to_constants.py\", line 182, in _get_tensor_data\r\n    for var in func.graph.variables:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 435, in variables\r\n    \"Called a function referencing variables which have been deleted. \"\r\nAssertionError: Called a function referencing variables which have been deleted. This likely means that function-local variables were created and not referenced elsewhere in the program. This is generally a mistake; consider storing variables in an object attribute on first call.\r\n```\r\n",
	"issue_comments": "3"
},
{
	"login": "ThisIsIsaac",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "435071568",
	"issue_number": "27975",
	"issue_state": "opened",
	"issue_title": "CUDA Kernel throughput optimization",
	"issue_body": "I want to go through Tensorflow's CUDA kernels and optimize them. It seems like all the CUDA kernels are defined in `tensorflow/core/kernels` and `tensorflow/contrib` with some helper functions in `tensorflow/core/util`.\r\n\r\n1. Is it okay for me to optimize kernels in tensorflow/core/kernels and send pull request?\r\n\r\n2. now that tensorflow is moving to 2.0, are the CUDA kernels going to also change so dramatically that any improvements to them now could be rendered useless?\r\n\r\n3. what are some conventions or practices when writing CUDA kernels? I have read the `contrib.md`, but there was nothing special on CUDA kernels ( ex. \" Do not change kernel launch configurations \" or \" must support devices of compute capability >= 3.0 \" )\r\n\r\n4. must I use `CudaGridRangeX` over regular for loops?\r\n\r\n5. Is there way to test and profile each .cu file individually, instead of having to rebuild the entire tensorflow or even having to test all kernels?",
	"issue_comments": "0"
},
{
	"login": "cancan101",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "134341416",
	"issue_number": "1145",
	"issue_state": "opened",
	"issue_title": "Specify --no-install-recommends in apt-get install in Dockerfiles",
	"issue_body": "Explicitly list needed packaged in Dockerfile and then add `--no-install-recommends` to that unneeded packaged are not added. For example right now install OpenJDK tried to install fuse.",
	"issue_comments": "0"
},
{
	"login": "cancan101",
	"repo_name": "Theano/Theano",
	"issue_id": "90770018",
	"issue_number": "3064",
	"issue_state": "opened",
	"issue_title": "Theano does not play well with IPython's \"Interrupt Kernel\"",
	"issue_body": "See: https://github.com/ipython/ipython/issues/8563\r\n\r\nRunning \"Interrupt Kernel\" in Ipython when running a Theano function does not always work.",
	"issue_comments": "0"
},
{
	"login": "mpjlu",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "362158259",
	"issue_number": "22410",
	"issue_state": "opened",
	"issue_title": "GAN train will hand if not use default GANTrainSteps(1, 1)",
	"issue_body": "When I test WGAN on tensorflow,  I set the generator_train_steps = 1 and discriminator_train_steps = 5 following the paper, like this:\r\ntensorflow/contrib/gan/python/train.py:815\r\n`def get_sequential_train_hooks(train_steps=namedtuples.GANTrainSteps(1, 5))`\r\nThe train process always hand after the first step. \r\nAnd the default value works well.\r\n`def get_sequential_train_hooks(train_steps=namedtuples.GANTrainSteps(1, 1))`\r\n\r\nTest:\r\njust run \r\n`https://github.com/tensorflow/models/blob/master/research/gan/cifar/train.py `\r\nwith cifar10 dataset.\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "415456425",
	"issue_number": "26197",
	"issue_state": "closed",
	"issue_title": "[TF 2.0 API Docs] tf.keras",
	"issue_body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras\r\n\r\n**Describe the documentation issue**\r\n\r\n**Links** \r\n\"Defined in python/keras/api/_v2/keras/__init__.py\" is pointing to a broken link:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/api/_v2/keras/__init__.py\r\n\r\n**Description**\r\nCurrently it has \"Detailed documentation and user guides are available at keras.io.\"\r\nIt would be better to point users to https://www.tensorflow.org/guide/keras, otherwise the experience feels broken.\r\n\r\nIt would be great to list some key differences between tf.keras vs Keras as an independent project (keras.io). Or at least point out there is no 1:1 mapping and what each one has and the other one doesn't have. This has been discussed in blog posts and forums but the official documentation should at least have a high level overview with a few sentences.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes\r\n",
	"issue_comments": "14"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "605713596",
	"issue_number": "38842",
	"issue_state": "closed",
	"issue_title": "ValueError: Could not interpret optimizer identifier (tf.keras) ",
	"issue_body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- I have written a custom callback for learning_rate_scheduler in keras\r\n- Code is running on Google Colaboratory:\r\n- TensorFlow version (use command below): tensorflow 2.2.0-rc3.\r\nI need to be able to set and get my learning_rate and other params in my optimizer,\r\n\r\n I need to be able to use the constructor of optimizer to set the parameters in it\r\n\r\nUsed the sample code in the keras documentation \r\n\"Issue Reproducing steps\"\r\n1. Run this code in Google colab\r\nfrom keras import optimizers\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))\r\nmodel.add(Activation('softmax'))\r\n\r\nsgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\r\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\r\n2. Throws Deserialization error\r\n3. Attaching the screenshot of the erro\r\n4.Please help with a resolution/workaround for this issue, as i am working on a critical course assignment which I need to submit soon .\r\n![error 2020-04-23 222914](https://user-images.githubusercontent.com/21074002/80129974-824ed280-85b5-11ea-9eac-5dd4791e8d6a.jpg)\r\n\r\nThanks\r\n\r\n\r\n",
	"issue_comments": "11"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "577134274",
	"issue_number": "37399",
	"issue_state": "closed",
	"issue_title": "InvalidArgumentError: Cannot assign a device for operation conv2d_1/kernel/IsInitialized/VarIsInitializedOp: node conv2d_1/kernel/IsInitialized/VarIsInitializedOp (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /job:worker/replica:0/task:0/device:TPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device. \t [[conv2d_1/kernel/IsInitialized/VarIsInitializedOp]]",
	"issue_body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n",
	"issue_comments": "3"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "590491026",
	"issue_number": "38054",
	"issue_state": "reopened",
	"issue_title": "Unable to access files on S3 with tf.io.gfile.GFile",
	"issue_body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): MacOS Mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): 2.0.0\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nExecuting the following code: \r\n\r\n```\r\nwith tf.io.gfile.GFile(\"s3://path/to/my/file\", mode=\"r\") as f:\r\n    data = f.read()\r\n```\r\n\r\nresults in the following error message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 124, in read\r\n    length = self.size() - self.tell()\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 102, in size\r\n    return stat(self.__name).length\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 727, in stat\r\n    return stat_v2(filename)\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 744, in stat_v2\r\n    pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Object s3://[REDACTED]/train.txt does not exist\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\nThe contents of the file should be written to variable `data`\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nThis points to a public s3 file, but still fails:\r\n\r\nhttps://colab.research.google.com/drive/1VSlfzRPdFNSGGI8wd6RdhH9uFj7fkaFG\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n2020-03-30 23:22:36.465054: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /Users/neelabh//.aws/config and using profilePrefix = 1\r\n2020-03-30 23:22:36.465103: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /Users/neelabh//.aws/credentials and using profilePrefix = 0\r\n2020-03-30 23:22:36.465129: I tensorflow/core/platform/s3/aws_logging.cc:54] Setting provider to read credentials from /Users/neelabh//.aws/credentials for credentials file and /Users/neelabh//.aws/config for the config file , for use with profile default\r\n2020-03-30 23:22:36.465207: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating AWSHttpResourceClient with max connections2 and scheme http\r\n2020-03-30 23:22:36.465336: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 2\r\n2020-03-30 23:22:36.465391: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating Instance with default EC2MetadataClient and refresh rate 300000\r\n2020-03-30 23:22:36.465427: I tensorflow/core/platform/s3/aws_logging.cc:54] Added EC2 metadata service credentials provider to the provider chain.\r\n2020-03-30 23:22:36.465682: I tensorflow/core/platform/s3/aws_logging.cc:54] Successfully reloaded configuration.\r\n2020-03-30 23:22:36.465889: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 25\r\n2020-03-30 23:22:36.466559: I tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2\r\n2020-03-30 23:22:36.466586: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2020-03-30 23:22:37.536377: E tensorflow/core/platform/s3/aws_logging.cc:60] HTTP response code: 301\r\nException name: \r\nError message: No response body.\r\n7 response headers:\r\ncontent-type : application/xml\r\ndate : Mon, 30 Mar 2020 17:52:37 GMT\r\nserver : AmazonS3\r\ntransfer-encoding : chunked\r\nx-amz-bucket-region : eu-north-1\r\nx-amz-id-2 : 021phnKX0e6e9R+N9sMrXZHViGoHdzJrTT5rnyHyWsP8d9ErkPMZT02RbTZcjVeCVrI/3hDkWk8=\r\nx-amz-request-id : 7DAC97A633CA370B\r\n2020-03-30 23:22:37.536443: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2020-03-30 23:22:37.536681: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2020-03-30 23:22:37.818954: W tensorflow/core/platform/s3/aws_logging.cc:57] Encountered Unknown AWSError 'PermanentRedirect': The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint.\r\n2020-03-30 23:22:37.819073: E tensorflow/core/platform/s3/aws_logging.cc:60] HTTP response code: 301\r\nException name: PermanentRedirect\r\nError message: Unable to parse ExceptionName: PermanentRedirect Message: The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint.\r\n7 response headers:\r\ncontent-type : application/xml\r\ndate : Mon, 30 Mar 2020 17:52:37 GMT\r\nserver : AmazonS3\r\ntransfer-encoding : chunked\r\nx-amz-bucket-region : eu-north-1\r\nx-amz-id-2 : ob9TL15Q4Y7/idUzUTWvurB3Z4nxfVYRV2V+9ly88HrVGuHytuZA1U02rhcL0vFUpv83vUxeO9o=\r\nx-amz-request-id : 51E3695245C81463\r\n2020-03-30 23:22:37.819138: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 124, in read\r\n    length = self.size() - self.tell()\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 102, in size\r\n    return stat(self.__name).length\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 727, in stat\r\n    return stat_v2(filename)\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 744, in stat_v2\r\n    pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Object s3://[REDACTED]/train.txt does not exist\r\n```",
	"issue_comments": "20"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "646842101",
	"issue_number": "40876",
	"issue_state": "closed",
	"issue_title": "TFL Classify keeps stopping on Pixel 3.",
	"issue_body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n",
	"issue_comments": "3"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "672466304",
	"issue_number": "42016",
	"issue_state": "closed",
	"issue_title": "Timeseries example is not working with latest 2.4 code",
	"issue_body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\r\n\r\nWhen it comes to Convolution model, this errors out.\r\n===code===\r\nhistory = compile_and_fit(conv_model, conv_window)\r\n\r\nIPython.display.clear_output()\r\nval_performance['Conv'] = conv_model.evaluate(conv_window.val)\r\nperformance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)\r\n==============\r\n===error====\r\nNotFoundError:  No algorithm worked!\r\n\t [[node sequential_3/conv1d/conv1d (defined at <ipython-input-41-716049f06cb3>:12) ]] [Op:__inference_train_function_127129]\r\n\r\nFunction call stack:\r\ntrain_function\r\n",
	"issue_comments": "1"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "589336636",
	"issue_number": "37984",
	"issue_state": "closed",
	"issue_title": "no detection on custom trained model",
	"issue_body": "I have made a custom trained model using yolov2 and after 1500 iteration i tried to test it but no detection boxes the output image as the input any help please",
	"issue_comments": "5"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "621756855",
	"issue_number": "39716",
	"issue_state": "closed",
	"issue_title": "TF 2.2.0 ptxas issue",
	"issue_body": "Running in linux some code I get the following warning:\r\n\r\n`You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 9.2.88).  Compilation of XLA kernels below will likely fail.`\r\n\r\nHowever when I run with the flag `TF_CPP_VMODULE=asm_compiler=2` I get this output:\r\n\r\n`2020-05-20 14:57:36.735438: I tensorflow/stream_executor/gpu/asm_compiler.cc:169] Looking for ptxas at /usr/local/cuda-10.1/bin/bin/ptxas`\r\n`2020-05-20 14:57:36.735500: I tensorflow/stream_executor/gpu/asm_compiler.cc:169] Looking for ptxas at /usr/local/cuda/bin/ptxas`\r\n`2020-05-20 14:57:36.735521: I tensorflow/stream_executor/gpu/asm_compiler.cc:178] Using ptxas at /usr/local/cuda/bin/ptxas`\r\n\r\nSo it seems that when it's looking in cuda-10.1 it's going in the wrong dir (there is no cuda-10.1/bin/bin, the ptxas binary is in cuda-10.1/bin). Does anyone know how to fix this?\r\n\r\nThe situation is somewhat similar to #33375 ",
	"issue_comments": "5"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "706556916",
	"issue_number": "43462",
	"issue_state": "closed",
	"issue_title": "Tensorflow developer certificate",
	"issue_body": "Can we refer some resources like stackover flow(for any errors) or our noted material while taking the exam?",
	"issue_comments": "1"
},
{
	"login": "Saduf2019",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "606961629",
	"issue_number": "38907",
	"issue_state": "closed",
	"issue_title": "%%bash cd models/research/ protoc object_detection/protos/*.proto --python_out= ./object_detection/protos/anchor_generator_pb2.py: Permission denied",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n",
	"issue_comments": "4"
},
{
	"login": "8bitmp3",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "428782374",
	"issue_number": "27463",
	"issue_state": "opened",
	"issue_title": "[TF 2.0 API Docs] tf.keras.Sequential",
	"issue_body": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Sequential\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/sequential.py\r\n\r\n**Describe the documentation issue**\r\n\r\n**- Description:**\r\n\r\nThe order of _Properties_ and _Methods_ is alphabetical, probably by TF doc design. With a large doc for an arguably popular module such as `tf.keras.Sequential` navigating around it may be confusing to the user. Perhaps we should start with the most important ones e.g. `compile` and `fit` under Methods. Since `tf.keras.Sequential`, like many other modules/classes, expands on `keras.Sequential` it would still be logical to list certain Properties, Methods etc in the beginning (at the top of the page) in order of importance for better UX. See: https://keras.io/models/sequential/ as a good example where these are not in alphabetical order.\r\n\r\nAlso, in the beginning after a short intro (\"inherits from `Model`... a linear stack of layers\"), a link to \"Build a Simple Model\" (with `tf.keras.Sequential`) in TensorFlow would be cool for those who are new to `(tf.)Keras`/TF - https://www.tensorflow.org/alpha/guide/keras/overview#sequential_model. Also, the official Keras.io docs include a URL in https://keras.io/models/sequential/ to \"Getting started with the Keras Sequential model\": https://keras.io/getting-started/sequential-model-guide.\r\n\r\n**- Examples:**\r\n\r\nThere already is an example right in the beginning. Maybe adding adding a separate link to or copying an example from this Sequential notebook would be cool too - https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/beginner.ipynb (source: https://www.tensorflow.org/alpha/guide/keras/overview#sequential_model)\r\n\r\n**- Parameters**\r\n\r\nInconsistent. Some reformatting may be needed e.g. input_shape -> `input_shape`. \r\nAlso, both _Arguments_ and _Args_ are used throughout the doc.\r\n\r\n**- Returns, Raises:**\r\n\r\nSometimes exist, sometimes not - creates a UX issue because of inconsistency.\r\n\r\n**- Visuals:**\r\n\r\nA simple one similar to https://www.tensorflow.org/alpha/guide/keras/functional would be appreciated.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nFor sure.",
	"issue_comments": "0"
},
{
	"login": "rrkarim",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "537285030",
	"issue_number": "35073",
	"issue_state": "opened",
	"issue_title": "`tf.vectorized_map` works incorrectly for functions with `tf.stack`",
	"issue_body": "Description of the bug is pretty much in the title, here is the little snippet:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\n\r\ndef log_prob(x):\r\n    x = 0 # we don't care about the input tensor\r\n    final_log_probs = [tf.ones(1)]\r\n    concat_log_probs = tf.stack(final_log_probs, 0)\r\n    return concat_log_probs\r\n\r\nlog_prob(tf.ones(1))\r\nlog_prob = tf.vectorized_map(log_prob, tf.ones(1))\r\n```",
	"issue_comments": "0"
},
{
	"login": "DjangoPeng",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "170782017",
	"issue_number": "3762",
	"issue_state": "opened",
	"issue_title": "PS is bound in GPU:0 by default, we can't change!",
	"issue_body": "I modified the seq2seq , mnist_replica and ptb model into distributed training model. But all of them have the same problem, that is when I start the server and `server.join()` the ps. The ps was bound in GPU:0 by default, and I can't change the setting. I follow the tutorial of distributed tensorflow [here](https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#putting-it-all-together-example-trainer-program). \r\nThis is part of my translate.py :\r\n```\r\ndef train():\r\n\r\n  # set distributed configs\r\n  ps_hosts = [\"9.91.9.130:2222\"]\r\n  worker_hosts = [\"9.91.9.130:2223\", \"9.91.9.130:2224\"]\r\n  #worker_hosts = [\"9.91.9.130:2223\"]\r\n\r\n  cluster = tf.train.ClusterSpec({\"ps\":ps_hosts, \"worker\":worker_hosts})\r\n  server = tf.train.Server(cluster,\r\n                            job_name=FLAGS.job_name,\r\n                            task_index=FLAGS.task_index)\r\n  if FLAGS.job_name == \"ps\":\r\n        server.join()\r\n  elif FLAGS.job_name == \"worker\":\r\n      # Worker server \r\n      is_chief = (FLAGS.task_index == 0)      \r\n      gpu_num = FLAGS.task_index + 1\r\n      #with tf.Graph().as_default():\r\n      with tf.device(tf.train.replica_device_setter(cluster=cluster,\r\n          worker_device=\"/job:worker/task:%d/gpu:%d\" % (FLAGS.task_index, gpu_num))):\r\n      #with tf.device(\"/gpu:%d\" % FLAGS.task_index):\r\n          \"\"\"Train a en->fr translation model using WMT data.\"\"\"\r\n```\r\nThis is the GPU info:\r\n```\r\nFri Aug 12 09:17:07 2016\r\n+------------------------------------------------------+\r\n| NVIDIA-SMI 352.39     Driver Version: 352.39         |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |\r\n| N/A   67C    P0    63W / 149W |  11099MiB / 11519MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |\r\n| N/A   45C    P0    72W / 149W |  10986MiB / 11519MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           On   | 0000:85:00.0     Off |                    0 |\r\n| N/A   76C    P0    66W / 149W |  11049MiB / 11519MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           On   | 0000:86:00.0     Off |                    0 |\r\n| N/A   57C    P0    75W / 149W |    223MiB / 11519MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      9198    C   python                                       10940MiB |\r\n|    0     29865    C   python                                          64MiB |\r\n|    0     29961    C   python                                          64MiB |\r\n|    1      9198    C   python                                          64MiB |\r\n|    1     29865    C   python                                          64MiB |\r\n|    1     29961    C   python                                       10827MiB |\r\n|    2      9198    C   python                                          64MiB |\r\n|    2     29865    C   python                                       10891MiB |\r\n|    2     29961    C   python                                          64MiB |\r\n|    3      9198    C   python                                          64MiB |\r\n|    3     29865    C   python                                          64MiB |\r\n|    3     29961    C   python                                          64MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\nAs you can see, the pid 9198 is the `ps server` process, cause it occupied the GPU:0, I have to bind the `worker server` in GPU:1 and GPU:2.\r\nCould we add a function or API to set the `ps server device` by configuration or arguments?",
	"issue_comments": "0"
},
{
	"login": "npanpaliya",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "171377368",
	"issue_number": "3845",
	"issue_state": "opened",
	"issue_title": "Build fails Tensorflow 0.9, with cuda 8.0 on Ubuntu 16.04, ppc64le",
	"issue_body": "Tensorflow 0.9, with cuda 8.0 fails to build on Ubuntu 16.04 linux ppc64le. Without cuda, it does build successfully. Is this NVIDIA driver issue? Or some eigen issue. Kindly help.\r\n\r\nThe error I get is as below -\r\nexternal/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h(192): internal error: assertion failed at: \"/dvs/p4/build/sw/rel/gpu_drv/r361/r361_00/drivers/compiler/edg/EDG_4.10/src/folding.c\", line 9819\r\n\r\n\r\n1 catastrophic error detected in the compilation of \"/tmp/tmpxft_00020696_00000000-9_cwise_op_gpu_select.cu.compute_52.cpp1.ii\".\r\nCompilation aborted.\r\nAborted\r\nERROR: /home/nishidha/pkgbuild/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:973:1: output 'tensorflow/core/kernels/_objs/cwise_op_gpu/tensorflow/core/kernels/cwise_op_gpu_select.cu.pic.o' was not created.\r\nERROR: /home/nishidha/pkgbuild/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:973:1: not all outputs were created.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04, ppc64le\r\nNVIDIA Driver: 361.78\r\n\r\nInstalled version of CUDA and cuDNN: Cuda 8.0 with cudnn 5.1\r\n$ ls -s /usr/local/cuda/lib64\r\ntotal 1239696\r\n 48080 libcublas_device.a        0 libcufftw.so.8.0            0 libnppc.so.8.0         20320 libnppig.so.8.0.35    10864 libnpps_static.a\r\n     0 libcublas.so            556 libcufftw.so.8.0.35       536 libnppc.so.8.0.35          0 libnppim.so               0 libnvblas.so\r\n     0 libcublas.so.8.0         48 libcufftw_static.a         28 libnppc_static.a           0 libnppim.so.8.0           0 libnvblas.so.8.0\r\n 37884 libcublas.so.8.0.35       0 libcuinj64.so               0 libnppial.so            4296 libnppim.so.8.0.35      584 libnvblas.so.8.0.35\r\n 43936 libcublas_static.a        0 libcuinj64.so.8.0           0 libnppial.so.8.0           0 libnppi.so                0 libnvgraph.so\r\n   552 libcudadevrt.a         5572 libcuinj64.so.8.0.35     9684 libnppial.so.8.0.35        0 libnppi.so.8.0            0 libnvgraph.so.8.0\r\n     0 libcudart.so             36 libculibos.a                0 libnppicc.so          105316 libnppi.so.8.0.35      4568 libnvgraph.so.8.0.35\r\n     0 libcudart.so.8.0          0 libcurand.so                0 libnppicc.so.8.0      131588 libnppi_static.a       6824 libnvgraph_static.a\r\n   464 libcudart.so.8.0.35       0 libcurand.so.8.0         3864 libnppicc.so.8.0.35        0 libnppist.so              0 libnvrtc-builtins.so\r\n   936 libcudart_static.a    57768 libcurand.so.8.0.35         0 libnppicom.so              0 libnppist.so.8.0          0 libnvrtc-builtins.so.8.0\r\n     4 libcudnn5.0.5         57820 libcurand_static.a          0 libnppicom.so.8.0      13860 libnppist.so.8.0.35    9400 libnvrtc-builtins.so.8.0.35\r\n     0 libcudnn.so               0 libcusolver.so           1104 libnppicom.so.8.0.35       0 libnppisu.so              0 libnvrtc.so\r\n     0 libcudnn.so.5             0 libcusolver.so.8.0          0 libnppidei.so              0 libnppisu.so.8.0          0 libnvrtc.so.8.0\r\n 76296 libcudnn.so.5.0.5     50916 libcusolver.so.8.0.35       0 libnppidei.so.8.0        528 libnppisu.so.8.0.35   19380 libnvrtc.so.8.0.34\r\n 67748 libcudnn_static.a     21528 libcusolver_static.a     6912 libnppidei.so.8.0.35       0 libnppitc.so              0 libnvToolsExt.so\r\n     0 libcufft.so               0 libcusparse.so              0 libnppif.so                0 libnppitc.so.8.0          0 libnvToolsExt.so.1\r\n     0 libcufft.so.8.0           0 libcusparse.so.8.0          0 libnppif.so.8.0         2916 libnppitc.so.8.0.35      44 libnvToolsExt.so.1.0.0\r\n143232 libcufft.so.8.0.35    42080 libcusparse.so.8.0.35   46544 libnppif.so.8.0.35         0 libnpps.so                4 stubs\r\n126244 libcufft_static.a     50268 libcusparse_static.a        0 libnppig.so                0 libnpps.so.8.0\r\n     0 libcufftw.so              0 libnppc.so                  0 libnppig.so.8.0         8564 libnpps.so.8.0.35\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`) - v0.9.0 (and cherry-pick two commits - 2c3385523f00ea7de97ec16a7c060b39b834a7f5 and ea9e00a630f91a459dd5858cb22e8cd1a666ba4e)\r\n2. The output of `bazel version` - 0.2.0\r\n\r\n### Steps to reproduce\r\n1. ./configure - Enable GPU support, Cloud Platform support, and rest all with default\r\n2. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### What have you tried?\r\n1. Building without GPU support works.\r\n",
	"issue_comments": "0"
},
{
	"login": "daquexian",
	"repo_name": "Tencent/ncnn",
	"issue_id": "260103733",
	"issue_number": "148",
	"issue_state": "opened",
	"issue_title": "Forward \u65f6\u95ea\u9000\uff0c\u5373\u4f7f\u6574\u4e2a\u7f51\u7edc\u53ea\u6709\u4e00\u5c42\u5377\u79ef",
	"issue_body": "\u4f7f\u7528\u81ea\u5df1\u7684\u7f51\u7edc\uff0c\u62a5\u9519\u4fe1\u606f\uff1a\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 7407 (ent.squeezencnn)\r\n\r\n\u9519\u8bef\u662f `Extractor` \u7684 `extract` \u5f15\u53d1\u7684\u3002\u5373\u4f7f\u628a prototxt \u5168\u780d\u6389\u53ea\u7559\u4e0b\u4e00\u5c42\u5377\u79ef\uff0c\u8fd8\u662f\u4f1a\u62a5\u540c\u6837\u7684\u9519\u8bef\u3002\r\n\r\n\u6709\u6ca1\u6709\u5927\u5927\u77e5\u9053\u8fd9\u662f\u600e\u4e48\u56de\u4e8b0\u30020 \u5341\u5206\u611f\u8c22\uff01",
	"issue_comments": "0"
},
{
	"login": "hamelsmu",
	"repo_name": "fastai/fastai",
	"issue_id": "443730056",
	"issue_number": "2089",
	"issue_state": "opened",
	"issue_title": "Error: attribute not found when trying to load textdatabunch",
	"issue_body": "**Describe the bug**\r\nI'm getting an error that an attribute `pass_through` is not found when loading a language model data bunch.  \r\n\r\n**Provide your installation details**\r\n\r\n\r\n```text\r\n=== Software === \r\npython       : 3.7.3\r\nfastai       : 1.0.52\r\nfastprogress : 0.1.21\r\ntorch        : 1.1.0\r\ntorch cuda   : None / is **Not available** \r\n\r\n=== Hardware === \r\nNo GPUs available \r\n\r\n=== Environment === \r\nplatform     : Linux-3.16.0-4-amd64-x86_64-with-debian-9.9\r\ndistro       : #1 SMP Debian 3.16.51-3 (2017-12-13)\r\nconda env    : Unknown\r\npython       : /usr/local/bin/python\r\nsys.path     : /ds/mdtokenizer/notebooks\r\n/usr/local/lib/python37.zip\r\n/usr/local/lib/python3.7\r\n/usr/local/lib/python3.7/lib-dynload\r\n\r\n/usr/local/lib/python3.7/site-packages\r\n/usr/local/lib/python3.7/site-packages/IPython/extensions\r\n/root/.ipython\r\nno supported gpus found on this system\r\n```\r\n\r\n\r\n**To Reproduce**\r\nFirst, I created a databunch with the following code\r\n\r\n```python\r\ndata_lm = lmdb.from_df(path=path,\r\n                       train_df=train_df,\r\n                       valid_df=valid_df,\r\n                       text_cols='text',\r\n                       tokenizer=tokenizer,\r\n                       chunksize=3000000)\r\n```\r\n\r\nSecond, I saved this databunch\r\n\r\n```python\r\ndata_lm.save() \r\n```\r\n\r\nThird, tried to load data bunch with `load_data`:\r\n```python\r\nfrom fastai.text import load_data\r\ndata_lm = load_data('lang_model/', num_workers=0)\r\n```\r\n\r\nThat returns this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-ba8e7fea8797> in <module>\r\n----> 1 data_lm = load_data('lang_model/', num_workers=0)\r\n\r\n/usr/local/lib/python3.7/site-packages/fastai/basic_data.py in load_data(path, file, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\r\n    275     \"Load a saved `DataBunch` from `path/file`. `file` can be file-like (file or buffer)\"\r\n    276     source = Path(path)/file if is_pathlike(file) else file\r\n--> 277     ll = torch.load(source, map_location='cpu') if defaults.device == torch.device('cpu') else torch.load(source)\r\n    278     return ll.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, dl_tfms=dl_tfms, device=device,\r\n    279                         collate_fn=collate_fn, no_check=no_check, **kwargs)\r\n\r\n/usr/local/lib/python3.7/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)\r\n    385         f = f.open('rb')\r\n    386     try:\r\n--> 387         return _load(f, map_location, pickle_module, **pickle_load_args)\r\n    388     finally:\r\n    389         if new_fd:\r\n\r\n/usr/local/lib/python3.7/site-packages/torch/serialization.py in _load(f, map_location, pickle_module, **pickle_load_args)\r\n    572     unpickler = pickle_module.Unpickler(f, **pickle_load_args)\r\n    573     unpickler.persistent_load = persistent_load\r\n--> 574     result = unpickler.load()\r\n    575 \r\n    576     deserialized_storage_keys = pickle_module.load(f, **pickle_load_args)\r\n\r\nAttributeError: Can't get attribute 'pass_through' on <module '__main__'>\r\n```\r\n\r\n\r\n**Expected behavior**\r\nI'm just trying to load a previously created data bunch.  \r\n",
	"issue_comments": "0"
},
{
	"login": "shoyer",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "155159297",
	"issue_number": "2395",
	"issue_state": "opened",
	"issue_title": "Tensors should have an \"ndim\" property",
	"issue_body": "This is a useful shortcut property on NumPy arrays. In TensorFlow, `tensor.ndim` would be equivalent to `len(tensor.get_shape())`.",
	"issue_comments": "0"
},
{
	"login": "formath",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "260524748",
	"issue_number": "13306",
	"issue_state": "closed",
	"issue_title": "How to set include path and lib path when building custom code on macOS",
	"issue_body": "Firstly, I set CC=/usr/local/bin/gcc-6 and CXX=/usr/local/bin/g++-6. Then I built tensorflow from source using `sh tensorflow/contrib/makefile/build_all_ios.sh` on macOS 10.12.5 and it done successfully. Lastly, I built a test cpp using CMake but it failed. \r\n\r\nThe reasons I guess maybe:\r\n1. Tensorflow built using default clang but not g++-6. So how to set compiler when using `tensorflow/contrib/makefile/build_all_ios.sh`?\r\n2. The include and lib path in CMakeLists.txt may be wrong.\r\n\r\n```\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\nusing namespace tensorflow;\r\nint main(int argc, char* argv[]) {\r\n  // Initialize a tensorflow session\r\n  Session* session;\r\n  Status status = NewSession(SessionOptions(), &session);\r\n  if (!status.ok()) {\r\n    std::cout << status.ToString() << \"\\n\";\r\n    return 1;\r\n  }\r\n  session->Close();\r\n  return 0;\r\n}\r\n```\r\nIn my CMakeLists.txt, I set include path \r\n```\r\n${PROJECT_SOURCE_DIR}/../tensorflow\r\n${PROJECT_SOURCE_DIR}/../tensorflow/tensorflow/contrib/makefile/gen/proto\r\n${PROJECT_SOURCE_DIR}/../tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include\r\n${PROJECT_SOURCE_DIR}/../tensorflow/tensorflow/contrib/makefile/downloads/eigen\r\n${PROJECT_SOURCE_DIR}/../tensorflow/tensorflow/contrib/makefile/downloads/nsync/public\r\n```\r\nand the library path\r\n```\r\nlink_directories(\r\n\t${PROJECT_SOURCE_DIR}/../tensorflow/tensorflow/contrib/makefile/gen/lib/ios_X86_64\r\n\t${PROJECT_SOURCE_DIR}/../tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_x86_64/lib)\r\nset(DEMO_LINKER_LIBS \"\")\r\nlist(APPEND DEMO_LINKER_LIBS libtensorflow-core-x86_64.a libprotobuf-lite.a libprotobuf.a)\r\n```\r\n\r\nCompile ok but errors occur when linking. What's wrong in my use? Thanks.\r\n```\r\nld: warning: URGENT: building for OSX, but linking in object file (/Users/formath/github/tensorflow/tensorflow/contrib/makefile/gen/lib/ios_X86_64/libtensorflow-core-x86_64.a(session.o)) built for iOS. Note: This will be an error in the future.\r\nld: warning: URGENT: building for OSX, but linking in object file (/Users/formath/github/tensorflow/tensorflow/contrib/makefile/gen/lib/ios_X86_64/libtensorflow-core-x86_64.a(config.pb.o)) built for iOS. Note: This will be an error in the future.(/Users/formath/github/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(config.pb.o)) built for iOS. Note: This will be an error in the future.\r\nUndefined symbols for architecture x86_64:\r\n  \"tensorflow::internal::CheckOpMessageBuilder::NewString[abi:cxx11]()\", referenced from:\r\n      std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* tensorflow::internal::MakeCheckOpString<int, int>(int const&, int const&, char const*) in test.cc.o\r\n  \"nsync::nsync_mu_init(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::SessionFactory::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::SessionFactory*) in libtensorflow-core-x86_64.a(session_factory.o)\r\n      tensorflow::SessionFactory::GetFactory(tensorflow::SessionOptions const&, tensorflow::SessionFactory**) in libtensorflow-core-x86_64.a(session_factory.o)\r\n      tensorflow::Env::Env()   in libtensorflow-core-x86_64.a(env.o)\r\n  \"nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::SessionFactory::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::SessionFactory*) in libtensorflow-core-x86_64.a(session_factory.o)\r\n      tensorflow::SessionFactory::GetFactory(tensorflow::SessionOptions const&, tensorflow::SessionFactory**) in libtensorflow-core-x86_64.a(session_factory.o)\r\n      tensorflow::FileSystemRegistryImpl::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::function<tensorflow::FileSystem* ()>) in libtensorflow-core-x86_64.a(env.o)\r\n      tensorflow::FileSystemRegistryImpl::Lookup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-x86_64.a(env.o)\r\n      tensorflow::FileSystemRegistryImpl::GetRegisteredFileSystemSchemes(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) in libtensorflow-core-x86_64.a(env.o)\r\n  \"nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::SessionFactory::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::SessionFactory*) in libtensorflow-core-x86_64.a(session_factory.o)\r\n      tensorflow::SessionFactory::GetFactory(tensorflow::SessionOptions const&, tensorflow::SessionFactory**) in libtensorflow-core-x86_64.a(session_factory.o)\r\n      tensorflow::FileSystemRegistryImpl::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::function<tensorflow::FileSystem* ()>) in libtensorflow-core-x86_64.a(env.o)\r\n      tensorflow::FileSystemRegistryImpl::Lookup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-x86_64.a(env.o)\r\n      tensorflow::FileSystemRegistryImpl::GetRegisteredFileSystemSchemes(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) in libtensorflow-core-x86_64.a(env.o)\r\n  \"tensorflow::Status::ToString[abi:cxx11]() const\", referenced from:\r\n      _main in test.cc.o\r\n  \"std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::at(unsigned long) const\", referenced from:\r\n      google::protobuf::io::Tokenizer::IsIdentifier(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libprotobuf.a(tokenizer.o)\r\n  \"std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::find(char const*, unsigned long, unsigned long) const\", referenced from:\r\n      google::protobuf::GlobalReplaceSubstring(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) in libprotobuf-lite.a(strutil.o)\r\n      tensorflow::str_util::StringReplace(tensorflow::StringPiece, tensorflow::StringPiece, tensorflow::StringPiece, bool) in libtensorflow-core-x86_64.a(str_util.o)\r\n```",
	"issue_comments": "0"
},
{
	"login": "srihari-humbarwadi",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "454121969",
	"issue_number": "29593",
	"issue_state": "closed",
	"issue_title": "tf.estimator.train_and_evaluate fails to print anything (loss/ accuracy) when used with  tf.keras.estimator.model_to_estimator [tf2.0 beta]",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below): 2.0.0-beta0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/ 7.5\r\n- GPU model and memory: 11gb GTX 1080ti\r\n\r\n**Describe the current behavior**\r\nWhen training an estimator which is got from a tf.keras.Model instance, the tf.estimator.train_and_evaluate method fails to log anything on the stdout.\r\n```\r\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\r\n```\r\nHowever, if set the above flag, i can loss being logged (similar to that of API v1)\r\n\r\n```\r\nI0610 16:24:54.069874 140233725445952 basic_session_run_hooks.py:260] loss = 0.9756932, step = 600 (4.162 sec)\r\n```\r\n**Describe the expected behavior**\r\nlog the metrics and loss as described in the official docs\r\n[https://www.tensorflow.org/beta/guide/migration_guide]()\r\n```\r\nW0608 04:37:53.280840 139724414916352 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp4rht4njh W0608 04:37:54.037474 139724414916352 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version. Instructions for updating: Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts. W0608 04:37:58.233872 139724414916352 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating: Use standard file APIs to check for files with this prefix. \r\n({'accuracy': 0.678125, 'global_step': 25, 'loss': 1.4507575}, [])\r\n```\r\n**Code to reproduce the issue**\r\n```\r\nfrom tensorflow.keras.applications.xception import Xception\r\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint('Tensorflow version', tf.__version__)\r\n\r\ndef input_fn(training=False):\r\n    batch_size = 8\r\n    def preprocess_map_func(image, label):\r\n        image = tf.image.resize(image, size=[299, 299])\r\n        image.set_shape([None, None, 3])\r\n        image /=  127.5\r\n        image -= 1\r\n        return image, label\r\n    \r\n    def input_():\r\n        if training:\r\n            dataset = tfds.load(name='cats_vs_dogs', as_supervised=True, split=[\"train\"])[0]\r\n            train_dataset = dataset.skip(3000)\r\n            train_dataset = train_dataset.map(preprocess_map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n            train_dataset = train_dataset.shuffle(1024).batch(batch_size).repeat().prefetch(tf.data.experimental.AUTOTUNE)\r\n            return train_dataset\r\n        else:\r\n            dataset = tfds.load(name='cats_vs_dogs', as_supervised=True, split=[\"train\"])[0]\r\n            test_dataset = dataset.take(3000)\r\n            test_dataset = test_dataset.map(preprocess_map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n            test_dataset = test_dataset.shuffle(1024).batch(batch_size).repeat().prefetch(tf.data.experimental.AUTOTUNE)\r\n            return test_dataset\r\n    return input_\r\n\r\nepochs = 10\r\nsamples = 23000\r\nbatch_size = 8\r\n\r\nbase_model = Xception(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\r\ny = GlobalAveragePooling2D()(base_model.output)\r\ny = Dense(units=1, activation='linear', kernel_initializer='he_normal')(y)\r\nbase_model.trainable = False\r\nmodel = tf.keras.Model(base_model.input, y)\r\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\nestimator = tf.keras.estimator.model_to_estimator(model)\r\ntrain_spec = tf.estimator.TrainSpec(input_fn(training=True), max_steps=epochs * samples//batch_size)\r\neval_spec = tf.estimator.EvalSpec(input_fn(training=False), steps=3000//batch_size)\r\ntf.estimator.train_and_evaluate(estimator, \r\n                                train_spec=train_spec, \r\n                                eval_spec=eval_spec)\r\n\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n",
	"issue_comments": "4"
},
{
	"login": "samdow",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "388838137",
	"issue_number": "24231",
	"issue_state": "opened",
	"issue_title": "Adding Backwards Edge in Tensorflow Java",
	"issue_body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAs we started working with Tensorflow Java, we realized that it isn't yet possible to implement while loops in the graph because we cannot mutate the nodes after they have been created. Therefore, we cannot make a backwards edge to create the loop from the NextIteration node to the Merge node, as seen in [the design of while loops](https://github.com/tensorflow/tensorflow/blob/2a050766bf0556d7d92eea62d40fd2bebbcb399f/tensorflow/cc/ops/while_loop.cc#L148).\r\n\r\n**Will this change the current api? How?**\r\nYes. This will allow the graph to be mutated after a node has been created.\r\n\r\n**Who will benefit with this feature?**\r\nThose who want to use Tensorflow Java to make a while loop or other sorts of loops.\r\n\r\n**Any Other info.**\r\n",
	"issue_comments": "0"
},
{
	"login": "bhadreshpsavani",
	"repo_name": "huggingface/transformers",
	"issue_id": "747265998",
	"issue_number": "8680",
	"issue_state": "opened",
	"issue_title": "Result changes if we don't pass attension mask in TFDistilbert model on SQUADv1 dataset",
	"issue_body": "## Environment info\r\n- `transformers` version: latest\r\n- Platform: Colab\r\n- Python version: \r\n- Tensorflow version (GPU?): 2.3.0\r\n- Using GPU in script?: Yes\r\n- Using distributed or parallel set-up in script?: No\r\n\r\n### Who can help\r\nI used the below code for getting Model\r\n```\r\nfrom transformers import  AutoTokenizer, TFAutoModelForQuestionAnswering\r\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')\r\nmodel =  TFAutoModelForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad', return_dict=True)\r\n```\r\n tokenizers: @mfuntowicz\r\n\r\n Speed and Memory Benchmarks: @patrickvonplaten\r\n examples/seq2seq: @patil-suraj\r\n tensorflow: @jplu \r\n\r\n## Information\r\n\r\nThe model I am using **TFDistilbert** pretrained.\r\n\r\nThe problem arises when using:\r\n* my own modified scripts:\r\nThis is the Notebook\r\n[Colab](https://github.com/bhadreshpsavani/UnderstandingNLP/blob/master/TFLiteExperimentsQALatest.ipynb)\r\n\r\nThe tasks I am working on is:\r\n*  an official SQUaD task\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior: [Colab](https://github.com/bhadreshpsavani/UnderstandingNLP/blob/master/TFLiteExperimentsQALatest.ipynb)\r\n\r\n## Expected behavior\r\n\r\nThe performance should be the same because the Attention mask is the optional argument, if we don't pass it will create it internally. \r\n\r\nWith Attention Mask:\r\n```\r\nOrderedDict([('exact', 77.71050141912077),\r\n           ('f1', 85.5370981182013),\r\n           ('total', 10570)])\r\n```\r\nWithout Attention Mask:\r\n```\r\nOrderedDict([('exact', 72.82876064333927),\r\n             ('f1', 80.71521545953475),\r\n             ('total', 10570)])\r\n```\r\n     \r\n",
	"issue_comments": "0"
},
{
	"login": "imransalam",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "451178165",
	"issue_number": "29317",
	"issue_state": "opened",
	"issue_title": "[TF 2.0 API Docs] tf.identity_n",
	"issue_body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/identity_n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Correct links\r\n\r\nThe path should be href, also the file it refers to does not exists\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined\r\n\r\n### Submit a pull request?\r\n\r\nNo",
	"issue_comments": "0"
},
{
	"login": "FrancescoSaverioZuppichini",
	"repo_name": "open-mmlab/mmdetection",
	"issue_id": "1012120952",
	"issue_number": "6203",
	"issue_state": "opened",
	"issue_title": "Cannot find the eval results in runner.log_buffer.output ",
	"issue_body": "Hi guys, \r\n\r\nI hope you are doing great. I am trying to get the `eval_results` from my custom hook but even if they are set (https://github.com/open-mmlab/mmcv/blob/8cac7c25ee5bc199d6e4059297ef2fa92d9c069c/mmcv/runner/hooks/evaluation.py#L327) in `runner.log_buffer.output` I am not able to find them. I have tried with any time of callbacks in the hooks APIs (after_iter, after_epoch, after_val_epoch, etc) but the `log_buffer` is always empty\r\n\r\n```\r\n@HOOKS.register_module()\r\nclass EarlyStopping(Hook):\r\n    def after_val_epoch(self, runner):\r\n        print(runner.log_buffer.output)\r\n\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nOrderedDict()\r\n```\r\n\r\nWhat is the correct way to properly fetch the eval results?\r\n\r\nThank you",
	"issue_comments": "0"
},
{
	"login": "FrancescoSaverioZuppichini",
	"repo_name": "PyTorchLightning/pytorch-lightning",
	"issue_id": "689984227",
	"issue_number": "3302",
	"issue_state": "opened",
	"issue_title": "Trainer doesn't load the model when .test",
	"issue_body": "Dear all,\r\n\r\nI have a trainer \r\n\r\n```python\r\n\r\nimport torch\r\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\r\nfrom pytorch_lightning import LightningModule\r\nfrom torch.nn import functional as F\r\nfrom pytorch_lightning.metrics.functional import accuracy, f1_score, auroc\r\n\r\n\r\nclass TraversabilityModule(LightningModule):\r\n\r\n    def __init__(self, model: torch.nn.Module):\r\n        super().__init__()\r\n        self.model = model\r\n\r\n    def forward(self, x):\r\n        return self.model(x)\r\n\r\n    def get_metrics(self, pred, y):\r\n        return {\r\n            'accuracy': accuracy(pred, y, num_classes=2),\r\n            'f1': f1_score(pred, y, num_classes=2),\r\n            # 'roc_auc': auroc(pred, y)\r\n        }\r\n\r\n    def step(self, batch, batch_idx):\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        pred = torch.argmax(y_hat, dim=1)\r\n        metrics = self.get_metrics(pred, y)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        return loss, metrics\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        loss, metrics = self.step(batch, batch_idx)\r\n        return {'loss': loss, 'log': metrics }\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        loss, metrics = self.step(batch, batch_idx)\r\n        return {'val_loss': loss, 'log': metrics }\r\n\r\n    def validation_epoch_end(self, outputs):\r\n        val_loss_mean = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        acc_mean = torch.stack([x['log']['accuracy'] for x in outputs]).mean()\r\n        f1_mean = torch.stack([x['log']['f1'] for x in outputs]).mean()\r\n        # roc_auc_mean = torch.stack([x['log']['roc_auc'] for x in outputs]).mean()\r\n\r\n        return {\r\n            'val_loss': val_loss_mean,\r\n            'val_f1': f1_mean,\r\n            'progress_bar': {'f1': f1_mean},\r\n            'log': {\r\n                'val_accuracy': acc_mean,\r\n                'val_f1': f1_mean,\r\n                # 'roc_auc': roc_auc_mean\r\n                \r\n                }\r\n            }\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        loss, metrics = self.step(batch, batch_idx)\r\n        return {'test_loss': loss, 'log': metrics}\r\n\r\n    def test_epoch_end(self, outputs):\r\n        val_loss_mean = torch.stack([x['test_loss'] for x in outputs]).mean()\r\n        acc_mean = torch.stack([x['log']['accuracy'] for x in outputs]).mean()\r\n        f1_mean = torch.stack([x['log']['f1'] for x in outputs]).mean()\r\n        # roc_auc_mean = torch.stack([x['log']['roc_auc'] for x in outputs]).mean()\r\n\r\n        return {\r\n            'test_loss': val_loss_mean,\r\n            'test_f1': f1_mean,\r\n            'progress_bar': {'f1': f1_mean},\r\n            'log': {\r\n                'test_accuracy': acc_mean,\r\n                'test_f1': f1_mean,\r\n                # 'roc_auc': roc_auc_mean\r\n                \r\n                }\r\n            }\r\n\r\n    def configure_optimizers(self):\r\n        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\r\n        scheduler = {'scheduler': ReduceLROnPlateau(optimizer, verbose=True),\r\n                     'monitor': 'val_f1'}\r\n\r\n        return [optimizer], [scheduler]\r\n\r\n```\r\n\r\nAnd I have a training loop\r\n\r\n```python\r\nmodule = TraversabilityModule(model)\r\n\r\n    trainer = pl.Trainer(\r\n        gpus=1,\r\n        max_epochs=params['epoches'],\r\n        logger=comet_logger,\r\n        checkpoint_callback=ModelCheckpoint(\r\n            monitor='val_f1',\r\n            filepath=project.checkpoint_dir / params['model'] / 'model',\r\n            ),\r\n        early_stop_callback=EarlyStopping(monitor='val_f1',\r\n                                          patience=15))\r\n    trainer.fit(module, train_dl, val_dl)\r\n    \r\n    trainer.test(test_dataloaders=test_dl)\r\n```\r\nI get the following error when I try to validate the test set (at `trainer.test`)\r\n\r\n```\r\nRuntimeError: Error(s) in loading state_dict for TraversabilityModule:\r\n        Unexpected key(s) in state_dict: \"model.encoder.gate.0.weight\", \"model.encoder.gate.1.weight\", \"model.encoder.gate.1.bias\", \"model.encoder.gate.1.running_mean\", \"model.encoder.gate.1.running_var\", \"model.encoder.gate.1.num_batches_tracked\", \"model.encoder.layers.0.layer.0.shortcut.0.weight\", \"model.encoder.layers.0.layer.0.shortcut.1.weight\", \"model.encoder.layers.0.layer.0.shortcut.1.bias\", \"model.encoder.layers.0.layer.0.shortcut.1.running_mean\", \"model.encoder.layers.0.layer.0.shortcut.1.running_var\", \"model.encoder.layers.0.layer.0.shortcut.1.num_batches_tracked\", \"model.encoder.layers.0.layer.0.convs.0.weight\", \"model.encoder.layers.0.layer.0.convs.0.bias\", \"model.encoder.layers.0.layer.0.convs.0.running_mean\", \"model.encoder.layers.0.layer.0.convs.0.running_var\", \"model.encoder.layers.0.layer.0.convs.0.num_batches_tracked\", \"model.encoder.layers.0.layer.0.convs.2.weight\", \"model.encoder.layers.0.layer.0.convs.3.weight\", \"model.encoder.layers.0.layer.0.convs.3.bias\", \"model.encoder.layers.0.layer.0.convs.3.running_mean\", \"model.encoder.layers.0.layer.0.convs.3.running_var\", \"model.encoder.layers.0.layer.0.convs.3.num_batches_tracked\", \"model.encoder.layers.0.layer.0.convs.5.weight\", \"model.encoder.layers.0.layer.0.se.se.0.weight\", \"model.encoder.layers.0.layer.0.se.se.0.bias\", \"model.encoder.layers.0.layer.0.se.se.2.weight\", \"model.encoder.layers.0.layer.0.se.se.2.bias\", \"model.encoder.layers.1.layer.0.shortcut.0.weight\", \"model.encoder.layers.1.layer.0.shortcut.1.weight\", \"model.encoder.layers.1.layer.0.shortcut.1.bias\", \"model.encoder.layers.1.layer.0.shortcut.1.running_mean\", \"model.encoder.layers.1.layer.0.shortcut.1.running_var\", \"model.encoder.layers.1.layer.0.shortcut.1.num_batches_tracked\", \"model.encoder.layers.1.layer.0.convs.0.weight\", \"model.encoder.layers.1.layer.0.convs.0.bias\", \"model.encoder.layers.1.layer.0.convs.0.running_mean\", \"model.encoder.layers.1.layer.0.convs.0.running_var\", \"model.encoder.layers.1.layer.0.convs.0.num_batches_tracked\", \"model.encoder.layers.1.layer.0.convs.2.weight\", \"model.encoder.layers.1.layer.0.convs.3.weight\", \"model.encoder.layers.1.layer.0.convs.3.bias\", \"model.encoder.layers.1.layer.0.convs.3.running_mean\", \"model.encoder.layers.1.layer.0.convs.3.running_var\", \"model.encoder.layers.1.layer.0.convs.3.num_batches_tracked\", \"model.encoder.layers.1.layer.0.convs.5.weight\", \"model.encoder.layers.1.layer.0.se.se.0.weight\", \"model.encoder.layers.1.layer.0.se.se.0.bias\", \"model.encoder.layers.1.layer.0.se.se.2.weight\", \"model.encoder.layers.1.layer.0.se.se.2.bias\", \"model.encoder.layers.2.layer.0.shortcut.0.weight\", \"model.encoder.layers.2.layer.0.shortcut.1.weight\", \"model.encoder.layers.2.layer.0.shortcut.1.bias\", \"model.encoder.layers.2.layer.0.shortcut.1.running_mean\", \"model.encoder.layers.2.layer.0.shortcut.1.running_var\", \"model.encoder.layers.2.layer.0.shortcut.1.num_batches_tracked\", \"model.encoder.layers.2.layer.0.convs.0.weight\", \"model.encoder.layers.2.layer.0.convs.0.bias\", \"model.encoder.layers.2.layer.0.convs.0.running_mean\", \"model.encoder.layers.2.layer.0.convs.0.running_var\", \"model.encoder.layers.2.layer.0.convs.0.num_batches_tracked\", \"model.encoder.layers.2.layer.0.convs.2.weight\", \"model.encoder.layers.2.layer.0.convs.3.weight\", \"model.encoder.layers.2.layer.0.convs.3.bias\", \"model.encoder.layers.2.layer.0.convs.3.running_mean\", \"model.encoder.layers.2.layer.0.convs.3.running_var\", \"model.encoder.layers.2.layer.0.convs.3.num_batches_tracked\", \"model.encoder.layers.2.layer.0.convs.5.weight\", \"model.encoder.layers.2.layer.0.se.se.0.weight\", \"model.encoder.layers.2.layer.0.se.se.0.bias\", \"model.encoder.layers.2.layer.0.se.se.2.weight\", \"model.encoder.layers.2.layer.0.se.se.2.bias\", \"model.decoder.decoder.weight\", \"model.decoder.decoder.bias\". \r\n```\r\nThey are clearly the weights in my model (a variant of ResNet). The model path exists and the model is stored there.\r\n\r\nThank you.\r\n\r\nBest Regards,\r\n\r\nFrancesco",
	"issue_comments": "0"
},
{
	"login": "PhilipMay",
	"repo_name": "keras-team/keras",
	"issue_id": "332673347",
	"issue_number": "10446",
	"issue_state": "opened",
	"issue_title": "Small error in Documentation (multiple outputs -> multiple inputs)",
	"issue_body": "I think this should be changed from \"multiple outputs\" to \"multiple inputs\".\r\n\r\nhttps://github.com/keras-team/keras/blob/2d183db0372e5ac2a686608cb9da0a9bd4319764/keras/engine/training.py#L1128",
	"issue_comments": "0"
},
{
	"login": "zuoxingdong",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "163688325",
	"issue_number": "3185",
	"issue_state": "opened",
	"issue_title": "Udacity Notebook with \"None\" kernel",
	"issue_body": "I use Jupyter notebook to open the .ipynb files, but it shows a red \"None\" kernel on top right corner and all lines of code cannot run. \r\n\r\nMethod I use:\r\n1. Build a new directory and extract .ipynb files from `examples/udacity` to the directory\r\n2. In terminal, run `jupyter notebook`",
	"issue_comments": "0"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "375358136",
	"issue_number": "23368",
	"issue_state": "closed",
	"issue_title": "tensorflow\\contrib\\coder\\python\\ops\\_coder_ops.so not found",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nsample from matterport/maskrcnn\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10 x64\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):\r\nconda list\r\ntensorflow-gpu            1.10.0                   py36_0    aaronzs\r\ntensorflow-gpu            1.11.0                    <pip>\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nb'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\r\n- Python version:3.6.7\r\n- CUDA/cuDNN version:9.0/7.1.4\r\n- GPU model and memory:GeForce GTX 1060 3GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI tired to train a sample in the project from [https://github.com/matterport/Mask_RCNN](url)\r\nthen there is an error showed up.\r\nI tried the basic functions of tensorflow like session they works fine.\r\nbut when I used train something about DLL showed up\r\nit said that it can't find something like program input  \"? MakeShape@TensorShapeUtils@tensorflow@@SA?AVStatus@2@V?$Span@$$CBH@absl@@PEAVTensorShape@2@@Z(in DLL C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops_coder_ops.so)\"\r\n**Describe the expected behavior**\r\nthere should be no error \r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nthere is no error until this line\r\n`train(model)`\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nLoading weights  C:\\HSIR\\Mask_RCNN\\mask_rcnn_coco.h5\r\n2018-10-30 15:35:55.918873: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-10-30 15:35:56.255762: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties:\r\nname: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.759\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 3.00GiB freeMemory: 2.42GiB\r\n2018-10-30 15:35:56.255976: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-10-30 15:35:56.948830: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-30 15:35:56.948953: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0\r\n2018-10-30 15:35:56.953167: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N\r\n2018-10-30 15:35:56.954126: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2125 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraining network heads\r\nTraceback (most recent call last):\r\n  File \"balloon.py\", line 364, in <module>\r\n    train(model)\r\n  File \"balloon.py\", line 199, in train\r\n    layers='heads')\r\n  File \"C:\\HSIR\\Mask_RCNN\\mrcnn\\model.py\", line 2341, in train\r\n    histogram_freq=0, write_graph=True, write_images=False),\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\keras\\callbacks.py\", line 745, in __init__\r\n    from tensorflow.contrib.tensorboard.plugins import projector\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 31, in <module>\r\n    from tensorflow.contrib import coder\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\coder\\__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.coder.python.layers.entropybottleneck import *\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\layers\\entropybottleneck.py\", line 24, in <module>\r\n    from tensorflow.contrib.coder.python.ops import coder_ops\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops\\coder_ops.py\", line 30, in <module>\r\n    resource_loader.get_path_to_datafile(\"_coder_ops.so\"))\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\util\\loader.py\", line 56, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py\", line 56, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: C:\\Users\\willy_sung\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\contrib\\coder\\python\\ops\\_coder_ops.so not found",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "377030443",
	"issue_number": "23474",
	"issue_state": "closed",
	"issue_title": "how can i solve this issue on importing tensorflow in linux?",
	"issue_body": ">\r\n\r\n****System information****\r\n- OS Platform and Distribution: (Linux Ubuntu 18.04):\r\n- M device (e.HP-proBook) .\r\n- Tensor-flow installed by running on terminal \r\npip3 install --upgrade tensorflow-gpu\r\n- TensorFlow version:\r\n- Python version:3.6.6\r\n- Installed using pip.\r\n -I dont have a CUDA/cuDNN version but  Intelhaswall.\r\n- GPU model :Intel\u00ae Haswell Mobile\r\n-memory:7.7 Gi\r\n**the problem is :** \r\nI cant install and using tensor flow or numpy for object detection algorithms.\r\nI don't know how can i install virtualenv.\r\nI run on terminal\r\n$sudo apt install python-pip python3-pip      \r\n$pip3 install --upgrade tensorflow \r\nthe tensor flow already installed \r\nbut ,,when i run \r\n$python3\r\nand import tensorflow the error was \r\n![screenshot from 2018-11-03 09-05-52](https://user-images.githubusercontent.com/44716923/47949282-f708f980-df48-11e8-9032-98813b6a8767.png)\r\n\r\n\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n______________________________________________________________________\r\n\r\n**Any other info / logs**\r\ni dont want to use a black-screen !!! to type a command i want to clone a codes and running it from a GitHub,starting coding .. somone advice me to setup \r\n",
	"issue_comments": "3"
},
{
	"login": "ymodak",
	"repo_name": "keras-team/keras",
	"issue_id": "355152782",
	"issue_number": "11023",
	"issue_state": "closed",
	"issue_title": "Cannot load_model",
	"issue_body": "Thank you!\r\n\r\n- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:\r\npip install git+git://github.com/keras-team/keras.git --upgrade --no-deps\r\n\r\n- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).\r\n\r\n- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:\r\npip install git+git://github.com/Theano/Theano.git --upgrade --no-deps\r\n\r\n- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\r\n\r\nI am using Google Colab to train a CNN and then save the entire model to a `.h5` file. The code is available here: [CNN-Colab](https://gist.github.com/abhisheksoni27/184c49ca703eb124e1b17eb8dd8af518)\r\n\r\nThe model gets saved but when I later try to load it back, I get the following error:\r\n\r\n```\r\nTypeError: float() argument must be a string or a number, not 'dict'\r\n```\r\n\r\nThe entire Output log is here: [CNN - Colab - Error](https://gist.github.com/abhisheksoni27/732bec240629d2dd721e80130cb2956b)\r\n",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "361635811",
	"issue_number": "22374",
	"issue_state": "closed",
	"issue_title": "*** stack smashing detected ***: <unknown> terminated \u5df2\u653e\u5f03 (\u6838\u5fc3\u5df2\u8f6c\u50a8)",
	"issue_body": "## describe problems\uff1a\r\n1. ubuntu 18.04 cmake\r\n2. c++ with libtensorflow_cc.so\r\n3. I can compile my code,but when I run it,the error is \"*** stack smashing detected ***: <unknown> terminated \u5df2\u653e\u5f03 (\u6838\u5fc3\u5df2\u8f6c\u50a8)\"\r\n\r\n## code\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n\r\nusing namespace std;\r\nusing namespace chrono;\r\nusing namespace tensorflow;\r\nint main(int argc, char* argv[]) {\r\n  // SessionOptions options;\r\n  // std::unique_ptr<tensorflow::Session> session(tensorflow::NewSession(options));\r\n  Session *session = NewSession(SessionOptions());\r\n  if(session == nullptr)\r\n  {\r\n    throw runtime_error(\"Could not create tensorflow session\");\r\n  }\r\n  session->Close();\r\n  return 0;\r\n}\r\n## So, what should I do?Thank you!",
	"issue_comments": "3"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "362455201",
	"issue_number": "22433",
	"issue_state": "closed",
	"issue_title": "train_op given in estimator spec raising error while given with distribution strategy",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.5.2\r\n- **CUDA/cuDNN version**: CuDA 9 and CuDNN 7\r\n- **GPU model and memory**: K1100M Quadro, 2 GB\r\n\r\n### Describe the problem\r\nWhile training simple mnist model with estimator, if the loss function is given to the optimiser for minimisation, the following error is reproduced.\r\n\r\n### Source code / logs\r\nFile \"D:/Userdata/Software/FullModelSeparate/train.py\", line 62, in <module>\r\n    tf.estimator.train_and_evaluate(mnist_est,train_spec=train_spec,eval_spec=eval_spec)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 447, in train_and_evaluate\r\n    return executor.run()\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 531, in run\r\n    return self.run_local()\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 669, in run_local\r\n    hooks=train_hooks)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 366, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1117, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1160, in _train_model_distributed\r\n    self.config)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\training\\distribute.py\", line 794, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\contrib\\distribute\\python\\one_device_strategy.py\", line 77, in _call_for_each_tower\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1107, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"D:\\Userdata\\Software\\FullModelSeparate\\ModelToEstimator.py\", line 110, in convert\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=apply_gradient_op)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\model_fn.py\", line 184, in __new__\r\n    _check_is_tensor_or_operation(train_op, 'train_op')\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\model_fn.py\", line 390, in _check_is_tensor_or_operation\r\n    raise TypeError('{} must be Operation or Tensor, given: {}'.format(name, x))\r\nTypeError: train_op must be Operation or Tensor, given: <tf.Variable 'global_step:0' shape=() dtype=int64>\r\n",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "keras-team/keras",
	"issue_id": "258740783",
	"issue_number": "7925",
	"issue_state": "closed",
	"issue_title": "examples/mnist_tfrecord.py throws OutOfRangeError for enqueue_many=False",
	"issue_body": "\r\nInstead of this code\r\n```\r\ndata = mnist.load_mnist()\r\n\r\nx_train_batch, y_train_batch = tf.train.shuffle_batch(\r\n    tensors=[data.train.images, data.train.labels.astype(np.int32)],\r\n    batch_size=batch_size,\r\n    capacity=capacity,\r\n    min_after_dequeue=min_after_dequeue,\r\n    enqueue_many=enqueue_many,\r\n    num_threads=8)\r\n```\r\nI'm using this code\r\n\r\n```\r\ndef read_and_decode(filename_queue):\r\n    reader = tf.TFRecordReader()\r\n    _, serialized_example = reader.read(filename_queue)\r\n\r\n    features = tf.parse_single_example(\r\n        serialized_example,\r\n        features={\r\n            'label': tf.FixedLenFeature([8], tf.int64),\r\n            'image': tf.FixedLenFeature([150528], tf.float32)\r\n        })\r\n    label = features['label'][1:]\r\n    image = features['image']\r\n    image = tf.reshape(image, [224, 224, 3])\r\n    image = tf.cast(image, tf.float32) / 255\r\n\r\n    return image, label\r\n\r\nfilename_list = glob.glob(os.path.join(train_dir, '*.tfrecords'))\r\nfilename_queue = tf.train.string_input_producer(filename_list, num_epochs=epochs)\r\nimage, label = read_and_decode(filename_queue)\r\n\r\nx_train_batch, y_train_batch = tf.train.shuffle_batch(\r\n[image, label],\r\nbatch_size=batch_size,\r\nnum_threads=8,\r\ncapacity=2000 + 3 * batch_size,\r\nmin_after_dequeue=2000,\r\nenqueue_many=False)`\r\n```\r\n\r\n\r\nThe rest of the code remains the same.\r\n\r\nError-\r\n```\r\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 128, current size 0)\r\n         [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\r\n```\r\n\r\nI am missing something but don't know what.",
	"issue_comments": "1"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "363093207",
	"issue_number": "22479",
	"issue_state": "closed",
	"issue_title": "Keras: removing layers with model.layers.pop() doesn't work",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Colab\r\n- **TensorFlow version (use command below)**:  1.10.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: Colab\r\n- **GCC/Compiler version (if compiling from source)**: Colab\r\n- **CUDA/cuDNN version**: Colab\r\n- **GPU model and memory**: Colab\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen we delete a layer with model.layers.pop(), the deleted layer reappears. \r\n\r\n### Source code / logs\r\n\r\n    import tensorflow as tf\r\n    import tensorflow.keras as keras\r\n    import tensorflow.keras.backend as K\r\n    from tensorflow.keras.layers import Dense, Input, Layer\r\n    from tensorflow.keras.models import Model\r\n    input_tensor = Input(shape=(10,))\r\n    hidden = Dense(100, activation='relu')(input_tensor)\r\n    out = Dense(10, activation='relu')(hidden)\r\n    model = Model(input_tensor, out)\r\n    model.compile(loss=\"mse\", optimizer=tf.train.AdamOptimizer(learning_rate=0.001))\r\n    model.summary()\r\n    model.layers.pop()\r\n    model.layers.pop()\r\n    model.summary()\r\n    hidden = Dense(120, activation='relu')(model.layers[-1].output)\r\n    out = Dense(5, activation='softmax')(hidden)\r\n    model = Model(input_tensor, out)\r\n    model.summary()\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         (None, 10)                0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 100)               1100      \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 10)                1010      \r\n=================================================================\r\nTotal params: 2,110\r\nTrainable params: 2,110\r\nNon-trainable params: 0\r\n```\r\n```\r\n_________________________________________________________________\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         (None, 10)                0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 100)               1100      \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 10)                1010      \r\n=================================================================\r\nTotal params: 2,110\r\nTrainable params: 2,110\r\nNon-trainable params: 0\r\n\r\n```\r\n\r\n```\r\n_________________________________________________________________\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         (None, 10)                0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 100)               1100      \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 10)                1010      \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 120)               1320      \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 5)                 605       \r\n=================================================================\r\nTotal params: 4,035\r\nTrainable params: 4,035\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```",
	"issue_comments": "5"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "119554165",
	"issue_number": "378",
	"issue_state": "closed",
	"issue_title": "matmul gradients incorrect with complex64 tensors",
	"issue_body": "The conjugation step was skipped.\nSee  https://tensorflow-review.googlesource.com/#/c/1154/ for unit tests and a fix\n",
	"issue_comments": "12"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "367711834",
	"issue_number": "22816",
	"issue_state": "closed",
	"issue_title": "The usage of CUDA_VISIBLE_DEVICES.",
	"issue_body": "I cannot figure out an ambigious definition of the env variable \"CUDA_VISIBLE_DEVICES\". As we know, the command `export CUDA_VISIBLE_DEVICES = 0`  means that we can only find the GPU:0. However, what's the defination of the command `export CUDA_VISIBLE_DEVICES = '' `? It means that we can either find all gpus or mask all gpus in our system?\r\n\r\nAnd another odd thing is that I am running a BiLSTM-CRF model to do some NER tasks with a 8-gpu server. Without using the command `export CUDA_VISIBLE_DEVICES = '' `, the model runs a bit slower than expected, and we can see the program running with all 8 gpus through the command `nvidia-smi`. However, the model runs extremely faster than before when I use the command `export CUDA_VISIBLE_DEVICES = '' `, in addition, I cannot find any program information with `nvidia-smi`. \r\n\r\nDid I run the model with CPU? But the CPU usage changed only a little. And there seems no posibility that the CPU runs extremely faster than GPU under BiLSTM-CRF model. What's the matter?  If any information is needed, I'll update later cuz I don't know what information to display now.",
	"issue_comments": "1"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "368927416",
	"issue_number": "22880",
	"issue_state": "closed",
	"issue_title": "how to get  \u201ctf. fake_quant_with_min_max_args\u201d  by  API  \"tf.keras\"",
	"issue_body": "I want to quantize a h5 model, but i can't find \u201ctf. fake_quant_with_min_max_args\u201d  by   API tf.keras  ",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "386071913",
	"issue_number": "24063",
	"issue_state": "closed",
	"issue_title": "cann't import tensorflow-gpu 1.12 on windows",
	"issue_body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "377197992",
	"issue_number": "23505",
	"issue_state": "closed",
	"issue_title": "Facing this error",
	"issue_body": "2018-11-04 14:31:10.477036: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\nGPU mode with 1.0 usage\r\n2018-11-04 14:31:11.087112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \r\nname: GeForce GTX 745 major: 5 minor: 0 memoryClockRate(GHz): 1.0325\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.36GiB\r\n2018-11-04 14:31:11.087670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-11-04 14:31:12.174849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-04 14:31:12.175138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-11-04 14:31:12.175377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-11-04 14:31:12.175722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory) -> physical GPU (device: 0, name: GeForce GTX 745, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2018-11-04 14:31:12.177136: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 4.00G (4294967296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2018-11-04 14:31:12.177430: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 3.60G (3865470464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\nFinished in 15.694188356399536s\r\n\r\n2018-11-04 14:31:24.869864: E tensorflow/stream_executor/cuda/cuda_dnn.cc:353] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n[Finished in 30.221s]\r\n<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: conda install -c aaronzs tensorflow-gpu\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 9.0 and cuDNN7.0.5 \r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "keras-team/keras",
	"issue_id": "243646935",
	"issue_number": "7369",
	"issue_state": "closed",
	"issue_title": "Keras callbacks Tensorboard multi-output Error",
	"issue_body": "Here on suggestion of stackoverflow.com user's answer. https://stackoverflow.com/questions/45020361/keras-callbacks-tensorboard-multi-output-error\r\n\r\nI can't figure out what is causing this error for multi-output Keras Model when using callbacks.TensorBoard.\r\n\r\n```\r\ntbCallBack = keras.callbacks.TensorBoard(log_dir = logdir, histogram_freq = 1, write_graph = 1, write_images = 0, write_grads = 1)\r\n###No errror when not using callbacks\r\nregr.fit(  Ax_train, [Ay_train_p, Ay_train_s], validation_data= (Ax_test, [Ay_test_p, Ay_test_s]), epochs = 500, batch_size = 10, verbose = 1)\r\n###No errror when not using validation_data\r\nregr.fit(  Ax_train, [Ay_train_p, Ay_train_s], epochs = 500, batch_size = 10, verbose = 1, callbacks=[tbCallBack])\r\n###Error Occurred\r\nregr.fit( Ax_train, [Ay_train_p, Ay_train_s], validation_data= (Ax_test, [Ay_test_p, Ay_test_s]), epochs = 500, batch_size = 10, verbose = 1, callbacks=[tbCallBack])\r\n```\r\n\r\nError\r\n\r\n```\r\nEpoch 1/500\r\n1280/1663 [======================>.......] - ETA: 0s - loss: 1.6230 - output_power_loss: 0.9627 - output_slack_loss: 0.66032017-07-11 03:17:27.964542: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1] has negative dimensions\r\n2017-07-11 03:17:27.964589: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1] has negative dimensions\r\n     [[Node: output_slack_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n2017-07-11 03:17:27.970690: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1] has negative dimensions\r\n2017-07-11 03:17:27.970735: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1] has negative dimensions\r\n     [[Node: output_power_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n2017-07-11 03:17:27.972004: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1] has negative dimensions\r\n2017-07-11 03:17:27.972026: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1] has negative dimensions\r\n     [[Node: output_power_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\nTraceback (most recent call last):\r\n  File \"tf_keras.py\", line 183, in <module>\r\n    regr.fit( Ax_train, [Ay_train_p, Ay_train_s], validation_data= (Ax_test, [Ay_test_p, Ay_test_s]), epochs = 500, batch_size = 10, verbose = 1, callbacks=[tbCallBack])\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/keras/engine/training.py\", line 1507, in fit\r\n    initial_epoch=initial_epoch)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/keras/engine/training.py\", line 1176, in _fit_loop\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/keras/callbacks.py\", line 77, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/keras/callbacks.py\", line 768, in on_epoch_end\r\n    result = self.sess.run([self.merged], feed_dict=feed_dict)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 997, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape [-1] has negative dimensions\r\n     [[Node: output_power_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'output_power_sample_weights', defined at:\r\n  File \"tf_keras.py\", line 180, in <module>\r\n    regr = nn_model()\r\n  File \"tf_keras.py\", line 177, in nn_model\r\n    model.compile(optimizer = 'adam', loss ={'output_power': 'mean_squared_error', 'output_slack': 'binary_crossentropy'})\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/keras/engine/training.py\", line 870, in compile\r\n    name=name + '_sample_weights'))\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 431, in placeholder\r\n    x = tf.placeholder(dtype, shape=shape, name=name)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\r\n    name=name)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/roy/keras_tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Shape [-1] has negative dimensions\r\n     [[Node: output_power_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nWhat does \"Shape [-1] has negative dimensions\" means? I had also tried with each output with callbacks.Tensorboard and there wasn't any error occurred. Also search with \"Node: output_power_sample_weights\" but no results.\r\n\r\n```\r\nregr.summary()\r\n```\r\n____________________________________________________________________________________________________\r\nLayer (type)                     Output Shape          Param #     Connected to                     \r\n====================================================================================================\r\nmain_input (InputLayer)          (None, 5)             0                                            \r\n____________________________________________________________________________________________________\r\nHidden (Dense)                   (None, 5)             30          main_input[0][0]                 \r\n____________________________________________________________________________________________________\r\noutput_power (Dense)             (None, 1)             6           Hidden[0][0]                     \r\n____________________________________________________________________________________________________\r\noutput_slack (Dense)             (None, 1)             6           Hidden[0][0]                     \r\n====================================================================================================\r\nTotal params: 42\r\nTrainable params: 42\r\nNon-trainable params: 0\r\n```\r\n\r\n\r\nThank you!\r\n\r\n- [/ ] Check that you are up-to-date with the master branch of Keras. You can update with:\r\npip install git+git://github.com/fchollet/keras.git --upgrade --no-deps\r\n\r\n- [ /] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).\r\n\r\n- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:\r\npip install git+git://github.com/Theano/Theano.git --upgrade --no-deps\r\n\r\n- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\r\n",
	"issue_comments": "6"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "374611209",
	"issue_number": "23311",
	"issue_state": "closed",
	"issue_title": "Hey. Just saw that the vocabulary size is a parameter you have to define manually? Seems not very intuitive for me as it can be computed automatically.",
	"issue_body": "_Originally posted by @b-3-n in https://github.com/tensorflow/tensorflow/issues/2734#issuecomment-224732629_",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "370597270",
	"issue_number": "23023",
	"issue_state": "closed",
	"issue_title": "Hyperspectral image classification using tensorflow",
	"issue_body": "\r\nDelivery Status Notification (Failure)Application toolbar\r\nMessage Body\r\nHello sandeep.ladi@gitam.edu,\r\n\r\nWe're writing to let you know that the group you tried to contact (discuss) may not exist, or you may not have permission to post messages to the group. A few more details on why you weren't able to post:\r\n\r\n * You might have spelled or formatted the group name incorrectly.\r\n * The owner of the group may have removed this group.\r\n * You may need to join the group before receiving permission to post.\r\n * This group may not be open to posting.\r\n\r\nIf you have questions related to this or any other Google Group, visit the Help Center at https://support.google.com/a/tensorflow.org/bin/topic.py?topic=25838.\r\n\r\nThanks,\r\n\r\ntensorflow.org admins\r\n\r\n\r\n\r\n----- Original message -----\r\n\r\nX-Google-Smtp-Source: ACcGV625ngDxZGFv6zxaJTNRD5PlUDFyJNQJK/RowOuC79uaJbT7E4TVqkiThwkQIV8Yc/WPsFZ0\r\nX-Received: by 2002:a5d:44ce:: with SMTP id z14-v6mr19096788wrr.286.1539685981354;\r\n        Tue, 16 Oct 2018 03:33:01 -0700 (PDT)\r\nARC-Seal: i=1; a=rsa-sha256; t=1539685981; cv=none;\r\n        d=google.com; s=arc-20160816;\r\n        b=E/S3lH6dW8jBpv80GEP3mZyz1KyIDntxI9nZGVOdAbeJS3yOgQ3nq4bp7hre3N/HU8\r\n         9HqA9XkD3dHukXpz06r+2R5F3i2Rbio9TsIfnjdh9b454Ps75DUM7gm1nuxEGojtfeZd\r\n         2RKUTWWKH3a/1dOWecoz0fRibWJd0ByhBNTYW2F+p9hMdg9TAP3m9nuxpLl/bF/r/VAw\r\n         62gIT4ydaIgySfEH6uXHh5dYAab8+96sPnw5wZiAHzO1LpUt766K85dv/6asxCHoMMOR\r\n         M5lzAq1FK+XOfca7bJqn7lt2Vu2YIU7wJbIJs2vQKtLwZcl7SYf20rkFeVGrNQ4zmonY\r\n         zuwg==\r\nARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;\r\n        h=user-agent:message-id:disposition-notification-to:return-receipt-to\r\n         :subject:to:from:date:mime-version;\r\n        bh=OsFzSe3J2uxfPu0m4Xtt3CiGAfo46dWIPdy+i82VhII=;\r\n        b=ePJSnFaP1g6RcKwXYOLK4F+lXEJ8Ul1ycwocH3iAPT6Ga19fNe5HJXhaFcbexJywfr\r\n         G+86clKs6GOA2baW3nqnAl/4rAVGMjQyWIUMBPFHdei28lIjvMo3gyXX3ocxM0XMPP2z\r\n         2vQ2qCJZQBHZegkhMO/z+d1/8a/bjqScVAH+gZOXS0hbQIp23fsx9CsPeM6iX2boAlDB\r\n         q8zh8LkYwMUxA+p0EDdmrflNA2hs9mqqiYaCJJQ2oD7VvqHpUsqdMeczcmck75SvB0xO\r\n         uvPdhrFHdp26RDN2JKj36FInwYHZTnTEKw69UFchUoLBSgzOCdCnhBQlIWyEyDX6LGYQ\r\n         8fUg==\r\nARC-Authentication-Results: i=1; mx.google.com;\r\n       spf=pass (google.com: domain of sandeep.ladi@gitam.edu designates 103.23.29.142 as permitted sender) smtp.mailfrom=sandeep.ladi@gitam.edu\r\nReturn-Path: <sandeep.ladi@gitam.edu>\r\nReceived: from mail.gitam.edu (mail.gitam.edu. [103.23.29.142])\r\n        by mx.google.com with ESMTP id s1-v6si12238610wrf.2.2018.10.16.03.33.00\r\n        for <discuss@tensorflow.org>;\r\n        Tue, 16 Oct 2018 03:33:00 -0700 (PDT)\r\nReceived-SPF: pass (google.com: domain of sandeep.ladi@gitam.edu designates 103.23.29.142 as permitted sender) client-ip=103.23.29.142;\r\nAuthentication-Results: mx.google.com;\r\n       spf=pass (google.com: domain of sandeep.ladi@gitam.edu designates 103.23.29.142 as permitted sender) smtp.mailfrom=sandeep.ladi@gitam.edu\r\nReceived: from mail.gitam.edu (webmail.gitam.edu [192.168.23.28])\r\n    by mail.gitam.edu (Postfix) with ESMTPA id B765722BCC5\r\n    for <discuss@tensorflow.org>; Tue, 16 Oct 2018 16:02:46 +0530 (IST)\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\r\n boundary=\"=_8b103ec7c4f10c51b775e6343c7573ca\"\r\nDate: Tue, 16 Oct 2018 16:02:46 +0530\r\nFrom: sandeep.ladi@gitam.edu\r\nTo: discuss@tensorflow.org\r\nSubject: Command to Input Hyperspectral Image dataset to TensorFlow.\r\nReturn-Receipt-To: sandeep.ladi@gitam.edu\r\nDisposition-Notification-To: sandeep.ladi@gitam.edu\r\nMessage-ID: <e885520003a6c5c626388950aeb89319@gitam.edu>\r\nX-Sender: sandeep.ladi@gitam.edu\r\nUser-Agent: GITAM Webmail/1.2.2\r\nX-gitam-MailScanner-Information: Please contact the ISP for more information\r\nX-gitam-MailScanner-ID: B765722BCC5.A15A0\r\nX-gitam-MailScanner: Found to be clean\r\nX-gitam-MailScanner-SpamScore: s\r\nX-gitam-MailScanner-From: sandeep.ladi@gitam.edu\r\nX-Spam-Status: No\r\n\r\n--=_8b103ec7c4f10c51b775e6343c7573ca\r\nContent-Transfer-Encoding: 7bit\r\nContent-Type: text/plain; charset=US-ASCII\r\n\r\nDear sir/Madam, \r\n\r\nGreetings of the day. \r\n\r\nI am Mr.Ladi Sandeep Kumar,working as an Assistant Professor in GITAM\r\nUniversity,Visakhapatnam,India.I and my project students are working on\r\na Project based on Hyperspectral image classification which is an\r\nemerging research topic.The opensource Hyperspectral image datasets are\r\nin .mat files containing reflectance values.We are going to use CNN\r\ntechnique for image classification using Hyperspectral image dataset of \r\nIndian pines which is a dataset of 145x145x200 where 145x145 are height\r\nand width of image and 200 is number of channels.There are lot of\r\nresources and guide for using tensorflow CNN toolbox for color image.Can\r\nyou please tell me the way and send the code to input the Indian pines\r\ndataset of 145x145 x200 as input to the CNN. \r\n\r\nI will use the tensorFlow toolbox in my  research as well as projects \r\nto teach my students and quote your website in my publications wherever\r\nI apply tensorflow module.\r\n",
	"issue_comments": "3"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "387980647",
	"issue_number": "24185",
	"issue_state": "closed",
	"issue_title": "Problem importing Tensorflow with Python 3.6.7",
	"issue_body": "Hi experts,\r\n    I've installed Anaconda 3 64-bit and Python 3.6.7 on my Windows 10 laptop, also I've installed Tensorflow, however when I try to import Tensorflow, it fails, messages are appended below, could you please give my advises and instruction of solving this problem? Thanks.\r\n\r\n\r\n\r\n```\r\n(tensorflow) C:\\Users\\user>python\r\nPython 3.6.7 |Anaconda custom (64-bit)| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *  # pylint: disable=redefined-builtin\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n```",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "357875192",
	"issue_number": "22128",
	"issue_state": "closed",
	"issue_title": "[Feature Request] retrieving exact node names from multiple outputs (`tf.nn.top_k`)",
	"issue_body": "### System information\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow version (use command below)**: '1.9.0-rc1'  I also believe it happens r1.10\r\n- **Python version**: 2.7 \r\n- **CUDA/cuDNN version**: 7.1\r\n- **Bazel version**: 0.16.1\r\n- **GPU model and memory** : TitanV 12 G\r\n- **Exact command to reproduce**: I added python sample code \r\n- **Mobile device**:  n/a\r\n\r\n\r\n\r\n### Describe the problem\r\nWhen a tensor op returns multiple outputs such as  `tf.nn.top_k`, \r\nit would be great to retrieve exact individual input nodes of its output recursively. \r\n\r\nAs addressed here, https://www.tensorflow.org/api_docs/python/tf/nn/top_k, \r\n`tf.nn.top_k` returns \r\n- values: The k largest elements along each last dimensional slice.\r\n- indices: The indices of values within the last dimension of input.\r\n\r\nWith below sample code, \r\n'Namespace/TopKV2' returns two outputs: 'Namespace/probabilities', 'Namespace/indices'\r\n(From the two output nodes, )\r\n'Namespace/probabilities' takes 'Namespace/TopKV2' **values** as input, \r\n'Namespace/indices' takes  'Namespace/TopKV2' **indices** as input. \r\n\r\nHowever, only 'Namespace/TopKV2' can be retrieved from the two output nodes. \r\nI also checked graph structure on tensorboard; it seems that same tensor/node (i.e., 'Namespace/TopKV2') goes to 'Namespace/probabilities' and  'Namespace/indices', both, however, one is values and, the other indices. \r\n\r\nIf differentiable names for multiple outputs are used, that would be great. \r\nOr, if there is workaround, please advise me. \r\nThis issue also causes key error in TensorRT graphsurgeon module. \r\n\r\n```\r\ndef _map_nodes(nodes):\r\n    return {node.name: node for node in nodes}\r\n\r\ndef main():\r\n   # simple network \r\n    with tf.variable_scope(\"Namespace\"):\r\n        inputs = tf.placeholder(tf.float32, [1, 3, 16, 16], name=\"input\")\r\n        convolved = tf.layers.conv2d(inputs, 4, [1, 1], data_format='channels_first')\r\n        reshaped = tf.reshape(convolved, [1, 256, 4])\r\n        best_probabilities, best_indices = tf.nn.top_k(reshaped, k=1)\r\n        output1 = tf.reshape(best_probabilities, [256], name='probabilities')\r\n        output2 = tf.reshape(best_indices, [256], name='indices')\r\n\r\n    graph = tf.get_default_graph()\r\n    graphdef = tf.get_default_graph().as_graph_def()\r\n\r\n    # Freeze the graph.\r\n    output_node_names = ['Namespace/probabilities', 'Namespace/indices']\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n            sess, graphdef, output_node_names\r\n        )\r\n        # Remove training nodes.\r\n        infer_graph = tf.graph_util.remove_training_nodes(frozen_graph)\r\n        graph_io.write_graph(infer_graph, \"./\", \"test.pb\", as_text=False)\r\n        node_map = _map_nodes(infer_graph.node)\r\n        for node in infer_graph.node:\r\n            for input_name in node.input:\r\n                # Recursively check against all of this node's inputs\r\n                input_node = node_map[input_name]\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\nI also attached TF board events file. \r\nhttps://drive.google.com/file/d/1HdV_eqMloqXgLenZSZHmKwME_oSnJbFb/view?usp=sharing ",
	"issue_comments": "4"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "394274093",
	"issue_number": "24589",
	"issue_state": "closed",
	"issue_title": "Why can't Python 2.7 install tensorFlow with windows operating system ?  Does TensorFlow not support Python 27 now? Is there a kind person who can tell me, I really urgent!",
	"issue_body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n",
	"issue_comments": "1"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "370268761",
	"issue_number": "22993",
	"issue_state": "closed",
	"issue_title": "TOCO failed see console for info. ",
	"issue_body": "INFO:\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\nTensorFlow installed from (source or binary): Anaconda \r\nTensorFlow version (use command below): 1.11\r\nPython version: 3.5\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\nExact command to reproduce:\r\n\r\nHi, \r\n I've used the example given in [converter python api guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/convert/python_api.md)\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Dense(2, input_shape=(3,)))\r\nmodel.add(tf.keras.layers.RepeatVector(3))\r\nmodel.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(3)))\r\nmodel.compile(loss=tf.keras.losses.MSE,\r\n              optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\r\n              metrics=[tf.keras.metrics.categorical_accuracy],\r\n              sample_weight_mode='temporal')\r\nx = np.random.random((1, 3))\r\ny = np.random.random((1, 3, 3))\r\nmodel.train_on_batch(x, y)\r\nmodel.predict(x)\r\nkeras_file = \"keras_model.h5\"\r\ntf.keras.models.save_model(model, keras_file)\r\nconverter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\ntflite_model = converter.convert()`\r\n\r\n\r\nI ran this code and this is the error I get:\r\n\r\n> RuntimeError: TOCO failed see console for info.\r\nb'Traceback (most recent call last):\\r\\n  File \"C:\\\\Users\\\\sgavvala\\\\AppData\\\\Roaming\\\\Python\\\\Python35\\\\site-packages\\\\tensorflow\\\\contrib\\\\lite\\\\toco\\\\python\\\\tensorflow_wrap_toco.py\", line 18, in swig_import_helper\\r\\n    fp, pathname, description = imp.find_module(\\'_tensorflow_wrap_toco\\', [dirname(__file__)])\\r\\n  File \"c:\\\\users\\\\sgavvala\\\\appdata\\\\local\\\\continuum\\\\anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\imp.py\", line 297, in find_module\\r\\n    raise ImportError(_ERR_MSG.format(name), name=name)\\r\\nImportError: No module named \\'_tensorflow_wrap_toco\\'\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"c:\\\\users\\\\sgavvala\\\\appdata\\\\local\\\\continuum\\\\anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\runpy.py\", line 193, in _run_module_as_main\\r\\n    \"__main__\", mod_spec)\\r\\n  File \"c:\\\\users\\\\sgavvala\\\\appdata\\\\local\\\\continuum\\\\anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\runpy.py\", line 85, in _run_code\\r\\n    exec(code, run_globals)\\r\\n  File \"C:\\\\Users\\\\sgavvala\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\tensorflow\\\\Scripts\\\\toco_from_protos.exe\\\\__main__.py\", line 5, in <module>\\r\\n  File \"C:\\\\Users\\\\sgavvala\\\\AppData\\\\Roaming\\\\Python\\\\Python35\\\\site-packages\\\\tensorflow\\\\contrib\\\\lite\\\\toco\\\\python\\\\toco_from_protos.py\", line 22, in <module>\\r\\n    from tensorflow.contrib.lite.toco.python import tensorflow_wrap_toco\\r\\n  File \"C:\\\\Users\\\\sgavvala\\\\AppData\\\\Roaming\\\\Python\\\\Python35\\\\site-packages\\\\tensorflow\\\\contrib\\\\lite\\\\toco\\\\python\\\\tensorflow_wrap_toco.py\", line 28, in <module>\\r\\n    _tensorflow_wrap_toco = swig_import_helper()\\r\\n  File \"C:\\\\Users\\\\sgavvala\\\\AppData\\\\Roaming\\\\Python\\\\Python35\\\\site-packages\\\\tensorflow\\\\contrib\\\\lite\\\\toco\\\\python\\\\tensorflow_wrap_toco.py\", line 20, in swig_import_helper\\r\\n    import _tensorflow_wrap_toco\\r\\nImportError: No module named \\'_tensorflow_wrap_toco\\'\\r\\n'\r\nNone\r\n\r\nMy plan is to convert a keras model with my custom layers into tflite quantized version. Figured I would start with a given example but that doesn't seem to run.",
	"issue_comments": "8"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "388923972",
	"issue_number": "24240",
	"issue_state": "closed",
	"issue_title": "build from source Windows toolchain for CPU error",
	"issue_body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source):0.20\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7.4.1.5\r\n- GPU model and memory: AMD 2700\r\n\r\nBuilding tensorflow from source I followed this description\r\nhttps://medium.com/@amsokol.com/how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-d047d9342b44\r\n\r\nI launch bazel and get the following error \r\n(tensorflow) C:\\Users\\Stefan\\tensorflow-build\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nc:\\users\\stefan\\tensorflow-build\\tensorflow/.bazelrc\r\nc:\\users\\stefan\\tensorflow-build\\tensorflow/tools/bazel.rc\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\n\r\nINFO: Invocation ID: 1f1e1f31-ec58-4119-9c1d-385bb8e68863\r\nERROR: cc_toolchain_suite '@local_config_cuda//crosstool:toolchain' does not contain a toolchain for CPU 'x64_windows', you may want to add an entry for 'x64_windows|msvc-cl' into toolchains and toolchain_identifier 'local_windows' into the corresponding cc_toolchain rule (see --incompatible_disable_cc_toolchain_label_from_crosstool_proto).\r\nINFO: Elapsed time: 3.855s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\nHow can I fix this?\r\n\r\nThanks for helping",
	"issue_comments": "2"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "369860260",
	"issue_number": "22963",
	"issue_state": "closed",
	"issue_title": "Subclassing the tf.keras.model.Model class, throw \"ValueError: You tried to call `count_params` on dense_81, but the layer isn't built. You can build it manually via: `dense_81.build(batch_input_shape)`.\"",
	"issue_body": "The example code :\r\n```python\r\nfrom tensorflow.keras.models import Sequential, Model\r\nfrom tensorflow.keras.layers import Dense, Input\r\n\r\nclass MyModel(Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.dense = Dense(4)\r\n    \r\n    def call(self, inputs):\r\n  \r\n        return self.dense(inputs)\r\n    \r\nmodel = MyModel()\r\n# inputs = Input(shape=(None, 10))\r\nmodel.build((None, 10))\r\nmodel.summary()\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-103-b62d1ffe41d5> in <module>()\r\n     14 # inputs = Input(shape=(None, 10))\r\n     15 model.build((None, 10))\r\n---> 16 model.summary()\r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\engine\\network.py in summary(self, line_length, positions, print_fn)\r\n   1551                               line_length=line_length,\r\n   1552                               positions=positions,\r\n-> 1553                               print_fn=print_fn)\r\n   1554 \r\n   1555 \r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py in print_summary(model, line_length, positions, print_fn)\r\n    221   for i in range(len(layers)):\r\n    222     if sequential_like:\r\n--> 223       print_layer_summary(layers[i])\r\n    224     else:\r\n    225       print_layer_summary_with_connections(layers[i])\r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py in print_layer_summary(layer)\r\n    177     name = layer.name\r\n    178     cls_name = layer.__class__.__name__\r\n--> 179     fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\r\n    180     print_row(fields, positions)\r\n    181 \r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in count_params(self)\r\n   1324                          ', but the layer isn\\'t built. '\r\n   1325                          'You can build it manually via: `' + self.name +\r\n-> 1326                          '.build(batch_input_shape)`.')\r\n   1327     weight_shapes = [w.shape.as_list() for w in self.weights]\r\n   1328     return int(sum([np.prod(w) for w in weight_shapes]))\r\n\r\nValueError: You tried to call `count_params` on dense_84, but the layer isn't built. You can build it manually via: `dense_84.build(batch_input_shape)`.\r\n```\r\n\r\n>The environment in below:\r\nOS Platform: Window10 64bit\r\nDistribution: N\r\ntools: Jupyter Notebook\r\nPython:  python3.5\r\nTensorflow: tensorflow-gpu1.10 by pip installed\r\nBazel version: N\r\nCUDA: 9.0\r\ncuDNN: 7.0\r\nGPU: Quadro M2000/4G\r\nMobile device: N\r\n\r\nIn **Jupyter** result thrown ValueError, but result show as below in **Colab**\r\n```\r\n_______________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense_2 (Dense)              multiple                  44        \r\n=================================================================\r\nTotal params: 44\r\nTrainable params: 44\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```",
	"issue_comments": "7"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "278749567",
	"issue_number": "15072",
	"issue_state": "closed",
	"issue_title": "Have to reinstall numpy",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.4.0\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nBefore I installed tensorflow, I have installed numpy through anaconda. But after I run the command provided in the website (https://www.tensorflow.org/install/install_windows), it automatically reinstalled numpy. Then when I import numpy or tensorflow, I got an import error \"cannot import name 'add_newdocs'\" which is required when importing numpy. I have to reinstall my numpy through anaconda to solve this problem. \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n",
	"issue_comments": "3"
},
{
	"login": "ymodak",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "389012357",
	"issue_number": "24248",
	"issue_state": "closed",
	"issue_title": "Support for `skip_mismatch` in `tf.keras.engine.saving.load_weights_from_hdf5_group_by_name`",
	"issue_body": "**System information**\r\n- TensorFlow version (you are using): \r\n```\r\ntensorflow                1.12.0          gpu_py36he68c306_0    anaconda\r\ntensorflow-base           1.12.0          gpu_py36h8e0ae2d_0    anaconda\r\ntensorflow-gpu            1.12.0               h0d30ee6_0    anaconda\r\n```\r\n\r\nThe feature is already supported in `keras-team/keras` and the behaviour and motivation is already explained in: https://github.com/keras-team/keras/pull/8462\r\n",
	"issue_comments": "1"
},
{
	"login": "cyyever",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "334018366",
	"issue_number": "20144",
	"issue_state": "opened",
	"issue_title": "lack using namespace std",
	"issue_body": "/opt/tensorflow/tensorflow/core/graph/default_device.h:29:36: error: 'string' does not name a type; did you mean 'stdin'?\r\n inline void SetDefaultDevice(const string& device, GraphDef* graph_def) {\r\n                                    ^~~~~~\r\n                                    stdin\r\n",
	"issue_comments": "0"
},
{
	"login": "sachinprasadhs",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "607476548",
	"issue_number": "38939",
	"issue_state": "closed",
	"issue_title": "Tensorflow lite Quantization aware training in Keras FAIL",
	"issue_body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux 39df84b83a78 4.19.104+ #1 SMP Wed Feb 19 05:26:34 PST 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n- TensorFlow installed from (source or binary): \r\n2.2.0-dev20200427\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nHere's the Colab https://colab.research.google.com/drive/1H_DGK2VjIKSNhNboW_XfqHr7kzXR-rrI\r\n\r\n```\r\n! pip uninstall -y tensorflow\r\n! pip install -q tf-nightly\r\n! pip install -q tensorflow-model-optimization\r\nimport tempfile\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n# Load MNIST dataset\r\nmnist = keras.datasets.mnist\r\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\r\n\r\n# Normalize the input image so that each pixel value is between 0 to 1.\r\ntrain_images = train_images / 255.0\r\ntest_images = test_images / 255.0\r\n\r\n# Define the MODIFIED model architecture.\r\nmodel = keras.Sequential([\r\n  keras.layers.InputLayer(input_shape=(28, 28)),\r\n  keras.layers.Reshape(target_shape=(28, 28, 1)),\r\n  keras.layers.Conv2D(filters=12, kernel_size=(3, 3),name='conv1'),\r\n  keras.layers.BatchNormalization(),\r\n  keras.layers.ReLU(),\r\n  keras.layers.MaxPooling2D(pool_size=(2, 2)),\r\n  keras.layers.Flatten(),\r\n  keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\n# Train the digit classification model\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(\r\n  train_images,\r\n  train_labels,\r\n  epochs=1,\r\n  validation_split=0.1,\r\n)\r\nimport tensorflow_model_optimization as tfmot\r\nquantize_model = tfmot.quantization.keras.quantize_model\r\n# q_aware stands for for quantization aware.\r\nq_aware_model = quantize_model(model)\r\n\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-5fc1d8762a1f> in <module>()\r\n      4 \r\n      5 # q_aware stands for for quantization aware.\r\n----> 6 q_aware_model = quantize_model(model)\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py in quantize_model(to_quantize)\r\n    136 \r\n    137   annotated_model = quantize_annotate_model(to_quantize)\r\n--> 138   return quantize_apply(annotated_model)\r\n    139 \r\n    140 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py in quantize_apply(model)\r\n    401   # layer_quantize_map gets modified by the transformations.\r\n    402   transformed_model, layer_quantize_map = quantize_transform.apply(\r\n--> 403       unwrapped_model, layer_quantize_map)\r\n    404 \r\n    405   # TODO(pulkitb): Think more about how to introduce Default specific code.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_layout_transform.py in apply(self, model, layer_quantize_map)\r\n     65     return model_transformer.ModelTransformer(\r\n     66         model, transforms,\r\n---> 67         layer_quantize_map.keys(), layer_quantize_map).transform()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/model_transformer.py in transform(self)\r\n    550     else:\r\n    551       transformed_model = keras.Sequential.from_config(self._config,\r\n--> 552                                                        custom_objects)\r\n    553 \r\n    554     for layer in transformed_model.layers:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in from_config(cls, config, custom_objects)\r\n    498       layer = layer_module.deserialize(layer_config,\r\n    499                                        custom_objects=custom_objects)\r\n--> 500       model.add(layer)\r\n    501     if (not model.inputs and build_input_shape and\r\n    502         isinstance(build_input_shape, (tuple, list))):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    454     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    455     try:\r\n--> 456       result = method(self, *args, **kwargs)\r\n    457     finally:\r\n    458       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n    227       # If the model is being built continuously on top of an input layer:\r\n    228       # refresh its output.\r\n--> 229       output_tensor = layer(self.outputs[0])\r\n    230       if len(nest.flatten(output_tensor)) != 1:\r\n    231         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    892         # are casted, not before.\r\n    893         input_spec.assert_input_compatibility(self.input_spec, inputs,\r\n--> 894                                               self.name)\r\n    895         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\r\n    896             and not self._supports_ragged_inputs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py in assert_input_compatibility(input_spec, inputs, layer_name)\r\n    178                          'expected ndim=' + str(spec.ndim) + ', found ndim=' +\r\n    179                          str(ndim) + '. Full shape received: ' +\r\n--> 180                          str(x.shape.as_list()))\r\n    181     if spec.max_ndim is not None:\r\n    182       ndim = x.shape.ndims\r\n\r\nValueError: Input 0 of layer conv1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 196]\r\n```\r\n",
	"issue_comments": "3"
},
{
	"login": "TevenLeScao",
	"repo_name": "PyTorchLightning/pytorch-lightning",
	"issue_id": "583821386",
	"issue_number": "1181",
	"issue_state": "opened",
	"issue_title": "Additional dataloader created and discarded when training with reload_dataloaders_every_epoch",
	"issue_body": "## \ud83d\udc1b Bug\r\n\r\nI am training with reload_dataloaders_every_epoch and I've noticed it instantiates an extra DataLoader before training for which nothing is run. This is an issue for me as I am training with chunks that get loaded every epoch and it is messing with the order I load them in especially if I reload a checkpoint; it would be an issue for people that generate a new dataset every epoch as they waste computation. The tqdm bar also keeps the information of the first, discarded DataLoader (in the screenshot, the number of iterations is the same for both whereas they should be different sizes)\r\n\r\n![image](https://user-images.githubusercontent.com/26709476/76968780-be917200-6929-11ea-82c5-6850a6f6e678.png)\r\n\r\n### To Reproduce\r\n\r\nThe DataLoader gets instantiated a first time line 286 in `training_loop.py` outside of the epoch loop (that's the usual time it gets instantiated when not reloading every epoch) then when using `reload_dataloaders_every_epoch` it also gets reset at the start of every epoch line 386, inside the loop, so for the first epoch there's an extra one.\r\n\r\n#### Code sample\r\n\r\n`import torch\r\nimport pytorch_lightning as pl\r\nfrom torch.utils.data import DataLoader, Dataset\r\nfrom time import sleep\r\n\r\nclass MinimalDataset(Dataset):\r\n\r\n    def __init__(self, index):\r\n        self.data = torch.Tensor(64 * index, 1024)\r\n\r\n    def __getitem__(self, item):\r\n        return self.data[item]\r\n\r\n    def __len__(self):\r\n        return len(self.data)\r\n\r\nclass MinimalModule(pl.LightningModule):\r\n\r\n    def __init__(self):\r\n        super(MinimalModule, self).__init__()\r\n        self.nn = torch.nn.Linear(1024, 1)\r\n        self.current_index = 0\r\n\r\n    def forward(self, batch):\r\n        return self.nn(batch)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        sleep(0.1)\r\n        loss = self.nn(batch)[0]\r\n        return {'loss': loss}\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        loss = self.nn(batch)[0]\r\n        return {'val_loss': loss}\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=0.01)\r\n\r\n    def train_dataloader(self):\r\n        # REQUIRED\r\n        self.current_index += 1\r\n        print(f\"initializing DataLoader n{self.current_index}\")\r\n        data_loader = DataLoader(MinimalDataset(self.current_index))\r\n        return data_loader\r\n    \r\nmodel = MinimalModule()\r\ntrainer = pl.Trainer(reload_dataloaders_every_epoch=True, num_sanity_val_steps=0, val_check_interval=8, max_epochs=1)\r\n\r\ntrainer.fit(model) `\r\n\r\n### Expected behavior\r\n\r\nOnly one dataloader should be created; two are. The tqdm bar should show 128 iterations as that is the dataset size the second time; but it is 64 (I added the sleep(0.1) to leave time to observe that)\r\n\r\n### Environment\r\n\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce RTX 2070 with Max-Q Design\r\nNvidia driver version: 435.21\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.1\r\n[pip3] pytorch-lightning==0.7.1\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.4.2\r\n[conda] Could not collect\r\n\r\n### Additional context\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "carlfm01",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "355815111",
	"issue_number": "21984",
	"issue_state": "opened",
	"issue_title": "Build from source failed on MSBuild absl/strings/str_format.h': No such file or directory",
	"issue_body": "\r\n\r\n### System information\r\nIncluded in atached files\r\n[cmakeresult.txt](https://github.com/tensorflow/tensorflow/files/2338523/cmakeresult.txt)\r\n[cmakecommand.txt](https://github.com/tensorflow/tensorflow/files/2338524/cmakecommand.txt)\r\n[old-tf_env.txt](https://github.com/tensorflow/tensorflow/files/2338525/old-tf_env.txt)\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/2338526/tf_env.txt)\r\n[msbuild.txt](https://github.com/tensorflow/tensorflow/files/2338527/msbuild.txt)\r\n\r\n\r\n\r\n\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n Files Attached.\r\n\r\nb'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\r\n\r\n### Describe the problem\r\nTensorflow build from source failed on MSBuild.\r\n\r\n### Source code / logs\r\nFiles attached.\r\n\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\n-DSWIG_EXECUTABLE=C:/Users/neoxz/Downloads/swigwin-3.0.10/swigwin-3.0.10/swig.exe ^\r\n-DPYTHON_EXECUTABLE=C:/Anaconda/python.exe ^\r\n-DPYTHON_LIBRARIES=C:/Anaconda/libs/python35.lib ^\r\n-Dtensorflow_ENABLE_GPU=ON ^\r\n-DCUDNN_HOME=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.2\" ^\r\n-Dtensorflow_ENABLE_MKL_SUPPORT=ON ^\r\n-DMKL_HOME=\"C:/Program Files (x86)/IntelSWTools/compilers_and_libraries\" ^\r\n-Dtensorflow_CUDA_VERSION=9.2 ^\r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 ^\r\n-Dtensorflow_ENABLE_GRPC_SUPPORT=OFF ^\r\n-Dtensorflow_BUILD_PYTHON_TESTS=OFF ^\r\n-Dtensorflow_BUILD_CC_EXAMPLE=OFF",
	"issue_comments": "0"
},
{
	"login": "Oceania2018",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "399973382",
	"issue_number": "24974",
	"issue_state": "reopened",
	"issue_title": "GetTempFilename is not implemented",
	"issue_body": "**System information**\r\n- Windows 10:\r\n- TensorFlow installed from (source or binary):\r\n- master branch:\r\n- python 3.6:\r\n\r\n**tensorflow\\core\\lib\\io\\path.cc(290) : error C4716: 'tensorflow::io::GetTempFilename': must return a value**\r\n\r\n**bazel build --config=opt -c fastbuild //tensorflow:libtensorflow.so**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n![image](https://user-images.githubusercontent.com/1705364/51275349-4e8b0300-1997-11e9-9991-5a86eb694e02.png)\r\n\r\n",
	"issue_comments": "10"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "176708040",
	"issue_number": "4358",
	"issue_state": "reopened",
	"issue_title": "Wrong example script in the docs for preprocessing data",
	"issue_body": "I was reading the [docs for preprocessing][1], which is a small paragraph linking to the [CIFAR-10 network][2] as an example. However, that script does not perform any preprocessing. Do we have a better example illustrating preprocessing steps like data normalization, distorting images, etc?\r\n\r\n[1]: https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/index.html#preprocessing\r\n[2]: https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/models/image/cifar10/cifar10.py",
	"issue_comments": "3"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "266158855",
	"issue_number": "13786",
	"issue_state": "closed",
	"issue_title": "no module",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n",
	"issue_comments": "1"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "162728885",
	"issue_number": "3079",
	"issue_state": "closed",
	"issue_title": "Wheel not supported installation problem: GPU Ubuntu 64 bit",
	"issue_body": "My installation attempt failed on the last step:\r\n\r\n```\r\ndrake@sparky:~$ sudo pip3 install --upgrade $TF_BINARY_URL\r\n[sudo] password for drake: \r\nThe directory '/home/drake/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nThe directory '/home/drake/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\ntensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl is not a supported wheel on this platform.\r\ndrake@sparky:~$ whoami\r\ndrake\r\ndrake@sparky:~$ sudo -H pip3 install --upgrade $TF_BINARY_URL\r\ntensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl is not a supported wheel on this platform.\r\n```\r\n\r\nWhat to do?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\n```\r\ndrake@sparky:/usr/local/bin/cuda/include$ uname -a\r\nLinux sparky 3.13.0-88-generic #135-Ubuntu SMP Wed Jun 8 21:10:42 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nInstalled version of CUDA and cuDNN: \r\n\r\nI've installed cuda-repo-ubuntu1404_7.5-18_amd64.deb.\r\n\r\nI _think_ I've installed cuDNN 5.0, but the instructions there are vague offer no way to test it.\r\n\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n```\r\ndrake@sparky:/usr/local/bin/cuda$ ls -l lib64/libcud*\r\nlrwxrwxrwx 1 root root       13 Jun 28 09:21 lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Jun 28 09:21 lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\r\n-rwxr-xr-x 1 root root 59909104 Jun 28 09:21 lib64/libcudnn.so.5.0.5\r\n-rw-r--r-- 1 root root 58775484 Jun 28 09:21 lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. Which pip package you installed.\r\n\r\nSee above\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\n```\r\ndrake@sparky:/usr/local/bin/cuda$ python3 -c \"import tensorflow; print(tensorflow.__version__)\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named 'tensorflow'\r\n```\r\n",
	"issue_comments": "6"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "196075062",
	"issue_number": "6361",
	"issue_state": "closed",
	"issue_title": "Using Multiple CPU Threads in an op",
	"issue_body": "Hi all,\r\n\r\nI'm interested in using multithreading within a CPU op to increase speed. More specifically, I have some linear algebra code which, for batched matrix multiplies, is much faster than MKL (and probably Eigen).\r\nI should be able to get the corresponding GPU version working without much trouble.\r\n\r\nCurrently my code uses OpenMP and SIMD pragmas which, as I understand it, don't play nicely with tensorflow at the moment. I've been digging through the documentation all day but haven't found any examples of a CPU op with multithreading (that isn't just calling eigen) which I can use.\r\n\r\nCould anyone please point me in the right direction here?\r\n\r\nCheers!\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n#22 #1747 \r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n-rw-r--r-- 1 root root   558720 Sep 15 00:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Sep 15 00:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Sep 15 00:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   415432 Sep 15 00:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Sep 15 00:02 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\ngit rev-parse HEAD\r\ndbe5e17e2ed307e86e1a6e79e558ec3e335d46fc\r\n\r\n2. The output of `bazel version`\r\nbazel version\r\nBuild label: 0.4.2\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Dec 7 18:47:11 2016 (1481136431)\r\nBuild timestamp: 1481136431\r\nBuild timestamp as int: 1481136431\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nN/A\r\n\r\n### What other attempted solutions have you tried?\r\nN/A\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\nN/A",
	"issue_comments": "3"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "176804608",
	"issue_number": "4371",
	"issue_state": "closed",
	"issue_title": "\"HOST_CFG\" is not defined on bazel clean",
	"issue_body": "During the ./configure step of my build from source, I encounter a bazel error when trying to download \r\n\r\n**The main error seems to be**\r\n```\r\n\r\nERROR: /home/kamal/.cache/bazel/_bazel_kamal/f9ae4eca457b390bb2ebe780caca64e0/external/protobuf/protobuf.bzl:91:19: name 'HOST_CFG' is not defined.\r\n\r\n``` \r\n\r\n\r\nBuilding with CUDA 8.0, cuDNN 5.1.5, GTX 1060\r\n\r\n\r\nFull stack:\r\n\r\n```\r\n~/tensorflow ~/tensorflow\r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\n/usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with GPU support? [y/N] y\r\nGPU support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.5\r\nPlease specify the location where cuDNN 5.1.5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n.\r\nERROR: /home/kamal/.cache/bazel/_bazel_kamal/f9ae4eca457b390bb2ebe780caca64e0/external/protobuf/protobuf.bzl:91:19: name 'HOST_CFG' is not defined.\r\nERROR: package contains errors: tensorflow/contrib/metrics.\r\nERROR: error loading package 'tensorflow/contrib/metrics': Extension 'protobuf.bzl' has errors.\r\nConfiguration finished\r\n``` ",
	"issue_comments": "5"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "282446391",
	"issue_number": "15398",
	"issue_state": "closed",
	"issue_title": "Feature request: tf.info to show docstrings in jupyter notebook",
	"issue_body": "When working with jupyter notebooks, it is really helpful to see the documentation within the notebook. Numpy has a function called `np.info` which takes a numpy function as argument and prints its docstring. For example, np.info(np.mean) prints the docstring for `np.mean`. It would be really helpful to have an equivalent `tf.info` for those of us who work with jupyter notebooks (and who doesn't?).",
	"issue_comments": "2"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "251950460",
	"issue_number": "12491",
	"issue_state": "closed",
	"issue_title": "AttributeError: 'int' object attribute '__doc__' is read-only",
	"issue_body": "In the file `tensorflow/compiler/tests/adagrad_test_poplar.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py\", line 191`, I have an error when trying to run unit tests.\r\n\r\nPython is unhappy with trying to assign to __doc__.\r\n\r\nThis is on OS/X, with a virtualenv containing all of the modules required for the head of master on 22nd August 2017.\r\n\r\nI have had to add `autograd` and `enum`, and as a consequence of the OS/X built-in numpy, I have switched to building tensorflow in a virtualenv.\r\n\r\n",
	"issue_comments": "2"
},
{
	"login": "andydavis1",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "195150117",
	"issue_number": "6272",
	"issue_state": "closed",
	"issue_title": "update docker image",
	"issue_body": "The docker image does not provide updated version of tensorflow. How should I upgrade to 0.12.0 cpu version?",
	"issue_comments": "1"
},
{
	"login": "jfsantos",
	"repo_name": "Theano/Theano",
	"issue_id": "53226339",
	"issue_number": "2370",
	"issue_state": "closed",
	"issue_title": "Python 3 support is broken",
	"issue_body": "As far as I know, Theano uses `2to3` to convert syntax to Python 3 upon install. I have just installed it under Python 3.4.3, but when trying to import it I got an error related to Python 2 syntax: \r\n\r\n```\r\nIn [1]: import theano\r\n  File \"/Users/jfsantos/Projects/Theano/theano/__init__.py\", line 153\r\n    except Exception, e0:\r\n                    ^\r\nSyntaxError: invalid syntax\r\n```\r\n\r\nI fixed this by hand, but only to get a crash due to incompatible syntax somewhere else (for example, references to `basestring`). Maybe this is just `2to3` not working as it is supposed to?",
	"issue_comments": "2"
},
{
	"login": "hadim",
	"repo_name": "tqdm/tqdm",
	"issue_id": "84578374",
	"issue_number": "1",
	"issue_state": "opened",
	"issue_title": "Add an option to disable progress bar",
	"issue_body": "Sometime it's convenient to not have progress bar. So it would be really nice to add an option to disable tqdm so the code does not need to be modified, only an option to turn off.\r\n\r\n```python\r\nfor i in tqdm.tqdm(range(10), total=10, disable=True):\r\n    print(i)\r\n```\r\n\r\nWhith disable being `False` by default of course.\r\n\r\nI can make a PR but I don't want to bother if the project is not maintained anymore... (see #18)",
	"issue_comments": "0"
},
{
	"login": "fayeshine",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "134866803",
	"issue_number": "1196",
	"issue_state": "opened",
	"issue_title": "two question about tensorflow",
	"issue_body": "1. Does tensorflow automatically use all cpus and gpus to run the computational task?\r\n\r\n2.I found that tensorflow use 1 5960X cpu and 2 Titan X gpus cost 300% time compared to theano use only 1 Titan X gpu, is there anything wrong with my configuration?\r\nI installed on Ubuntu 15.10, cuda 7.5, cudnn 4, gcc 4.9, installed from source code, built with GPU support.",
	"issue_comments": "0"
},
{
	"login": "fsx950223",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "423585473",
	"issue_number": "26973",
	"issue_state": "closed",
	"issue_title": "Tensorboard crashed when keras finish train in eager execution",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\ntensorboard crashed when keras finish training the model and do a record in tensorboard\r\n**Describe the expected behavior**\r\ntensorboard do the record normally\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n``` python\r\n  if True:\r\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss={\r\n            # use custom yolo_loss Lambda layer.\r\n            'yolo_loss': lambda y_true, y_pred: y_pred})\r\n\r\n        model.fit_generator(data_generator(files,batch_size, input_shape, anchors, num_classes),\r\n                    epochs=0, initial_epoch=0,\r\n                    steps_per_epoch=max(1, sum // batch_size),\r\n                    callbacks=[logging, checkpoint],\r\n                    validation_data=data_generator(val_files, batch_size, input_shape, anchors,num_classes,train=False),\r\n                    validation_steps=max(1, val_sum // batch_size))\r\n        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\r\n\r\n    # Unfreeze and continue training, to fine-tune.\r\n    # Train longer if the result is not good.\r\n    if True:\r\n        for i in range(len(model.layers)):\r\n            model.layers[i].trainable = True\r\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\r\n                      loss={'yolo_loss': lambda y_true, y_pred: y_pred})  # recompile to apply the change\r\n        print('Unfreeze all of the layers.')\r\n\r\n        model.fit_generator(data_generator(files,batch_size, input_shape, anchors, num_classes),\r\n                    epochs=1, initial_epoch=0, steps_per_epoch=max(1, sum // batch_size),\r\n                    callbacks=[logging,checkpoint, reduce_lr, early_stopping],\r\n                    validation_data=data_generator(val_files, batch_size, input_shape, anchors, num_classes,train=False),\r\n                    validation_steps=max(1, val_sum // batch_size))\r\n        model.save_weights(log_dir + 'trained_weights_final.h5')\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nTraceback (most recent call last):\r\n  File \"/media/fangsixie/data/pycharm-2018.2.4/helpers/pydev/pydevd.py\", line 1664, in <module>\r\n    main()\r\n  File \"/media/fangsixie/data/pycharm-2018.2.4/helpers/pydev/pydevd.py\", line 1658, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/media/fangsixie/data/pycharm-2018.2.4/helpers/pydev/pydevd.py\", line 1068, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/media/fangsixie/data/pycharm-2018.2.4/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/media/fangsixie/data/keras-yolo3/train.py\", line 192, in <module>\r\n    _main()\r\n  File \"/media/fangsixie/data/keras-yolo3/train.py\", line 78, in _main\r\n    validation_steps=max(1, val_sum // batch_size))\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1426, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 232, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs, mode=mode)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 251, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 1159, in on_epoch_end\r\n    self._write_custom_summaries(step, logs)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 1106, in _write_custom_summaries\r\n    summary_ops_v2.scalar(name, value, step=step)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 564, in scalar\r\n    return summary_writer_function(name, tensor, function, family=family)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 508, in summary_writer_function\r\n    should_record_summaries(), record, _nothing, name=\"\")\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/framework/smart_cond.py\", line 54, in smart_cond\r\n    return true_fn()\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 501, in record\r\n    with ops.control_dependencies([function(tag, scope)]):\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 562, in function\r\n    name=scope)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/gen_summary_ops.py\", line 675, in write_scalar_summary\r\n    writer, step, tag, value, name=name, ctx=_ctx)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/gen_summary_ops.py\", line 706, in write_scalar_summary_eager_fallback\r\n    attrs=_attrs, ctx=_ctx, name=name)\r\n  File \"/home/fangsixie/.conda/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/logdir:logs/000//N10tensorflow22SummaryWriterInterfaceE does not exist. [Op:WriteScalarSummary] name: epoch_loss/",
	"issue_comments": "1"
},
{
	"login": "edenlightning",
	"repo_name": "PyTorchLightning/pytorch-lightning",
	"issue_id": "631975383",
	"issue_number": "2093",
	"issue_state": "opened",
	"issue_title": "Add type checking to result dict",
	"issue_body": "",
	"issue_comments": "0"
},
{
	"login": "joel-shor",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "189883954",
	"issue_number": "5652",
	"issue_state": "closed",
	"issue_title": "cifar10_multi_gpu_train.py breaks with more than 1 GPU",
	"issue_body": "### Environment info\r\nOperating System: Ubuntu \r\n\r\nInstalled version of CUDA and cuDNN: 8.0 and 5\r\n\r\n1. The commit hash (`git rev-parse HEAD`): 3d41cf77d624aeee0482f92121a9300b29db2809\r\n2. The output of `bazel version`: \r\nBuild label: 0.3.2\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\r\nBuild timestamp: 1475861110\r\nBuild timestamp as int: 1475861110\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\npython cifar10_multi_gpu_train.py --num_gpus=2\r\n\r\nBoth cifar10_train.py and cifar10_multi_gpu_train.py (without specifying num_gpus, so running on a single GPU) work.\r\n\r\n### Logs or other output that would be helpful\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\r\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\r\nTraceback (most recent call last):\r\n  File \"cifar10_multi_gpu_train.py\", line 280, in <module>\r\n    tf.app.run()\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"cifar10_multi_gpu_train.py\", line 276, in main\r\n    train()\r\n  File \"cifar10_multi_gpu_train.py\", line 180, in train\r\n    loss = tower_loss(scope)\r\n  File \"cifar10_multi_gpu_train.py\", line 92, in tower_loss\r\n    loss_averages_op = loss_averages.apply(losses + [total_loss])\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/training/moving_averages.py\", line 391, in apply\r\n    self._averages[var], var, decay, zero_debias=zero_debias))\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/training/moving_averages.py\", line 70, in assign_moving_average\r\n    update_delta = _zero_debias(variable, value, decay)\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/training/moving_averages.py\", line 177, in _zero_debias\r\n    trainable=False)\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py\", line 1024, in get_variable\r\n    custom_getter=custom_getter)\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py\", line 850, in get_variable\r\n    custom_getter=custom_getter)\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py\", line 346, in get_variable\r\n    validate_shape=validate_shape)\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py\", line 331, in _true_getter\r\n    caching_device=caching_device, validate_shape=validate_shape)\r\n  File \"/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py\", line 650, in _get_single_variable\r\n    \"VarScope?\" % name)\r\nValueError: Variable tower_1/tower_1/conv1/weight_loss/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?",
	"issue_comments": "2"
},
{
	"login": "ekuznetsov139",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "506246172",
	"issue_number": "33294",
	"issue_state": "opened",
	"issue_title": "PackOp race condition / heisenbug",
	"issue_body": "tensorflow (1.x trunk) has a peculiar kernel: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/pack_op.cc#L168-L174\r\nit is registered for the op \"Pack\" as a GPU kernel, but it is implemented on the host (CPU), and it takes its inputs in host memory. (There may be others like it, this is merely the one I noticed.)\r\n\r\nConsider what happens when its input comes from the GPU memory. Graph builder will insert a HostRecv op, which copies the data from the GPU to the host. HostRecv is, by default, asynchronous.\r\n\r\nAfter HostRecv, tensorflow will call BaseGPUDevice::Compute() on the PackOp kernel. \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device.cc#L479\r\nWhich will immediately proceed calling Compute() on the assumption that it is a GPU kernel that's going to be executed in the same stream (therefore synchronization is unnecessary).\r\nSince HostRecv is asynchronous, the data may or may not be there by the time Pack attempts to read it, resulting in a race condition.\r\n\r\n(There was some code in BaseGPUDevice::Compute() that did attempt waiting for inputs up until about 2 weeks ago, but it did not prevent the race condition either.)",
	"issue_comments": "0"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "397458446",
	"issue_number": "24808",
	"issue_state": "closed",
	"issue_title": "InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,2048,2] rhs shape= [1,1,2048,1001]          [[Node: save/Assign_31 = Assign[T=DT_FLOAT, _class=[\"loc:@InceptionV3/Logits/Conv2d_1c_1x1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](InceptionV3/Logits/Conv2d_1c_1x1/weights, save/RestoreV2:31)]]",
	"issue_body": "Wenn  I ran following the bashscript, I got the following the errors. I want to train my dataset using the transferlearning of Inception-v3.\r\nHow do I go about correcting this? Thank you very much.\r\n\r\nBashcript:\r\npython3 train_image_classifier.py \\\r\n --train_dir=satellite/train_dir \\\r\n --dataset_name=satellite \\\r\n --dataset_split_name=train \\\r\n --dataset_dir=satellite/data \\\r\n --model_name=inception_v3 \\\r\n --checkpoint_path=satellite/pretrained/inception_v3.ckpt \\\r\n --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits \\\r\n --trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits \\\r\n --max_number_of_steps=100000 \\\r\n --batch_size =32 \\\r\n--learning_rate=0.001 \\\r\n--learning_rate_decay_type=fixed \\\r\n--save_summaries_secs=2 \\\r\n-log_every_n_steps=10 \\\r\n--optimizer=rmsprop \\\r\n--weight_decay=0.00004\r\n\r\nErrors:\r\nCaused by op 'save/Assign_31', defined at:\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 593, in <module>\r\n    tf.app.run()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 583, in main\r\n    init_fn=_get_init_fn(),\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 377, in _get_init_fn\r\n    ignore_missing_vars=FLAGS.ignore_missing_vars)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\", line 695, in assign_from_checkpoint_fn\r\n    write_version=saver_pb2.SaverDef.V1)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in __init__\r\n    self.build()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1296, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1333, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 781, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 422, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 113, in restore\r\n    self.op.get_shape().is_fully_defined())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 219, in assign\r\n    validate_shape=validate_shape)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,2048,2] rhs shape= [1,1,2048,1001]\r\n         [[Node: save/Assign_31 = Assign[T=DT_FLOAT, _class=[\"loc:@InceptionV3/Logits/Conv2d_1c_1x1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](InceptionV3/Logits/Conv2d_1c_1x1/weights, save/RestoreV2:31)]]\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,2048,2] rhs shape= [1,1,2048,1001]\r\n         [[Node: save/Assign_31 = Assign[T=DT_FLOAT, _class=[\"loc:@InceptionV3/Logits/Conv2d_1c_1x1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](InceptionV3/Logits/Conv2d_1c_1x1/weights, save/RestoreV2:31)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 593, in <module>\r\n    tf.app.run()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 589, in main\r\n    sync_optimizer=optimizer if FLAGS.sync_replicas else None)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 748, in train\r\n    master, start_standard_services=False, config=session_config) as sess:\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\contextlib.py\", line 112, in __enter__\r\n    return next(self.gen)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1005, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 833, in stop\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\", line 693, in reraise\r\n    raise value\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 994, in managed_session\r\n    start_standard_services=start_standard_services)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 731, in prepare_or_wait_for_session\r\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\", line 289, in prepare_session\r\n    init_fn(sess)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\", line 697, in callback\r\n    saver.restore(session, model_path)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1752, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,2048,2] rhs shape= [1,1,2048,1001]\r\n         [[Node: save/Assign_31 = Assign[T=DT_FLOAT, _class=[\"loc:@InceptionV3/Logits/Conv2d_1c_1x1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](InceptionV3/Logits/Conv2d_1c_1x1/weights, save/RestoreV2:31)]]\r\n\r\nCaused by op 'save/Assign_31', defined at:\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 593, in <module>\r\n    tf.app.run()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 583, in main\r\n    init_fn=_get_init_fn(),\r\n  File \"D:\\python\\Py Code\\Laufzeit\\train_image_classifier.py\", line 377, in _get_init_fn\r\n    ignore_missing_vars=FLAGS.ignore_missing_vars)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\", line 695, in assign_from_checkpoint_fn\r\n    write_version=saver_pb2.SaverDef.V1)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in __init__\r\n    self.build()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1296, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1333, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 781, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 422, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 113, in restore\r\n    self.op.get_shape().is_fully_defined())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 219, in assign\r\n    validate_shape=validate_shape)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,2048,2] rhs shape= [1,1,2048,1001]\r\n         [[Node: save/Assign_31 = Assign[T=DT_FLOAT, _class=[\"loc:@InceptionV3/Logits/Conv2d_1c_1x1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](InceptionV3/Logits/Conv2d_1c_1x1/weights, save/RestoreV2:31)]]\r\n\r\n",
	"issue_comments": "3"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "393830484",
	"issue_number": "24541",
	"issue_state": "closed",
	"issue_title": "How to resize segmentation map to the size of input image obtained from Deeplab?",
	"issue_body": "Currently, Deeplab v3 return resized (small) image and its corresponding mask. But, I need segmentation mask for the original input image (large)? How can I achieve this?\r\n",
	"issue_comments": "3"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "421412385",
	"issue_number": "26732",
	"issue_state": "closed",
	"issue_title": "[TF2.0] Error from Tensorboard with keras callback ",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below):conda list 2.0.0a0\r\n- Python version:Python 3.6.8 :: Anaconda custom (64-bit)\r\n- CUDA/cuDNN version:V10.0.130/7.5.0\r\n- GPU model and memory:GTX 1050 TI\r\n\r\n**Describe the current behavior**\r\nI want to try tensorboard from keras, it work if tensorflow-gpu=1.13.1 & tensorboard=1.13.1,\r\nbut get the error if tensorflow-gpu=2.0.0a0 & tb-nightly=1.14.0a20190301 as below:\r\n```\r\nEpoch 1/50\r\n   32/60000 [..............................] - ETA: 11:31 - loss: 2.3852 - acc: 0.1562\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-4-aadf56b04ffa> in <module>\r\n----> 1 model.fit(x_train, y_train, epochs=50, callbacks=[tensorboard_callback])\r\n      2 \r\n      3 model.evaluate(x_test, y_test)\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    863           validation_steps=validation_steps,\r\n    864           validation_freq=validation_freq,\r\n--> 865           steps_name='steps_per_epoch')\r\n    866 \r\n    867   def evaluate(self,\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    361         # Callbacks batch end.\r\n    362         batch_logs = cbks.make_logs(model, batch_logs, batch_outs, mode)\r\n--> 363         callbacks._call_batch_hook(mode, 'end', batch_index, batch_logs)\r\n    364         progbar.on_batch_end(batch_index, batch_logs)\r\n    365 \r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)\r\n    225     for callback in self.callbacks:\r\n    226       batch_hook = getattr(callback, hook_name)\r\n--> 227       batch_hook(batch, logs)\r\n    228     self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n    229 \r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in on_train_batch_end(self, batch, logs)\r\n    507     \"\"\"\r\n    508     # For backwards compatibility.\r\n--> 509     self.on_batch_end(batch, logs=logs)\r\n    510 \r\n    511   def on_test_batch_begin(self, batch, logs=None):\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks_v1.py in on_batch_end(self, batch, logs)\r\n    360     self._total_batches_seen += 1\r\n    361     if self._is_profiling:\r\n--> 362       profiler.save(self.log_dir, profiler.stop())\r\n    363       self._is_profiling = False\r\n    364     elif (not self._is_profiling and\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\profiler.py in save(logdir, result)\r\n    141       logdir, 'plugins', 'profile',\r\n    142       datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\r\n--> 143   gfile.MakeDirs(plugin_dir)\r\n    144   maybe_create_event_file(logdir)\r\n    145   with gfile.Open(os.path.join(plugin_dir, 'local.trace'), 'wb') as f:\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in recursive_create_dir(dirname)\r\n    446     errors.OpError: If the operation fails.\r\n    447   \"\"\"\r\n--> 448   recursive_create_dir_v2(dirname)\r\n    449 \r\n    450 \r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in recursive_create_dir_v2(path)\r\n    462   \"\"\"\r\n    463   with errors.raise_exception_on_not_ok_status() as status:\r\n--> 464     pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path), status)\r\n    465 \r\n    466 \r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    546             None, None,\r\n    547             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 548             c_api.TF_GetCode(self.status.status))\r\n    549     # Delete the underlying status object from memory otherwise it stays alive\r\n    550     # as there is a reference to status from this from the traceback due to\r\n\r\nNotFoundError: Failed to create a directory: logs/fit/20190315-164851\\plugins\\profile\\2019-03-15_16-48-53; No such file or directory\r\n```\r\nif reinstall tensorflow==2.0.0-alpha0 and tf-nightly-gpu got another error:\r\n```\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-6-aadf56b04ffa> in <module>\r\n----> 1 model.fit(x_train, y_train, epochs=50, callbacks=[tensorboard_callback])\r\n      2 \r\n      3 model.evaluate(x_test, y_test)\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    871           validation_steps=validation_steps,\r\n    872           validation_freq=validation_freq,\r\n--> 873           steps_name='steps_per_epoch')\r\n    874 \r\n    875   def evaluate(self,\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    202       samples=num_samples_or_steps,\r\n    203       verbose=0,  # Handle ProgBarLogger separately in this loop.\r\n--> 204       mode=mode)\r\n    205   # TODO(omalleyt): Handle ProgBar as part of Callbacks once hooks are ready.\r\n    206   progbar = training_utils.get_progbar(model, count_mode)\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in configure_callbacks(callbacks, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, count_mode, mode)\r\n     94   # Set callback model\r\n     95   callback_model = model._get_callback_model()  # pylint: disable=protected-access\r\n---> 96   callback_list.set_model(callback_model)\r\n     97 \r\n     98   set_callback_parameters(\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in set_model(self, model)\r\n    208     self.model = model\r\n    209     for callback in self.callbacks:\r\n--> 210       callback.set_model(model)\r\n    211 \r\n    212   def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in set_model(self, model)\r\n   1213     self.model = model\r\n   1214     with context.eager_mode():\r\n-> 1215       self._initialize_writers()\r\n   1216       if self.write_graph:\r\n   1217         if model.run_eagerly:\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in _initialize_writers(self)\r\n   1251       return summary_ops_v2.create_file_writer_v2(path)\r\n   1252 \r\n-> 1253     self._train_writer = create_writer('train')\r\n   1254     self._writers.append(self._train_writer)\r\n   1255     self._validation_writer = create_writer('validation')\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in create_writer(subdir)\r\n   1249     def create_writer(subdir):\r\n   1250       path = os.path.join(self.log_dir, subdir)\r\n-> 1251       return summary_ops_v2.create_file_writer_v2(path)\r\n   1252 \r\n   1253     self._train_writer = create_writer('train')\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py in create_file_writer_v2(logdir, max_queue, flush_millis, filename_suffix, name)\r\n    377               filename_suffix=filename_suffix),\r\n    378           name=name,\r\n--> 379           v2=True)\r\n    380 \r\n    381 \r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py in __init__(self, shared_name, init_op_fn, name, v2)\r\n    197     # TODO(nickfelt): cache other constructed ops in graph mode\r\n    198     self._init_op_fn = init_op_fn\r\n--> 199     self._init_op = init_op_fn(self._resource)\r\n    200     self._v2 = v2\r\n    201     self._closed = False\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py in create_summary_file_writer(writer, logdir, max_queue, flush_millis, filename_suffix, name)\r\n    190       else:\r\n    191         message = e.message\r\n--> 192       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n    193   # Add nodes to the TensorFlow graph.\r\n    194   _, _, _op = _op_def_lib._apply_op_helper(\r\n\r\n~\\Anaconda3\\envs\\lab\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: Failed to create a directory: logs/fit/20190315-171835\\train; No such file or directory [Op:CreateSummaryFileWriter]\r\n```\r\n\r\nAny suggestion to fix? Thanks.\r\n\r\n**Describe the expected behavior**\r\nshould be trained and logged\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport datetime\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\n\r\nmnist = tf.keras.datasets.mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n\r\nlog_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\ntensorboard_callback = TensorBoard(log_dir)\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(x_train, y_train, epochs=50, callbacks=[tensorboard_callback])\r\nmodel.evaluate(x_test, y_test)\r\n```\r\n\r\n**Other info / logs**",
	"issue_comments": "2"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "381291478",
	"issue_number": "23782",
	"issue_state": "closed",
	"issue_title": "Object detection time increases as the image resolution increase.",
	"issue_body": "<em> The Object detection inference time  for different Object detection techniques increases as  the increase in Image size(resolution). I did bit of research and came to know that detection api resizes image to certain resolution and pass the resized image to detection process. In case of SSD the images are resized to 300*300 and in case of Faster R-CNN image are resize  between resolution 600 and 1024. However, if this is the case, then such increase in processing time with respect to image size should not make sense as any sized image  will be eventually processed at the standard size  which is 300*300 in case of SSD and  between 600 & 1024 in case of Faster R-CNN. I have experimental result that shows the increase in inference with respect to image size. I am not able to put conclusion for this behavior in words. I know the reason behind this for Yolo but not for other detection framework</em>\r\n**This is my experimental result for SSD, Faster RCNN and Yolo is as follows**\r\n![result](https://user-images.githubusercontent.com/41212548/48574000-3cbfad80-e8cb-11e8-9332-816435401420.png)\r\n\r\n\r\n\r\n",
	"issue_comments": "4"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "424467968",
	"issue_number": "27053",
	"issue_state": "closed",
	"issue_title": "tf.Session and tf.ConfigProto do not work in the new TF2.0",
	"issue_body": "tf.Session and tf.ConfigProto do not work in the new TF2.0; what other options do I have?\r\n\r\nwith tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\r\n        result = session.run(sum_operation)\r\n        print(result)",
	"issue_comments": "6"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "401321777",
	"issue_number": "25070",
	"issue_state": "closed",
	"issue_title": "Use my data up bug?",
	"issue_body": "In the project,\r\n[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands](url)\r\n\r\nMy code is down:\r\n\r\n`if __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--data_dir',\r\n      type=str,\r\n      default='D:/python/speechtf/data/',\r\n      help=\"\"\"\\\r\n      Where to download the speech training data to.\r\n      \"\"\")\r\n  parser.add_argument(\r\n      '--background_volume',\r\n      type=float,\r\n      default=0.1,\r\n      help=\"\"\"\\\r\n      How loud the background noise should be, between 0 and 1.\r\n      \"\"\")\r\n  parser.add_argument(\r\n      '--background_frequency',\r\n      type=float,\r\n      default=0.8,\r\n      help=\"\"\"\\\r\n      How many of the training samples have background noise mixed in.\r\n      \"\"\")\r\n  parser.add_argument(\r\n      '--silence_percentage',\r\n      type=float,\r\n      default=10.0,\r\n      help=\"\"\"\\\r\n      How much of the training data should be silence.\r\n      \"\"\")\r\n  parser.add_argument(\r\n      '--unknown_percentage',\r\n      type=float,\r\n      default=10.0,\r\n      help=\"\"\"\\\r\n      How much of the training data should be unknown words.\r\n      \"\"\")\r\n  parser.add_argument(\r\n      '--time_shift_ms',\r\n      type=float,\r\n      default=0.0,\r\n      help=\"\"\"\\\r\n      Range to randomly shift the training audio by in time.\r\n      \"\"\")\r\n  parser.add_argument(\r\n      '--testing_percentage',\r\n      type=int,\r\n      default=10,\r\n      help='What percentage of wavs to use as a test set.')\r\n  parser.add_argument(\r\n      '--validation_percentage',\r\n      type=int,\r\n      default=10,\r\n      help='What percentage of wavs to use as a validation set.')\r\n  parser.add_argument(\r\n      '--sample_rate',\r\n      type=int,\r\n      default=16000,\r\n      help='Expected sample rate of the wavs',)\r\n  parser.add_argument(\r\n      '--clip_duration_ms',\r\n      type=int,\r\n      default=100,\r\n      help='Expected duration in milliseconds of the wavs',)\r\n  parser.add_argument(\r\n      '--window_size_ms',\r\n      type=float,\r\n      default=30.0,\r\n      help='How long each spectrogram timeslice is.',)\r\n  parser.add_argument(\r\n      '--window_stride_ms',\r\n      type=float,\r\n      default=10.0,\r\n      help='How far to move in time between spectogram timeslices.',)\r\n  parser.add_argument(\r\n      '--feature_bin_count',\r\n      type=int,\r\n      default=40,\r\n      help='How many bins to use for the MFCC fingerprint',\r\n  )\r\n  parser.add_argument(\r\n      '--how_many_training_steps',\r\n      type=str,\r\n      default='25000,5000',\r\n      help='How many training loops to run',)\r\n  parser.add_argument(\r\n      '--eval_step_interval',\r\n      type=int,\r\n      default=400,\r\n      help='How often to evaluate the training results.')\r\n  parser.add_argument(\r\n      '--learning_rate',\r\n      type=str,\r\n      default='0.001,0.0001',\r\n      help='How large a learning rate to use when training.')\r\n  parser.add_argument(\r\n      '--batch_size',\r\n      type=int,\r\n      default=100,\r\n      help='How many items to train with at once',)\r\n  parser.add_argument(\r\n      '--wanted_words',\r\n      type=str,\r\n      default='1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88',\r\n      help='Words to use (others will be added to an unknown label)',)\r\n  parser.add_argument(\r\n      '--train_dir',\r\n      type=str,\r\n      default='D:/python/speechtf/train_model/',\r\n      help='Directory to write event logs and checkpoint.')\r\n  parser.add_argument(\r\n      '--save_step_interval',\r\n      type=int,\r\n      default=100,\r\n      help='Save model checkpoint every save_steps.')\r\n  parser.add_argument(\r\n      '--start_checkpoint',\r\n      type=str,\r\n      default='',\r\n      help='If specified, restore this pretrained model before any training.')\r\n  parser.add_argument(\r\n      '--model_architecture',\r\n      type=str,\r\n      default='conv',\r\n      help='What model architecture to use')\r\n  parser.add_argument(\r\n      '--check_nans',\r\n      type=bool,\r\n      default=False,\r\n      help='Whether to check for invalid numbers during processing')\r\n  parser.add_argument(\r\n      '--quantize',\r\n      type=bool,\r\n      default=False,\r\n      help='Whether to train the model for eight-bit deployment')\r\n  parser.add_argument(\r\n      '--preprocess',\r\n      type=str,\r\n      default='mfcc',\r\n      help='Spectrogram processing mode. Can be \"mfcc\" or \"average\"')\r\n\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`\r\n\r\n\r\n\r\n`Traceback (most recent call last):\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Data too short when trying to read string\r\n\t [[{{node DecodeWav}} = DecodeWav[desired_channels=1, desired_samples=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:/python/speechtf/train4.py\", line 404, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:/python/speechtf/train4.py\", line 70, in main\r\n    FLAGS.testing_percentage, model_settings)\r\n  File \"D:/python/speechtf\\input_data4.py\", line 176, in __init__\r\n    self.prepare_background_data()\r\n  File \"D:/python/speechtf\\input_data4.py\", line 334, in prepare_background_data\r\n    feed_dict={wav_filename_placeholder: wav_path}).audio.flatten()\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Data too short when trying to read string\r\n\t [[node DecodeWav (defined at D:/python/speechtf\\input_data4.py:328)  = DecodeWav[desired_channels=1, desired_samples=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile)]]\r\n\r\nCaused by op 'DecodeWav', defined at:\r\n  File \"<string>\", line 1, in <module>\r\n  File \"D:\\python\\lib\\idlelib\\run.py\", line 144, in main\r\n    ret = method(*args, **kwargs)\r\n  File \"D:\\python\\lib\\idlelib\\run.py\", line 474, in runcode\r\n    exec(code, self.locals)\r\n  File \"D:/python/speechtf/train4.py\", line 404, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:/python/speechtf/train4.py\", line 70, in main\r\n    FLAGS.testing_percentage, model_settings)\r\n  File \"D:/python/speechtf\\input_data4.py\", line 176, in __init__\r\n    self.prepare_background_data()\r\n  File \"D:/python/speechtf\\input_data4.py\", line 328, in prepare_background_data\r\n    wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_audio_ops.py\", line 222, in decode_wav\r\n    desired_samples=desired_samples, name=name)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Data too short when trying to read string\r\n\t [[node DecodeWav (defined at D:/python/speechtf\\input_data4.py:328)  = DecodeWav[desired_channels=1, desired_samples=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile)]]`\r\n",
	"issue_comments": "4"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "398786783",
	"issue_number": "24890",
	"issue_state": "closed",
	"issue_title": "XLA Compiler Error \"(...)C++ compilation of rule '//tensorflow/compiler/xla:window_util' failed (Exit 2): python.exe failed: error executing command\"",
	"issue_body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Version 1809 Betriebssystembuild: 17763.253\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source (install impossible)\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: virtualenv: yes; pip: yes anaconda: no\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source):-\r\n- CUDA/cuDNN version: 10.0/7\r\n- GPU model and memory: RTX 2070 8GB\r\n- Microsoft Visual Studio Version: VS 2017 Enterprise (I am student)\r\n\r\n\r\n\r\n**Describe the problem**\r\nIf i build the pip package, than  following error occured:\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nERROR: F:/*/tensorflow/tensorflow/compiler/xla/BUILD:711:1: C++ compilation of rule '//tensorflow/compiler/xla:window_util' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/bjoern_std/_bazel_bjoern_std/h2irjqdy/execroot/org_tensorflow\r\n\r\n**Any other info / logs**\r\nLog one step before the error and one step after:\r\n\"(...)Hinweis: Einlesen der Datei:    external/com_google_absl\\absl/numeric/int128_no_intrinsic.inc\r\nERROR: F:/*/tensorflow/tensorflow/compiler/xla/BUILD:711:1: C++ compilation of rule '//tensorflow/compiler/xla:window_util' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/*/_bazel_bjoern_std/h2irjqdy/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;F:\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;F:\\Windows Kits\\10\\include\\10.0.17763.0\\shared;F:\\Windows Kits\\10\\include\\10.0.17763.0\\um;F:\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;F:\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;F:\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;F:\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\MSBuild\\15.0\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Team Tools\\Performance Tools;F:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;F:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;F:\\Windows Kits\\10\\bin\\10.0.17763.0\\x64;F:\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\Tools\\;;C:\\Windows\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Program Files/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Program Files/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\*~1\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.0,7.5\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\*~1\\AppData\\Local\\Temp\r\n  C:/Program Files/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/xla/_objs/window_util/window_util.o /c tensorflow/compiler/xla/window_util.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nHinweis: Einlesen der Datei: .\\tensorflow/compiler/xla/window_util.h(...)\"\r\n\"(...) Hinweis: Einlesen der Datei:   external/com_google_absl\\absl/strings/string_view.h\r\nHinweis: Einlesen der Datei:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\include\\cassert\r\nHinweis: Einlesen der Datei:     F:\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt\\assert.h\r\nHinweis: Einlesen der Datei: .\\tensorflow/core/platform/logging.h\r\nHinweis: Einlesen der Datei:  .\\tensorflow/core/platform/default/logging.h\r\nHinweis: Einlesen der Datei:   .\\tensorflow/core/platform/macros.h\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 536,864s, Critical Path: 314,01s\r\nINFO: 2538 processes: 2538 local.\r\nFAILED: Build did NOT complete successfully(...)\"\r\n\r\nNOTE from threadauthor: I have short the log, because they have only read acknowledges!\r\nA star (*) in the path means, that i anonymised my account name!\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n",
	"issue_comments": "9"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "408441360",
	"issue_number": "25639",
	"issue_state": "closed",
	"issue_title": "I want to reshape Tensor of shape[None,19,19,25] to [None,19,19,5,5] .Can anyone help me out",
	"issue_body": "I want to reshape Tensor of shape[None,19,19,25] to [None,19,19,5,5] .Can anyone help me out",
	"issue_comments": "1"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "411221673",
	"issue_number": "25814",
	"issue_state": "closed",
	"issue_title": "Batchnorm does not work in Eager mode in TF 1.12: InternalError",
	"issue_body": " Could not find valid device for node ",
	"issue_comments": "3"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "411153758",
	"issue_number": "25805",
	"issue_state": "closed",
	"issue_title": "About model size in ckpt format or numpy format",
	"issue_body": "Hello, I got a strange question when I tried to convert model from ckpt format to numpy format.\r\nI have two files for the source model in ckpt format\r\nmodel.ckpt.index - 53.7KB\r\nmodel.ckpt.data-00000-of-0001 - 330MB\r\n\r\nBut when I tried to use get_variable_to_shape_map() to get all variables from the src model and save them into a file with numpy format, I got a npy file with 494MB !!!\r\n\r\nI wonder if I used the wrong way to convert ckpt to npy? Or if the ckpt model has been saved in some code formats so it looks small. \r\n\r\nThank you !",
	"issue_comments": "1"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "407059731",
	"issue_number": "25536",
	"issue_state": "closed",
	"issue_title": "I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2",
	"issue_body": "I have installed tensorflow in my CPU based system using command:      \r\npip install tensorflow  \r\n\r\nInstallation completed without any error and as part of some initial verification I am able to see the tensorflow version installed:      \r\n>>> import tensorflow     \r\n>>> tensorflow.__version__    \r\n '1.5.0'\r\nOperating system used : Ubuntu 16.04  \r\n\r\nNow, when I tried running a python file having code to deal with a tensorflow model, I am getting the following error and the file did not execute:      \r\nI tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2  \r\n\r\nI checked online for solution and could see the discussions mostly around: TensorFlow binary was not compiled to use: 'AVX AVX2'(where in my case it is: 'SSE4.1 SSE4.2')  I am new to tensorflow and finding the solutions bit overwhelming. \r\nCould you please help me to resolve this specific issue?  \r\nThanks in advance",
	"issue_comments": "4"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "423406088",
	"issue_number": "26954",
	"issue_state": "closed",
	"issue_title": "Documentation Request: Transfer Learning in TF 2 with same and/or different final layer",
	"issue_body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2 alpha\r\n- Doc Link: N/A\r\n\r\n\r\n**Describe the documentation issue**\r\nHello, I'm in the process of porting some of our existing TF 1.x based code to be ready for TF 2.0. This means we are trying to be focused around tf.keras, so I was hoping for an example of the best way to do transfer learning in tf.keras. Specifically, we have the following (I assume common) use case.\r\n\r\n1. Train a model (say it's classification) with on dataset a, with 100 classes in the outputs.\r\n2. Finetune the model on dataset b, using the same architecture, also with 100 classes.\r\n3. Finetune the model on dataset c, which is the same except it has 50 classes, and thus the final layer has a different shape. So, we want to load all of the weights except the final layer,  and then train.\r\n\r\nIn TF 1.x, we used tf.estimator. For task 3, we would label the final layer with the name \"final_layer\", and then when warm-starting the models for finetuning, we would use the WarmstartSettings object to exclude weights that have final_layer in them. What is the equivalent for tf.keras in TF 2.x? Probably the cleanest way we could have the old functionality is if tf.keras.Model.load_weights had a regex field in the same form as WarmStartSettings, which only loaded a subset of variables.\r\n\r\nThanks!\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI'm happy to write the docs if someone could give a high-level summary of how this is done. All the ways I've come up with are pretty jank, and I assume there is a better way to do this given how elegant it was in TF 1.X.\r\n",
	"issue_comments": "10"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "421284920",
	"issue_number": "26719",
	"issue_state": "closed",
	"issue_title": "how to use the saved model after trained to detect new pictures",
	"issue_body": "Hi all,\r\nthis might be repeated question.\r\nI trained classifier on cats, dogs. and saved the model. Now I want to use the saved trained model to detect new pictures. How to do this? Is there a code for this?\r\n\r\nThanx",
	"issue_comments": "1"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "408799482",
	"issue_number": "25667",
	"issue_state": "closed",
	"issue_title": "Trigger point of object detection in tensorflow lite",
	"issue_body": "I am doing object detection using tensorflow  lite. My code detects the object & add a label with it & also display the label with it, but after that, I want to display the label of an object which is detected separately.\r\n& I want that point (trigger point) in code from where the label is displayed .\r\ncan you please help me to find out code .\r\n I am giving link of  my source code :\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/android",
	"issue_comments": "3"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "394787625",
	"issue_number": "24622",
	"issue_state": "closed",
	"issue_title": "tf.keras.utils.plot_model() raises TypeError: 'InputLayer' object is not iterable",
	"issue_body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac OS X 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION=\"1.13.0-dev20181226\" (this is the TF 2.0-preview)\r\nGIT_VERSION=\"b'v1.12.0-5133-gc343196842'\"\r\n- Python version:\r\n3.6.6\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\ntf.keras.utils.plot_model() raises `TypeError: 'InputLayer' object is not iterable`\r\n\r\n**Describe the expected behavior**\r\nI expect it to save a png image of the model.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Dense(3, input_shape=[2]))\r\nmodel.add(tf.keras.layers.Dense(1))\r\ntf.keras.utils.plot_model(model, to_file='my_model.png')\r\n```\r\n\r\n**Other info / logs**\r\nI ran the code in TF 1.12, no problem.\r\n\r\nHere is the traceback in TF 2.0-preview:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/ageron/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/utils/vis_utils.py\", line 148, in plot_model\r\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\r\n  File \"/Users/ageron/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/utils/vis_utils.py\", line 123, in model_to_dot\r\n    for inbound_layer in node.inbound_layers:\r\nTypeError: 'InputLayer' object is not iterable\r\n```",
	"issue_comments": "3"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "400117361",
	"issue_number": "24984",
	"issue_state": "closed",
	"issue_title": "Unable to install tensorflow 2.0 nightly for python 3.4",
	"issue_body": "OS version: Ubuntu 14.04\r\nWhen I run I get the below output\r\n pip install tf-nightly-2.0-preview\r\nCollecting tf-nightly-2.0-preview\r\n  Could not find a version that satisfies the requirement tf-nightly-2.0-preview (from versions: )\r\nNo matching distribution found for tf-nightly-2.0-preview\r\n",
	"issue_comments": "4"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "427364477",
	"issue_number": "27336",
	"issue_state": "closed",
	"issue_title": "Add examples of loading model that has been saved with save_keras_model",
	"issue_body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/tutorials/images/hub_with_keras\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe above example provides no example of loading the model after it's saved. I'm used to using the \"old style\" of freezing, optimizing (`optimize_for_inference_lib.optimize_for_inference`), and saving models with:\r\n`tf.train.write_graph(output_graph_def, output_dir, 'model.pb', as_text=False)`\r\n\r\nWhich gives me a graph: `model.pb`. I run predictions on this graph locally on my mobile applications with full Tensorflow (in Unity, so not using TF-Lite).\r\n\r\nIn my local prediction script, I load the graph like this:\r\n```python\r\ndef load_graph(model_file):\r\n  graph = tf.Graph()\r\n  graph_def = tf.GraphDef()\r\n\r\n  with open(model_file, \"rb\") as f:\r\n    graph_def.ParseFromString(f.read())\r\n  with graph.as_default():\r\n    tf.import_graph_def(graph_def)\r\n  return graph\r\n```\r\nThen grab the graph input and output ops and run a prediction session. This works pretty well.\r\n\r\nHowever, this new example uses `tf.contrib.saved_model.save_keras_model` to export the model, which I would love to use because it exports all kinds of useful information (which I'd like to use in conjunction with TF Serving for certain applications), and it looks to be making it into TF 2.0 core.\r\n\r\nWith `save_keras_model`, I end up with:\r\n`assets  labels.csv  saved_model.pb  variables`\r\n\r\nWhen trying to use my old graph loading script with this newly generated model with `save_keras_model`, I get an error like this:\r\n```bash\r\n...\r\n    graph_def.ParseFromString(f.read())\r\ngoogle.protobuf.message.DecodeError: Error parsing message\r\n```\r\nThis had me puzzled, as I expected this `.pb` graph generated with the new API to work the same as the one I generated with `tf.train.write_graph`. Browsing through their contents, they look the same, but the newer API's model is smaller in file size. Which makes me wonder if it's missing something.\r\n\r\nI found an alternative method to load it as a graph anyways, but I ran into issues down the road with running it's ops, so I'm not sure I'm approaching this correctly by loading it as a graph, or if there's a \"new, Keras way\" of loading a model and running predictions. Maybe I'm too far in the weeds with trying to load this model as a graph and run it's ops, I'd expect there's a higher level API to do this.\r\n\r\n\r\nSo I have a few questions:\r\n- Is the exported `saved_model.pb` frozen?\r\n- Is it optimized? If not, I can convert the model I have to a graph, then back to a model for something like `save_keras_model`?\r\n\r\n**Ultimately**, can an example be added to this tutorial that demonstrates how to load a saved model?\r\n\r\n\r\nI wrote our initial codebase using TF 1.7 a little while back and I haven't changed much since then, but the API is changing a lot and I want to take full advantage of the advancements. Also I understand if this issue should be moved, I assumed this was appropriate since there was no documentation demonstrating loading a saved model with the new API.\r\n\r\nThank you! \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes\r\n",
	"issue_comments": "5"
},
{
	"login": "jvishnuvardhan",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "416600252",
	"issue_number": "26307",
	"issue_state": "closed",
	"issue_title": "Inconsistent encoding leads to AttributeError",
	"issue_body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat 7.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): compiled from source\r\n- TensorFlow version (use command below): r13.1\r\n- Python version: 3.6.3\r\n- Bazel version (if compiling from source): 0.22\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: P5000/16G\r\n\r\nDeepMind open-sourced the implementation of IMPALA: https://github.com/deepmind/scalable_agent\r\n\r\nFor parallelism, they wrap a mechanism which is class-based in doing so, the file is: https://github.com/deepmind/scalable_agent/blob/master/py_process.py\r\n\r\nThere is a code snippet at the beginning of the file:\r\n\r\n```\r\n  class Zeros(object):\r\n    def __init__(self, dim0):\r\n      self._dim0 = dim0\r\n    def compute(self, dim1):\r\n      return np.zeros([self._dim0, dim1], dtype=np.int32)\r\n    @staticmethod\r\n    def _tensor_specs(method_name, kwargs, constructor_kwargs):\r\n      dim0 = constructor_kwargs['dim0']\r\n      dim1 = kwargs['dim1']\r\n      if method_name == 'compute':\r\n        return tf.contrib.framework.TensorSpec([dim0, dim1], tf.int32)\r\n  with tf.Graph().as_default():\r\n    p = py_process.PyProcess(Zeros, 1)\r\n    result = p.proxy.compute(2)\r\n    with tf.train.SingularMonitoredSession(\r\n        hooks=[py_process.PyProcessHook()]) as session:\r\n      print(session.run(result))  # Prints [[0, 0]].\r\n\r\n```\r\nhowever, when I tried to run it, I got the following error:\r\n\r\n```\r\n2019-03-01 17:37:16.260732: W tensorflow/core/framework/op_kernel.cc:1389] Unknown: AttributeError: 'Zeros' object has no attribute 'b'compute''\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/yuming/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/data/yuming/eeg-dpg/py_process.py\", line 89, in py_call\r\n    raise result\r\n\r\nAttributeError: 'Zeros' object has no attribute 'b'compute''\r\n\r\n```\r\n\r\nI suspect maybe there is a mismatch between encoding, but not for sure, since I have no problem in running the code if I use Python 2.7.\r\n\r\nCould anyone please take some effort on looking into it?\r\n",
	"issue_comments": "1"
},
{
	"login": "Flamefire",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "517176876",
	"issue_number": "33975",
	"issue_state": "opened",
	"issue_title": "Bazel build does not pick up correct compiler include paths",
	"issue_body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.5\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): GCC 8.2.0\r\n- CUDA/cuDNN version: 10.1\r\n\r\n\r\n**Describe the problem**\r\n\r\nBazel does not pick up the correct include paths of GCC and returns errors such as:\r\n\r\n```\r\nERROR: /tmp/easybuild-tmp/eb-5QGVSJ/tmpMZolLj-bazel-build/external/fft2d/BUILD.bazel:27:1: undeclared inclusion(s) in rule '@fft2d//:fft2d':\r\nthis rule is missing dependency declarations for the following files included by 'external/fft2d/fft2d/fftsg2d.c':\r\n  '/sw/installed/GCCcore/8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0/include/stddef.h'\r\n  '/sw/installed/GCCcore/8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0/include/stdarg.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- `TF_NEED_CUDA=1 ./configure`\r\n- `export TF_MKL_DOWNLOAD=1 &&   bazel --output_base=/tmp/easybuild-tmp/eb-5QGVSJ/tmpMZolLj-bazel-build --install_base=/tmp/easybuild-tmp/eb-5QGVSJ/tmpMZolLj-bazel-build/inst_base --output_user_root=/tmp/easybuild-tmp/eb-5QGVSJ/tmp514aJM-user_root build --compilation_mode=opt --config=opt --subcommands --verbose_failures --jobs=24 --action_env=PYTHONPATH --action_env=EBPYTHONPREFIXES --distinct_host_configuration=false  --config=mkl //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nNote that the installation is triggered via EasyBuild\r\n\r\n**Any other info / logs**\r\n[command.log](https://github.com/tensorflow/tensorflow/files/3804323/command.log)\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "robieta",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "463408435",
	"issue_number": "30324",
	"issue_state": "closed",
	"issue_title": "Memory leak in eager mode when creating keras model in loop",
	"issue_body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not tested\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-5259-ge703239 1.15.0-dev20190629\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): not compiled from source\r\n- GCC/Compiler version (if compiling from source): not compiled from source\r\n- CUDA/cuDNN version: using CPU\r\n- GPU model and memory: using CPU\r\n\r\n**Describe the current behavior**\r\n\r\nIn eager execution, when creating a `tf.keras.Sequential` model inside a loop and discarding it immediately, the memory increases over time. The following code shows this by printing the used memory at each iteration.\r\n\r\n```python\r\nimport psutil\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.enable_eager_execution()\r\n\r\nfor _ in range(100):\r\n    tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])\r\n    print(psutil.virtual_memory().used / 2 ** 30)\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n1.0170440673828125\r\n1.0506706237792969\r\n1.0841865539550781\r\n1.1179122924804688\r\n[...]\r\n4.285423278808594\r\n4.318950653076172\r\n4.35223388671875\r\n```\r\n\r\nThe same result happens when using the Functional API or Model subclassing API. Adding `tf.keras.backend.clear_session()` in the loop solves the leak in all cases like in graph mode. To see this effect better, one should additionally use `gc.collect()` in the loop.\r\n\r\n**Describe the expected behavior**\r\n\r\nWhile adding `tf.keras.backend.clear_session()` to the loop helps, this should not be necessary because in eager execution there is no graph to clear, which according to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session) seems to be the only thing this function does:\r\n\r\n> Destroys the current TF graph and creates a new one.\r\n\r\nTherefore it is also suprising that this function helps at all during eager execution. The expected behavior is that there is no memory leak even without `tf.keras.backend.clear_session()`. \r\n\r\n**Code to reproduce the issue**\r\nCode is in description above.\r\n\r\n**Other info / logs**\r\nNothing here.",
	"issue_comments": "15"
},
{
	"login": "robieta",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "463171263",
	"issue_number": "30306",
	"issue_state": "closed",
	"issue_title": "[tf.keras] predict_generator stuck with using use_multiprocessing=True",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Tesla P100 - 16280MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen I use `model.predict_generator` with `use_multiprocessing=True` the code gets stuck.\r\n**Describe the expected behavior**\r\nIdeally the code should not get stuck and all cores should be used for predictions.\r\n**Code to reproduce the issue**\r\n\r\n```\r\nfrom tensorflow.keras.layers import Conv3D, MaxPool3D, Flatten, Dense\r\nfrom tensorflow.keras.layers import Dropout, Input, BatchNormalization\r\nfrom tensorflow.keras.layers import AvgPool3D\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.utils import Sequence\r\nfrom tensorflow.keras import callbacks\r\nfrom tensorflow.keras.layers import Concatenate, Add\r\nfrom tensorflow.keras.estimator import model_to_estimator\r\nfrom tensorflow.keras.utils import multi_gpu_model\r\nfrom tensorflow.keras.utils import Sequence\r\nimport tensorflow as tf\r\n\r\n\r\ndef build_model(input_shape=(128, 128, 50, 1), n_class=3, multilabel=False):\r\n   \r\n    def spatial_reduction_block(inputs, block_name):\r\n        filters = inputs._shape_as_list()[-1]\r\n        with tf.name_scope(block_name):\r\n            maxpool = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(inputs)\r\n            conv_a_0 = Conv3D(filters=filters//4, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu')(inputs)\r\n            conv_b_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n            conv_c_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n\r\n            conv_b_1 = Conv3D(filters=(5*filters)//16, kernel_size=(3, 3, 3), strides=(2, 2, 2), \r\n                              padding='same', activation='relu')(conv_b_0)\r\n            conv_c_1 = Conv3D(filters=(5*filters)//16, kernel_size=(3, 3, 3), strides=(1, 1, 1), \r\n                              padding='same', activation='relu')(conv_c_0)\r\n            conv_c_2 = Conv3D(filters=(7*filters)//16, kernel_size=(3, 3, 3), strides=(2, 2, 2), \r\n                              padding='same', activation='relu')(conv_c_1)\r\n\r\n            concat_output = Concatenate()([maxpool, conv_a_0, conv_b_1, conv_c_2])\r\n\r\n        return concat_output\r\n\r\n    def residual_convolution_block(inputs, block_name):\r\n        filters = inputs._shape_as_list()[-1]\r\n        with tf.name_scope(block_name):\r\n            conv_a_0 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n            conv_b_0 = Conv3D(filters=filters//2, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n            conv_c_0 = Conv3D(filters=filters//2, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n\r\n            conv_b_1 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_b_0)\r\n            conv_c_1 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_c_0)\r\n            conv_c_2 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_c_1)\r\n\r\n            concat_output = Concatenate()([conv_a_0, conv_b_1, conv_c_2])\r\n\r\n            conv_d_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(concat_output)\r\n\r\n            add_1 = Add()([conv_d_0, inputs])\r\n\r\n        return add_1\r\n    \r\n    if not multilabel:\r\n        activation_fn = 'softmax'\r\n    else:\r\n        activation_fn = 'sigmoid'\r\n    \r\n    inputs = Input(shape=input_shape, name='inputs')\r\n    conv_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n    spatial_reduction_block_1 = spatial_reduction_block(conv_1, 'spatial_reduction_block_1')\r\n    residual_convolution_block_1 = residual_convolution_block(spatial_reduction_block_1, 'residual_convolution_block_1')\r\n    spatial_reduction_block_2 = spatial_reduction_block(residual_convolution_block_1, 'spatial_reduction_block_2')\r\n    residual_convolution_block_2 = residual_convolution_block(spatial_reduction_block_2, 'residual_convolution_block_2')\r\n    conv_2 = Conv3D(filters=512, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(residual_convolution_block_2)\r\n    maxpool_1 = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(conv_2)\r\n    conv_3 = Conv3D(filters=1024, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(maxpool_1)\r\n    maxpool_2 = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(conv_3)\r\n    flatten = Flatten()(maxpool_2)\r\n    dropout_1 = Dropout(rate=0.2)(flatten)\r\n    dense_1 = Dense(512, activation='sigmoid')(dropout_1)\r\n    dropout_2 = Dropout(rate=0.2)(dense_1)\r\n    outputs = Dense(n_class, activation=activation_fn, name='outputs')(dropout_2)\r\n    \r\n    model = Model(inputs=inputs, outputs=outputs)\r\n    return model\r\n\r\nmodel = build_model((128,128,50, 1), 3, False)\r\n\r\nclass mygenerator(Sequence):\r\n    def __init__(self, x_set, y_set, batch_size, augment=False):\r\n        self.x, self.y = x_set, y_set\r\n        self.batch_size = batch_size\r\n        self.augment = augment\r\n    \r\n    def __len__(self):\r\n        return int(np.ceil(len(self.x) / float(self.batch_size)))\r\n    \r\n    def __getitem__(self, idx):\r\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        \r\n        x = [read_image(filename, self.augment) for filename in batch_x] # read a numpy array named filename\r\n        y = [read_label(label) for label in batch_y]\r\n        \r\n        return np.array(x), np.array(y)\r\n\r\ntest_generator = mygenerator(X_TEST, Y_TEST, eval_batch_size, augment=False)\r\n\r\npreds = model.predict_generator(test_generator, verbose=1, use_multiprocessing=True, steps=eval_steps)\r\n\r\n```\r\n**Other info / logs**\r\nNA",
	"issue_comments": "14"
},
{
	"login": "robieta",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "335344594",
	"issue_number": "20273",
	"issue_state": "closed",
	"issue_title": "Add examples to documentation for CudnnRNN",
	"issue_body": "Have I written custom code: N/A\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nTensorFlow version: 1.8.0\r\nBazel version: N/A\r\nCUDA/cuDNN version: 9.0/7.0\r\nGPU model and memory: NVIDIA GTX 1080 Ti\r\nExact command to reproduce: N/A\r\n\r\nIt would be very helpful to add usage examples on how to use `cudnn_rnn`, particularly on cross-compatibility between non-CUDA and CUDA-supporting devices. Users should be able to figure out how to save/restore weights to run their models with, say, `tf.nn.rnn_cell.LSTMCell` or `tf.contrib.cudnn_rnn.CudnnLSTM`.\r\n\r\nThere are classes that seem to do this (e.g. `tf.contrib.cudnn_rnn.CudnnLSTMSaveable`) but there are no easily accessible code examples showing how they should be used.\r\n\r\n*A possible feature request*: would it be possible to have a high-level wrapper that makes this choice automatically based on the availability of a CUDA device, saving and restoring weights accordingly? This should be possible with `tf.test.is_gpu_available(cuda_only=True)`.",
	"issue_comments": "8"
},
{
	"login": "robieta",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "329741795",
	"issue_number": "19795",
	"issue_state": "closed",
	"issue_title": "Tensorflow logs everything twice while training",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nmacOS Sierra version 10.12.6\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.8.0\r\n- **Python version**: \r\n3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n0.13.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\nGCC 4.2.1\r\n\r\n### Describe the problem\r\nI'm training an object detection model using the new `ssdlite_mobilenet_v2_coco_2018_05_09` and it's configuration file `ssdlite_mobilenet_v2_coco.config` and tensorflow installed from source. When I launch the training tensorflow starts printing the same info twice. \r\n\r\nThis problem didn't happen while training the same network I'm trying to get, with a different model (checkpoint)  `ssd_mobilenet_v1_coco_2017_11_17` and the configuration file `ssd_mobilenet_v1_pets.config` and with tensorflow installed from pip (I tested with version 1.6.0 and 1.8.0) \r\n\r\nNOTE : I didn't change the code in both cases and I wonder what's the cause of this.\r\n\r\n### Source code / logs\r\n\r\n```\r\nINFO:tensorflow:global step 3292: loss = 3.2832 (2.960 sec/step)\r\nINFO:tensorflow:global step 3292: loss = 3.2832 (2.960 sec/step)\r\nINFO:tensorflow:global step 3293: loss = 3.5285 (3.675 sec/step)\r\nINFO:tensorflow:global step 3293: loss = 3.5285 (3.675 sec/step)\r\nINFO:tensorflow:global step 3294: loss = 2.3972 (3.564 sec/step)\r\nINFO:tensorflow:global step 3294: loss = 2.3972 (3.564 sec/step)\r\nINFO:tensorflow:Recording summary at step 3294.\r\nINFO:tensorflow:Recording summary at step 3294.\r\nINFO:tensorflow:global_step/sec: 0.294019\r\nINFO:tensorflow:global_step/sec: 0.294019\r\n```\r\n",
	"issue_comments": "4"
},
{
	"login": "njeffrie",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "463265356",
	"issue_number": "30314",
	"issue_state": "closed",
	"issue_title": "TensorFlow Lite Micro int8 quantization support?",
	"issue_body": "\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: STM32F746G\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: '1.14.0'\r\n- **Python version**: 3.7.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\n[feature request] \r\n.tflite model exported with a tensorflow version > r.1.13 are not compatible anymore with TensorFlow Lite Micro experimental Library. \r\n\r\nKernels functions has to be updated to support asymetric per-axis quantization. \r\n\r\nIs there any release schedule on this lib?\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n",
	"issue_comments": "7"
},
{
	"login": "tatatodd",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "175520820",
	"issue_number": "4252",
	"issue_state": "closed",
	"issue_title": "make -f tensorflow/contrib/makefile/Makefile for iOS is failing",
	"issue_body": "Probably related to [issue 2896](https://github.com/tensorflow/tensorflow/issues/2896)\r\n\r\nI am trying to build tensorflow on a mac for iOS. The first two commands work well:\r\n`tensorflow/contrib/makefile/download_dependencies.sh`\r\nand\r\n`compile_ios_protobuf.sh`\r\n\r\nHowever, when I call\r\n`make -f tensorflow/contrib/makefile/Makefile \\\r\n TARGET=IOS \\\r\n IOS_ARCH=ARM64`\r\n\r\nI receive a linker error:\r\n\r\n> Undefined symbols for architecture x86_64:\r\n  \"tensorflow::io::InputStreamInterface::SkipNBytes(long long)\", referenced from:\r\n      vtable for tensorflow::io::ZlibInputStream in zlib_inputstream.o\r\n  \"tensorflow::io::RandomAccessInputStream::RandomAccessInputStream(tensorflow::RandomAccessFile*)\", referenced from:\r\n      tensorflow::io::RecordReader::RecordReader(tensorflow::RandomAccessFile*, tensorflow::io::RecordReaderOptions const&) in record_reader.o\r\n  \"typeinfo for tensorflow::io::InputStreamInterface\", referenced from:\r\n      typeinfo for tensorflow::io::ZlibInputStream in zlib_inputstream.o\r\n  \"vtable for tensorflow::io::InputStreamInterface\", referenced from:\r\n      tensorflow::io::InputStreamInterface::InputStreamInterface() in zlib_inputstream.o\r\n  NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake: *** [/Users/senad/repos/tensorflow2/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1\r\n+ '[' 2 -ne 0 ']'\r\n+ echo 'armv7 compilation failed.'\r\narmv7 compilation failed.\r\n+ exit 1\r\n\r\nI tried it with the current master commit `f71cc62f71cc62`. After reading the discussion of issue 2896, I also tried it with the commit `582e6c8582e6c8`. This is the one that supposedly fixed the issue in the other ticket.",
	"issue_comments": "9"
},
{
	"login": "tatatodd",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "175678149",
	"issue_number": "4268",
	"issue_state": "closed",
	"issue_title": "resize_image_with_crop_or_pad loses channel information",
	"issue_body": "```python\r\npng = tf.image.resize_image_with_crop_or_pad(png_raw, 100, 100)\r\n```\r\nbefore:\r\n```\r\nTensorShape([Dimension(None), Dimension(None), Dimension(3)])\r\n```\r\nafter:\r\n```\r\nTensorShape([Dimension(100), Dimension(100), Dimension(None)]\r\n```\r\n\r\n`tf.image.pad_to_bounding_box` has the same problem.\r\nThe combination of these two lines seems questionable:\r\n```\r\nheight, width, depth = _ImageDimensions(image, static_only=False)\r\npadded_shape = [None if is_tensor(i) else i\r\n                  for i in [target_height, target_width, depth]]\r\n```\r\nwhy set `static_only=False`? The docs for `_ImageDimensions` say:\r\n>    list of integers `[batch, height, width, channels]`, when static shape is\r\n    fully defined or `static_only` is `True`.\r\n    list of integer scalar tensors `[batch, height, width, channels]`, when\r\n    static shape is not fully defined.\r\n\r\nso unless all dimensions of the image are defined you will get tensors which will then be changed to `None`.",
	"issue_comments": "7"
},
{
	"login": "tatatodd",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "181629216",
	"issue_number": "4816",
	"issue_state": "closed",
	"issue_title": "tensroflow 0.11rc conflict with boost.python generated so",
	"issue_body": "My application will use both tensorflow and some so generated by boost.python(1.53) running on centos 6.3 with cuda 7.5 and cudnn 4 .\r\nThe problem is everything is fine with tensorflow 0.10, but changing to tensorflow 0.11rc, then \r\nI will always face segmentation fault (double free) before the program stop running, especially if using numpy also, and if changing import library sequence  might decrease the chance of facing double free, but still not fully solve the problem.\r\n",
	"issue_comments": "1"
},
{
	"login": "tatatodd",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "176002951",
	"issue_number": "4297",
	"issue_state": "closed",
	"issue_title": "'SAME' padding works incorrect",
	"issue_body": "I have 28x28 image. When I apply convolution (or pooling) with 'SAME' padding, kernel size 2x2, stride 2, it produces feature map of size 14x14, but it should be 15x15, so the last (bottom and right) image pixels would't be processed. The output size should be calculated with formula output = [(input+2*padding-kernel) / stride] + 1 (look https://arxiv.org/pdf/1603.07285.pdf). In case of 'SAME', padding size would be [kernel/2]\r\nTF version 0.9.0\r\n",
	"issue_comments": "3"
},
{
	"login": "vincentvanhoucke",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "120365195",
	"issue_number": "407",
	"issue_state": "closed",
	"issue_title": "Adding new op, no c++ wrapper gen and user_ops.h not found",
	"issue_body": "I followed wiki of adding new op\r\nhttps://github.com/jikexueyuanwiki/tensorflow-zh/blob/master/SOURCE/how_tos/adding_an_op/index.md\r\n\r\nBut after rebuild successfully using \r\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\r\npip install /tmp/tensorflow_pkg/tensorflow-0.5.0-py2-none-any.whl\r\n\r\nNo user_op.zero_out found.\r\n\r\nIt seems python wrapper automatically generated ok,\r\n ./bazel-genfiles/tensorflow/python/ops/gen_user_ops.py \r\n\r\nBut c++ wrapper not generated,\r\nI can not find ./bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}., though tensorflow/core/user_ops/zero_out.cc exists.\r\n\r\n\"The C++ Op wrapper\r\n\r\nC++ op wrappers are created automatically for all ops placed in the tensorflow/core/user_ops directory, when you build Tensorflow. For example, ops in tensorflow/core/user_ops/zero_out.cc will generate wrappers in bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}.\"",
	"issue_comments": "1"
},
{
	"login": "daniellepintz",
	"repo_name": "PyTorchLightning/pytorch-lightning",
	"issue_id": "972086308",
	"issue_number": "8940",
	"issue_state": "opened",
	"issue_title": "Deprecate add_to_queue / get_from_queue",
	"issue_body": "## \ud83d\ude80 Feature\r\n\r\nDeprecate these two functions from the lightning interface:\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/4b6aaeeae3c53c45cf31a7fc2cf90133acfe5d12/pytorch_lightning/core/lightning.py#L1989-L2014\r\n\r\n### Motivation\r\n\r\nBoth of these hooks are hyper-specific to transferring data in a spawned manner. They are not related to ML code at all and should not be on the lightning module interface\r\n\r\nmore discussion here: https://docs.google.com/document/d/1xHU7-iQSpp9KJTjI3As2EM0mfNHHr37WZYpDpwLkivA/edit?disco=AAAANaZ8IYw\r\n\r\n\r\n### Pitch\r\n\r\n* Deprecate this method in v1.5\r\n* Remove this method in v1.7\r\n\r\n### Alternatives\r\n\r\n### Additional context\r\n\r\n______________________________________________________________________\r\n\r\n#### If you enjoy Lightning, check out our other projects! \u26a1\r\n\r\n<sub>\r\n\r\n- [**Metrics**](https://github.com/PyTorchLightning/metrics): Machine learning metrics for distributed, scalable PyTorch applications.\r\n\r\n- [**Flash**](https://github.com/PyTorchLightning/lightning-flash): The fastest way to get a Lightning baseline! A collection of tasks for fast prototyping, baselining, finetuning and solving problems with deep learning\r\n\r\n- [**Bolts**](https://github.com/PyTorchLightning/lightning-bolts): Pretrained SOTA Deep Learning models, callbacks and more for research and production with PyTorch Lightning and PyTorch\r\n\r\n- [**Lightning Transformers**](https://github.com/PyTorchLightning/lightning-transformers): Flexible interface for high performance research using SOTA Transformers leveraging Pytorch Lightning, Transformers, and Hydra.\r\n\r\n</sub>\r\n",
	"issue_comments": "0"
},
{
	"login": "rmlarsen",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "147871334",
	"issue_number": "1893",
	"issue_state": "closed",
	"issue_title": "Problem with shape inference with diag_part operator. ",
	"issue_body": "Running` from master the following small code snippet gives an error.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nW = tf.constant(3., tf.float64)\r\nX = tf.placeholder(tf.float64, [5,3])\r\nY = tf.scalar_mul( W , tf.ones(tf.pack([tf.shape(X)[0], tf.shape(X)[0]]), tf.float64) )\r\nZ = tf.diag_part(Y)\r\n\r\ninit = tf.initialize_all_variables()\r\n\r\nsess = tf.Session()\r\nsess.run(init)\r\nprint(sess.run(Z, feed_dict={X: np.ones((5,3))}))\r\n```\r\n\r\nThe relevant part of the error is \r\n\r\n> /tensorflow/python/ops/array_ops.py\", line 960, in _DiagPartShape\r\n>     \" do not match \")\r\n> ValueError: Invalid shape, shape[:mid] \\(?,\\) and shape[mid:] \\(?,\\) do not match \r\n> \r\n\r\nI think it is reasonable to be able to get the diagonal of this matrix. Therefore I think this is a bug with the shape inference. \r\n\r\nThanks,\r\nAlex ",
	"issue_comments": "3"
},
{
	"login": "jplu",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "340728994",
	"issue_number": "20747",
	"issue_state": "closed",
	"issue_title": "TPU code running locally but not on TPU",
	"issue_body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, I did put the code below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9\r\n- **TensorFlow installed from (source or binary)**: already installed while creating the VM\r\n- **TensorFlow version (use command below)**: 1.9.0-rc2\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: Not compiled\r\n- **GCC/Compiler version (if compiling from source)**: Not compiled\r\n- **CUDA/cuDNN version**: not installed\r\n- **GPU model and memory**: no GPU\r\n- **Exact command to reproduce**: ```python3 test.py --tpu=$TPU_NAME --model_dir=output -use-tpu=True --batch_size=24```\r\n\r\n### Describe the problem\r\nWhen I run the following code:\r\n\r\n```python\r\nfrom tensorflow.python.keras.applications.vgg16 import VGG16\r\nfrom tensorflow.python.keras import models\r\nfrom tensorflow.python.keras import layers\r\nfrom tensorflow.python.keras.preprocessing import image\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom absl import flags\r\nimport absl.logging as _logging\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_config\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_estimator\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_optimizer\r\nimport numpy as np\r\nimport random\r\nimport math\r\nimport os\r\n\r\n\r\n#  Cloud TPU Cluster Resolver flags\r\ntf.flags.DEFINE_string(\r\n    \"tpu\", default=None,\r\n    help=\"The Cloud TPU to use for training. This should be either the name \"\r\n    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\r\n    \"url.\")\r\ntf.flags.DEFINE_string(\r\n    \"tpu_zone\", default=None,\r\n    help=\"[Optional] GCE zone where the Cloud TPU is located in. If not \"\r\n    \"specified, we will attempt to automatically detect the GCE project from \"\r\n    \"metadata.\")\r\ntf.flags.DEFINE_string(\r\n    \"gcp_project\", default=None,\r\n    help=\"[Optional] Project name for the Cloud TPU-enabled project. If not \"\r\n    \"specified, we will attempt to automatically detect the GCE project from \"\r\n    \"metadata.\")\r\n\r\n# Model specific parameters\r\ntf.flags.DEFINE_string(\r\n    \"master\", default=None,\r\n    help=\"GRPC URL of the master (e.g. grpc://ip.address.of.tpu:8470). You \"\r\n    \"must specify either this flag or --tpu.\")\r\ntf.flags.DEFINE_string(\"data_dir\", \"\",\r\n                       \"Path to directory containing the dataset\")\r\ntf.flags.DEFINE_string(\"model_dir\", 'output', \"Estimator model_dir\")\r\ntf.flags.DEFINE_integer(\"batch_size\", 3,\r\n                        \"Mini-batch size for the training. Note that this \"\r\n                        \"is the global batch size and not the per-shard batch.\")\r\ntf.flags.DEFINE_integer(\"train_steps\", 1, \"Total number of training steps.\")\r\ntf.flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate.\")\r\n\r\ntf.flags.DEFINE_bool(\"use_tpu\", True, \"Use TPUs rather than plain CPUs\")\r\ntf.flags.DEFINE_integer(\"iterations\", 1,\r\n                        \"Number of iterations per TPU training loop.\")\r\ntf.flags.DEFINE_integer(\"num_shards\", 8, \"Number of shards (TPU chips).\")\r\n\r\nFLAGS = tf.flags.FLAGS\r\n\r\nfeature_names = [\r\n    'query',\r\n    'positive',\r\n    'negative']\r\n\r\ndef load_triplets():\r\n    triplets = []\r\n    triplet_file = os.path.join(FLAGS.data_dir, 'triplets.txt')\r\n    with tf.gfile.GFile(triplet_file) as f:\r\n        count = 0\r\n        for line in f:\r\n            triplets.append(line.strip().split(','))\r\n            count += 1\r\n            if count % 1000 == 0:\r\n                tf.logging.info(\"Loading {} triplets\".format(count))\r\n\r\n    tf.logging.info(\"Loading {} triplets\".format(count))\r\n    return triplets\r\n\r\ndef my_input_fn(triplet, label):\r\n    query_img = tf.image.decode_jpeg(triplet[0], channels=3)\r\n    query_img.set_shape([None, None, None])\r\n    query_img = tf.image.resize_images(query_img, [224, 224])\r\n    query_img.set_shape([224, 224, 3])\r\n    positive_img = tf.image.decode_jpeg(tf.read_file(triplet[1]), channels=3)\r\n    positive_img.set_shape([None, None, None])\r\n    positive_img = tf.image.resize_images(positive_img, [224, 224])\r\n    positive_img.set_shape([224, 224, 3])\r\n    negative_img = tf.image.decode_jpeg(tf.read_file(triplet[2]), channels=3)\r\n    negative_img.set_shape([None, None, None])\r\n    negative_img = tf.image.resize_images(negative_img, [224, 224])\r\n    negative_img.set_shape([224, 224, 3])\r\n\r\n    return dict(zip(feature_names, [query_img, positive_img, negative_img])), label\r\n\r\ndef random_flip_left_right(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_flip_left_right(image['query'])\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_flip_left_right(image['positive'])\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_flip_left_right(image['negative'])\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_flip_up_down(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_flip_up_down(image['query'])\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_flip_up_down(image['positive'])\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_flip_up_down(image['negative'])\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\n\r\ndef random_brightness(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_brightness(image['query'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_brightness(image['positive'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_brightness(image['negative'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_contrast(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_contrast(image['query'], lower=0.3, upper=1.0)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_contrast(image['positive'], lower=0.3, upper=1.0)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_contrast(image['negative'], lower=0.3, upper=1.0)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_hue(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_hue(image['query'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_hue(image['positive'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_hue(image['negative'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_saturation(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_saturation(image['query'], lower=0.0, upper=2.0)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_saturation(image['positive'], lower=0.0, upper=2.0)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_saturation(image['negative'], lower=0.0, upper=2.0)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_rotate(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.contrib.image.rotate(image['query'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.contrib.image.rotate(image['positive'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.contrib.image.rotate(image['negative'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef train_input_fn(params):\r\n    batch_size = params[\"batch_size\"]\r\n    triplets = load_triplets()\r\n    triplets_const = tf.constant(triplets)\r\n    labels_const =tf.zeros([len(triplets)], tf.int32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((triplets_const, labels_const))\r\n    dataset = dataset.shuffle(buffer_size=len(triplets))\r\n    triplets.clear()\r\n    dataset = dataset.map(my_input_fn)\r\n\r\n    augmented_flip_left_right = dataset.map(random_flip_left_right)\r\n    dataset = dataset.concatenate(augmented_flip_left_right)\r\n    augmented_flip_up_down = dataset.map(random_flip_up_down)\r\n    dataset = dataset.concatenate(augmented_flip_up_down)\r\n    augmented_brightness = dataset.map(random_brightness)\r\n    dataset = dataset.concatenate(augmented_brightness)\r\n    augmented_contrast = dataset.map(random_contrast)\r\n    dataset = dataset.concatenate(augmented_contrast)\r\n    augmented_hue = dataset.map(random_hue)\r\n    dataset = dataset.concatenate(augmented_hue)\r\n    augmented_saturation = dataset.map(random_saturation)\r\n    dataset = dataset.concatenate(augmented_saturation)\r\n    augmented_rotate = dataset.map(random_rotate)\r\n    dataset = dataset.concatenate(augmented_rotate)\r\n\r\n    ds = dataset.cache().repeat().apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n    triplets, labels = ds.make_one_shot_iterator().get_next()\r\n\r\n    return triplets, labels\r\n\r\n\r\ndef convnet_model_():\r\n    vgg_model = VGG16(weights=None, include_top=False)\r\n    x = vgg_model.output\r\n    x = layers.GlobalAveragePooling2D()(x)\r\n    x = layers.Dense(4096, activation='relu')(x)\r\n    x = layers.Dropout(0.6)(x)\r\n    x = layers.Dense(4096, activation='relu')(x)\r\n    x = layers.Dropout(0.6)(x)\r\n    x = layers.Lambda(lambda x_: keras.backend.l2_normalize(x_, axis=1))(x)\r\n    convnet_model = models.Model(inputs=vgg_model.input, outputs=x)\r\n\r\n    return convnet_model\r\n\r\n_EPSILON = keras.backend.epsilon()\r\ndef _loss_tensor(y_true, y_pred):\r\n    y_pred = keras.backend.clip(y_pred, _EPSILON, 1.0-_EPSILON)\r\n    loss = tf.convert_to_tensor(0, dtype=tf.float32)\r\n    g = tf.constant(1.0, shape=[1], dtype=tf.float32)\r\n    #for i in range(0, 24, 3):\r\n    for i in range(0, FLAGS.batch_size, 3):\r\n        try:\r\n            q_embedding = y_pred[i+0]\r\n            p_embedding = y_pred[i+1]\r\n            n_embedding = y_pred[i+2]\r\n            D_q_p = keras.backend.sqrt(keras.backend.sum((q_embedding - p_embedding)**2))\r\n            D_q_n = keras.backend.sqrt(keras.backend.sum((q_embedding - n_embedding)**2))\r\n            loss = (loss + g + D_q_p - D_q_n)\r\n        except:\r\n            continue\r\n    #loss = loss / 8\r\n    loss = loss / FLAGS.batch_size\r\n    zero = tf.constant(0.0, shape=[1], dtype=tf.float32)\r\n\r\n    return tf.maximum(loss, zero)\r\n\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    del params\r\n\r\n    convnet_model = convnet_model_()\r\n    first_input = layers.Input(shape=(224, 224, 3))\r\n    first_conv = layers.Conv2D(96, kernel_size=(8, 8), strides=(16, 16), padding='same')(first_input)\r\n    first_max = layers.MaxPool2D(pool_size=(3, 3), strides=(4, 4), padding='same')(first_conv)\r\n    first_max = layers.Flatten()(first_max)\r\n    first_max = layers.Lambda(lambda x: keras.backend.l2_normalize(x, axis=1))(first_max)\r\n    second_input = layers.Input(shape=(224, 224, 3))\r\n    second_conv = layers.Conv2D(96, kernel_size=(8, 8), strides=(32, 32), padding='same')(second_input)\r\n    second_max = layers.MaxPool2D(pool_size=(7, 7), strides=(2, 2), padding='same')(second_conv)\r\n    second_max = layers.Flatten()(second_max)\r\n    second_max = layers.Lambda(lambda x: keras.backend.l2_normalize(x, axis=1))(second_max)\r\n    merge_one = layers.concatenate([first_max, second_max])\r\n    merge_two = layers.concatenate([convnet_model.output, merge_one])\r\n    emb = layers.Dense(4096)(merge_two)\r\n    l2_norm_final = layers.Lambda(lambda x: keras.backend.l2_normalize(x, axis=1))(emb)\r\n    final_model = models.Model(inputs=[convnet_model.input, first_input, second_input], outputs=l2_norm_final)\r\n    final_model.summary()\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        logits = final_model([features['query'], features['positive'], features['negative']], training=False)\r\n        predictions = {\r\n            'embedding': logits[0]\r\n        }\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.PREDICT,\r\n            predictions=predictions,\r\n            export_outputs={\r\n                'classify': tf.estimator.export.PredictOutput(predictions)\r\n            })\r\n    logits = final_model([features['query'], features['positive'], features['negative']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    loss = _loss_tensor(None, logits)\r\n    optimizer = tf.train.MomentumOptimizer(learning_rate=FLAGS.learning_rate, momentum=0.9, use_nesterov=True)\r\n\r\n    if FLAGS.use_tpu:\r\n        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\r\n    return tf.contrib.tpu.TPUEstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=optimizer.minimize(loss, tf.train.get_global_step()))\r\n\r\n\r\ndef main(argv):\r\n    del argv\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n    if FLAGS.master is None and FLAGS.tpu is None:\r\n        raise RuntimeError('You must specify either --master or --tpu.')\r\n    if FLAGS.master is not None:\r\n        if FLAGS.tpu is not None:\r\n            tf.logging.warn('Both --master and --tpu are set. Ignoring '\r\n                      '--tpu and using --master.')\r\n        tpu_grpc_url = FLAGS.master\r\n    else:\r\n        tpu_cluster_resolver = (tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project))\r\n        tpu_grpc_url = tpu_cluster_resolver.get_master()\r\n\r\n    run_config = tpu_config.RunConfig(master=tpu_grpc_url, model_dir=FLAGS.model_dir, save_checkpoints_secs=3600, session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True), tpu_config=tpu_config.TPUConfig(iterations_per_loop=FLAGS.iterations, num_shards=FLAGS.num_shards),)\r\n    estimator = tpu_estimator.TPUEstimator(model_fn=model_fn, use_tpu=FLAGS.use_tpu, config=run_config, train_batch_size=FLAGS.batch_size)\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\r\n    img_input = tf.placeholder(tf.float32, [None, 224, 224, 3])\r\n    input_fn =tf.estimator.export.build_raw_serving_input_receiver_fn({\r\n        'query': img_input,\r\n        'positive': img_input,\r\n        'negative': img_input,\r\n    })\r\n    estimator.export_savedmodel('output', input_fn)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n```\r\nI get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 370, in <module>\r\n    tf.app.run()\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"test.py\", line 359, in main\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1143, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1168, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2162, in _call_model_fn\r\n    features, labels, mode, config)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1131, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2414, in _model_fn\r\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2724, in _train_on_tpu_system\r\n    device_assignment=ctx.device_assignment)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 829, in shard\r\n    name=name)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 475, in replicate\r\n    device_assignment, name)[1]\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 635, in split_compile_and_replicate\r\n    outputs = computation(*computation_inputs)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2717, in multi_tpu_train_steps_on_single_shard\r\n    single_tpu_train_step, [_INITIAL_LOSS])\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\r\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\r\n    name=\"\")\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\r\n    return_same_structure)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2924, in _BuildLoop\r\n    next_vars.append(_AddNextAndBackEdge(m, v))\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 666, in _AddNextAndBackEdge\r\n    _EnforceShapeInvariant(m, v)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 610, in _EnforceShapeInvariant\r\n    (input_t.name, input_t.shape, n_shape))\r\nValueError: Input tensor 'Const_1:0' enters the loop with shape (), but has shape (1,) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\r\n```\r\nWhile if I run the exact same code with ```--use_tpu=False --master=''``` it works like a charm.\r\n\r\nIs it somehow related to a bug or is it me who is doing something wrong with dedicated TPU code?\r\n\r\nThanks in advance.",
	"issue_comments": "4"
},
{
	"login": "shivaniag",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "259916766",
	"issue_number": "13245",
	"issue_state": "closed",
	"issue_title": "Links to Object_detection model no longer work",
	"issue_body": "Examples of broken links include\r\n\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/create_pascal_tf_record.py\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/g3doc/running_pets.md\r\n\r\nThanks!\r\n",
	"issue_comments": "1"
},
{
	"login": "MeghnaNatraj",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "509403245",
	"issue_number": "33526",
	"issue_state": "opened",
	"issue_title": "Error while trying to use tf.broadcast_weights ",
	"issue_body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Google Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Google Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.x\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: - \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nUnable to import tf.broadcast_weights in TF 2.0. \r\n\r\n**Describe the expected behavior**\r\nShould be able to import tf.broadcast_weights in TF 2.0\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nMethod 1: Plain python + TF 2.0\r\n```\r\nimport tensorflow as tf     # version 2.0\r\ntf.broadcast_weights\r\n```\r\nthrows AttributeError: module 'tensorflow' has no attribute 'broadcast_weights'\r\n\r\nMethod 2: Codelab\r\nI found this error in a recent TF 2.- + Keras tutorial - https://colab.sandbox.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO\r\n\r\n- Search for \"broadcast_weights\" in this codelab. \r\n- Run all cells before this.\r\n- Modify code \"m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\" to \"m.update_state([0, 1, 1, 1], [0, 1, 0, 0]), sample_weight=[0.1,0.2,0.3,0.4]\"\r\n- Run this cell\r\n- throws AttributeError: module 'tensorflow' has no attribute 'broadcast_weights'\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n",
	"issue_comments": "0"
},
{
	"login": "girving",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "116570241",
	"issue_number": "176",
	"issue_state": "closed",
	"issue_title": "Split a tensor with Tensor 0-D int32 as num_split argument",
	"issue_body": "Hi,\r\n\r\nAccording to the doc, th.split takes a 0-D int32 Tensor as num_split argument but executing :\r\n\r\nx = tf.placeholder(tf.float32, [5, None])\r\nnumsplit = tf.shape(x)[1]\r\nsplits = tf.split(1, numsplit, x)\r\n\r\nreturns :\r\n\r\n\"Expected int for argument 'num_split' not  < tensorflow.python.framework.ops.Tensor object at 0x7fcad834f810>\"\r\n\r\nIf the dimension is defined split also returns the same error :\r\n\r\nx = tf.placeholder(tf.float32, [5, 30])\r\nnumsplit = tf.shape(x)[1]\r\nsplits = tf.split(1, numsplit, x)\r\n\r\nSame thing with a constant as argument:\r\n\r\nx = tf.placeholder(tf.float32, [5, 30])\r\nnumsplit = tf.constant(30)\r\nsplits = tf.split(1, numsplit, x)\r\n\r\nAny ideas ?\r\n",
	"issue_comments": "2"
},
{
	"login": "girving",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "120262625",
	"issue_number": "405",
	"issue_state": "reopened",
	"issue_title": "gcc-4.8.1 wouldn't compile matrix_inverse_op.cc",
	"issue_body": "gcc-4.8.1 didn't like the way 'using' was used. This patch fixed the issue for me.\r\n\r\n[using_typename.txt](https://github.com/tensorflow/tensorflow/files/51293/using_typename.txt)\r\n",
	"issue_comments": "3"
},
{
	"login": "girving",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "124860296",
	"issue_number": "682",
	"issue_state": "closed",
	"issue_title": "TensorFlow on iOS",
	"issue_body": "In his NIPS tutorial, Jeff Dean mentioned that Google has an internal version of TensorFlow which runs on iOS.  Will this be open sourced?  If so, is there an estimate of how long until it will be available? ",
	"issue_comments": "1"
},
{
	"login": "girving",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "117686519",
	"issue_number": "281",
	"issue_state": "opened",
	"issue_title": "Reshape docs should mention that -1 can go anywhere",
	"issue_body": "I.e., -1 is not just for flattening, which is what the current docs say.",
	"issue_comments": "0"
},
{
	"login": "SamuelMarks",
	"repo_name": "keras-team/keras",
	"issue_id": "333592419",
	"issue_number": "10472",
	"issue_state": "opened",
	"issue_title": "Callback self.validation_data is None, when fit_generator is used",
	"issue_body": "Related: https://github.com/keras-team/keras/issues/2702\r\n\r\n- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:\r\npip install git+git://github.com/keras-team/keras.git --upgrade --no-deps\r\n\r\n- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).\r\n\r\n- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:\r\npip install git+git://github.com/Theano/Theano.git --upgrade --no-deps\r\n\r\n- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\r\n\r\nEvery epoch I like to run this `Callback`, to see how my model is performing:\r\n```python\r\nclass SensitivitySpecificityCallback(Callback):\r\n    def on_epoch_end(self, epoch, logs=None):\r\n        if epoch:\r\n            print('SensitivitySpecificityCallback::validation_data:',self.validation_data)\r\n            x_test = self.validation_data[0]\r\n            y_test = self.validation_data[1]\r\n            predictions = self.model.predict(x_test)\r\n            output_sensitivity_specificity(epoch, predictions, y_test)\r\n\r\ndef output_sensitivity_specificity(epoch, predictions, y_test):\r\n    y_test = np.argmax(y_test, axis=-1)\r\n    predictions = np.argmax(predictions, axis=-1)\r\n    c = confusion_matrix(y_test, predictions)\r\n    print('Confusion matrix:\\n', c)\r\n    print('[{:03d}] sensitivity'.format(epoch), c[0, 0] / (c[0, 1] + c[0, 0]))\r\n    print('[{:03d}] specificity'.format(epoch), c[1, 1] / (c[1, 1] + c[1, 0]))\r\n```\r\nRelevant parts of my new code:\r\n```python\r\nidg = ImageDataGenerator(horizontal_flip=True)\r\ntrain_seq = idg.flow_from_directory(train_dir, target_size=(pixels, pixels), shuffle=True)\r\nvalid_seq = idg.flow_from_directory(valid_dir, target_size=(pixels, pixels), shuffle=True)\r\ntest_seq  = idg.flow_from_directory(test_dir, target_size=(pixels, pixels), shuffle=True)\r\n\r\nmodel = Sequential()\r\n# ...\r\nmodel.compile(...)\r\nmodel.fit_generator(train_seq, validation_data=valid_seq, verbose=2,\r\n                    epochs=epochs, callbacks=[SensitivitySpecificityCallback()])\r\nscore = model.evaluate_generator(test_seq, verbose=0)\r\n```\r\n\r\nUnfortunately, since moving from [`fit`](https://keras.io/models/sequential/#fit) to [`flow_from_directory`](https://keras.io/preprocessing/image/#flow_from_directory) and [`fit_generator`](https://keras.io/models/sequential/#fit_generator), this has erred because `self.validation_data is None`.",
	"issue_comments": "0"
},
{
	"login": "tchaton",
	"repo_name": "keras-team/keras",
	"issue_id": "313204912",
	"issue_number": "9901",
	"issue_state": "opened",
	"issue_title": "Error when saving a model of models",
	"issue_body": "Hello,\r\nHere is my model topology.\r\nWhen I am trying to save it but got an error\r\n[<keras.engine.topology.InputLayer at 0x7fe85f8c8610>,\r\n <keras.engine.training.Model at 0x7fe846170390>,\r\n <nn.nn_blocks.BatchRenormalization at 0x7fe85f8910d0>,\r\n <keras.layers.pooling.GlobalAveragePooling2D at 0x7fe84611a450>,\r\n <keras.layers.core.Reshape at 0x7fe8476c93d0>,\r\n <keras.layers.core.Dense at 0x7fe845f99fd0>,\r\n <keras.layers.core.Dense at 0x7fe845ee2e50>,\r\n <keras.layers.merge.Multiply at 0x7fe845ef5ed0>,\r\n <keras.layers.core.Dropout at 0x7fe845ea8c10>,\r\n <keras.layers.pooling.AveragePooling2D at 0x7fe845e44c10>,\r\n <keras.layers.core.Dropout at 0x7fe845e93a50>,\r\n <keras.layers.pooling.GlobalMaxPooling2D at 0x7fe845e5b690>,\r\n <keras.layers.pooling.GlobalAveragePooling2D at 0x7fe845e5b9d0>,\r\n <keras.layers.merge.Add at 0x7fe845e02610>,\r\n <keras.layers.core.Dense at 0x7fe845dc3e90>,\r\n <nn.nn_blocks.BatchRenormalization at 0x7fe845dd4250>,\r\n <keras.layers.core.Dropout at 0x7fe845dd41d0>,\r\n <keras.layers.core.Activation at 0x7fe845d1c590>,\r\n <keras.layers.core.Dense at 0x7fe845d832d0>,\r\n <nn.nn_blocks.BatchRenormalization at 0x7fe845c00310>,\r\n <keras.layers.core.Dropout at 0x7fe845c65350>,\r\n <keras.layers.core.Activation at 0x7fe845bbdd90>,\r\n <keras.layers.core.Dense at 0x7fe845c2a390>]\r\n\r\nI looked into it, but it seems that the get_config function return a keyError when called over the  <keras.engine.training.Model at 0x7fe846170390>. But I can save the weights correclty but not the architecture.",
	"issue_comments": "0"
},
{
	"login": "omalleyt12",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "354305536",
	"issue_number": "21894",
	"issue_state": "closed",
	"issue_title": "Tensorflow with Keras fit and tensors in dataset input result in list index out of range",
	"issue_body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI encountered a strange error when using tf.keras in python with a dataset that consists out of tensors.\r\n\r\nWhat I do is create a dataset from a csv file and modify it as it contains a time series. In the end, I end up with a dataset that has tuples of input and output tensor.\r\n\r\nThese are fed into a tf.keras model and here is where it becomes interesting. Fit calls a function in training.py of the keras enginge which is called _standardize_user_data. This should return the input, targets, and so on for fit_loop, which in turn checks something on it and crashes with _if issparse is not None and issparse(ins[i]) and not K.is_sparse(feed[i]): IndexError: list index out of range_ in line 187 of training_arrays.py. This is due to the fact _standardize_user_data returns empty lists, with the reasoning that if tensors are the input, then everything should be set up already, which it apparently isn't.\r\n\r\n### Source code / logs\r\nA small script to reproduce the problem:\r\n```\r\n#!/usr/bin/env python3\r\nimport argparse\r\nimport glob\r\nimport logging\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n\r\ndef read_dataset(filename, columns, field_defaults, input_size, output_size, stride, input_features):\r\n    def decode_csv(row):\r\n        fields = tf.decode_csv(row, record_defaults=field_defaults, field_delim=',')\r\n        all_columns = dict(zip(columns, fields))\r\n        return all_columns\r\n\r\n    def split_window(window):\r\n        inputs = tf.reshape(tf.concat(window['value'][0:input_size], axis=1), [input_size, input_features])\r\n        outputs = tf.reshape(tf.concat(window['value'][input_size:input_size + output_size], axis=1),\r\n                             [output_size, input_features])\r\n\r\n        return inputs, outputs\r\n\r\n    dataset = tf.data.TextLineDataset(filenames=filename)\r\n    dataset = dataset.map(decode_csv)\r\n    dataset = dataset.apply(tf.contrib.data.sliding_window_batch(window_size=input_size + output_size, stride=stride))\r\n    dataset = dataset.map(split_window)\r\n    dataset = dataset.repeat()\r\n\r\n    return dataset\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    COLUMNS = ['value']\r\n    FIELD_DEFAULTS = [[0.0]]\r\n    INPUT_FEATURES = 1\r\n\r\n    epochs = 1\r\n    steps = 1\r\n    INPUT_SIZE = 4\r\n    OUTPUT_SIZE = 2\r\n    STRIDE = 1\r\n    input_train = \"./data/\"\r\n\r\n    input_train_list = glob.glob(input_train + \"*\")\r\n\r\n    model = keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(OUTPUT_SIZE, activation=None))\r\n    set = read_dataset(input_train_list, COLUMNS, FIELD_DEFAULTS, INPUT_SIZE, OUTPUT_SIZE, STRIDE, INPUT_FEATURES)\r\n\r\n    model.compile(optimizer=tf.train.AdamOptimizer(0.01), loss='mse', metrics=['mse'])\r\n    model.fit(set, epochs=epochs, steps_per_epoch=steps)\r\n```\r\nAnd the error itself:\r\n```\r\n2018-08-27 14:29:33.238328: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"/.../test.py\", line 102, in <module>\r\n    model.fit(set, epochs=epochs, steps_per_epoch=steps)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1363, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 187, in fit_loop\r\n    if issparse is not None and issparse(ins[i]) and not K.is_sparse(feed[i]):\r\nIndexError: list index out of range\r\n```\r\nThe data itself is something like this:\r\n```\r\n0.047910000000000785\r\n3.0999999999892225e-05\r\n0.0160979999999995\r\n2.9000000000500847e-05\r\n0.01716599999999957\r\n2.800000000036107e-05\r\n2.9999999999752447e-05\r\n0.019235000000000113\r\n```\r\n\r\nI am not sure if this behaviour is intended or not. In the Keras example, a dataset is used as well and I assume it should work with datasets consisting out of tensors. Is it possible that the return in this case should not be empty, but should only have an empty sample weight? ",
	"issue_comments": "5"
},
{
	"login": "reedwm",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "250837371",
	"issue_number": "12348",
	"issue_state": "closed",
	"issue_title": "convert .ckpt to .pb",
	"issue_body": "I trained my own model using ssd_mobilenets in object_detection, and it works well on my computer. I see the update of android demo, I want to use the ssd_mobilenets model on my android phone. But I only have .ckpt files, and do not know how to trans .ckpt to .pb, because the graph is too comlex to see which is the final tensor name. Does only one know how to genetate .pb of ssd_mobilenets",
	"issue_comments": "1"
},
{
	"login": "reedwm",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "249444730",
	"issue_number": "12188",
	"issue_state": "closed",
	"issue_title": "learner.run Couldn't find trained model",
	"issue_body": "I have built my custom experiment like this:\r\n\r\n```\r\ndef experiment_fn(run_config, hparams):\r\n    hooks = [\r\n        tf.train.CheckpointSaverHook ( \r\n            checkpoint_dir = run_config.model_dir,\r\n            save_steps = 5,\r\n        ), \r\n        \r\n        tf.train.SummarySaverHook ( \r\n            save_steps = 5, \r\n            output_dir = run_config.model_dir, \r\n            scaffold= tf.train.Scaffold(),\r\n            summary_op=tf.summary.merge_all()\r\n        )\r\n    ]\r\n    \r\n    return learn.Experiment (\r\n        estimator = learn.Estimator (\r\n            model_fn = model_fn, \r\n            config = run_config,\r\n            params = hparams\r\n        ),\r\n        train_input_fn = lambda: input_fun(train_set),\r\n        eval_input_fn = lambda: input_fun(eval_set),\r\n        eval_metrics = model_eval_metrics(),\r\n        train_steps = 20,\r\n        train_monitors = hooks,\r\n        eval_hooks = hooks,\r\n        min_eval_frequency = 1,\r\n        export_strategies = saved_model_export_utils.make_export_strategy (\r\n            serving_input_fn = serving_input_fn,\r\n        )\r\n    )\r\n```\r\n\r\n```\r\nlearn_runner.run (\r\n    experiment_fn = experiment_fn,\r\n    run_config = tf.contrib.learn.RunConfig (\r\n        model_dir = output_dir,\r\n    ),\r\n    schedule = \"train_and_evaluate\",\r\n    hparams =  tf.contrib.training.HParams (\r\n        ...some parameters...\r\n    )\r\n)\r\n```\r\n\r\nWhen I run it, I have files created in \\model with names like 'model.ckpt-6.meta' plus the monitor shows the following results:\r\n\r\n> Monitors are deprecated. Please use tf.train.SessionRunHook.\r\n> INFO:tensorflow:step = 1, loss = 0.0437659\r\n> INFO:tensorflow:Saving checkpoints for 1 into model\\model.ckpt.\r\n> INFO:tensorflow:Saving checkpoints for 6 into model\\model.ckpt.\r\n> INFO:tensorflow:Saving checkpoints for 11 into model\\model.ckpt.\r\n> INFO:tensorflow:Saving checkpoints for 16 into model\\model.ckpt.\r\n> INFO:tensorflow:Saving checkpoints for 20 into model\\model.ckpt.\r\n> INFO:tensorflow:Loss for final step: 0.0438498.\r\n\r\n> ---------------------------------------------------------------------------\r\n> NotFittedError                            Traceback (most recent call last)\r\n> <ipython-input-3-4a9282b8a5f5> in <module>()\r\n>     177         learning_rate = 0.01,\r\n>     178         decay_rate = 0.96,\r\n> --> 179         decay_steps = 10\r\n>     180     )\r\n>     181 )\r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)\r\n>     208   schedule = schedule or _get_default_schedule(run_config)\r\n>     209 \r\n> --> 210   return _execute_schedule(experiment, schedule)\r\n>     211 \r\n>     212 \r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py in _execute_schedule(experiment, schedule)\r\n>      45     logging.error('Allowed values for this experiment are: %s', valid_tasks)\r\n>      46     raise TypeError('Schedule references non-callable member %s' % schedule)\r\n> ---> 47   return task()\r\n>      48 \r\n>      49 \r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py in train_and_evaluate(self)\r\n>     499                                       metrics=self._eval_metrics,\r\n>     500                                       name=eval_dir_suffix,\r\n> --> 501                                       hooks=self._eval_hooks)\r\n>     502     export_results = self._maybe_export(eval_result)\r\n>     503     return eval_result, export_results\r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py in _call_evaluate(self, _sentinel, input_fn, steps, metrics, name, checkpoint_path, hooks)\r\n>     686                                       name=name,\r\n>     687                                       checkpoint_path=checkpoint_path,\r\n> --> 688                                       hooks=hooks)\r\n>     689 \r\n>     690 \r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py in new_func(*args, **kwargs)\r\n>     287             'in a future version' if date is None else ('after %s' % date),\r\n>     288             instructions)\r\n> --> 289       return func(*args, **kwargs)\r\n>     290     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n>     291                                        _add_deprecated_arg_notice_to_docstring(\r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in evaluate(self, x, y, input_fn, feed_fn, batch_size, steps, metrics, name, checkpoint_path, hooks, log_progress)\r\n>     541         checkpoint_path=checkpoint_path,\r\n>     542         hooks=hooks,\r\n> --> 543         log_progress=log_progress)\r\n>     544 \r\n>     545     if eval_results is not None:\r\n> \r\n> C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in _evaluate_model(self, input_fn, steps, feed_fn, metrics, name, checkpoint_path, hooks, log_progress)\r\n>     814       if not latest_path:\r\n>     815         raise NotFittedError(\"Couldn't find trained model at %s.\"\r\n> --> 816                              % self._model_dir)\r\n>     817       checkpoint_path = latest_path\r\n>     818 \r\n> \r\n> NotFittedError: Couldn't find trained model at \\model.\r\n\r\nWhy it cannot find the model ?\r\n\r\nThanks for assistance!",
	"issue_comments": "3"
},
{
	"login": "reedwm",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "244834773",
	"issue_number": "11681",
	"issue_state": "closed",
	"issue_title": "Different GPU memory not all allocated",
	"issue_body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nwin10\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.1\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\ncuda8.0,cudnn5.5\r\n- **GPU model and memory**:\r\nGTX Titan 6GB, GTX 1080Ti 11GB\r\n\r\n### Describe the problem\r\nNote that tensorflow will allocate tensor/op to all available gpus, but i only got 1080Ti occupied, I wonder if it's a bug or tensorflow doesn't support different gpu models.",
	"issue_comments": "3"
},
{
	"login": "reedwm",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "244028841",
	"issue_number": "11605",
	"issue_state": "closed",
	"issue_title": "[on the way] Reducing the binary size",
	"issue_body": "Hi , all ~\r\n    i am now succeed in using a cross compiled lib project call tensorflow. \r\n    now i got tensorflow run on ios , android and linux , using one same app code . \r\n    any one has any questions can ask me for help.\r\n\r\n    so my question now is turned to \"Reducing the binary size\". \r\n    many posts told that to config  tf_op_files.txt, but my questions are:\r\n    1. need we also config other files such as  tf_pb_text_files.txt ,  proto_text_cc_files.txt  ... for reducing?\r\n    2. is there any other thinking for reducing than configuring the txt files Exhaustive Attackly ?",
	"issue_comments": "13"
},
{
	"login": "zasdfgbnm",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "208700740",
	"issue_number": "7662",
	"issue_state": "opened",
	"issue_title": "Add a dynamic_partial_sum operator to tensorflow?",
	"issue_body": "Hi,\r\n\r\nIn my application I need to do operations that dynamically sum some rows of a matrix to get a new matrix.  There will be an input tensor named \"index\" that guides which part of the tensor to be summed. \r\n\r\nAn example is, if the input matrix is\r\n```python\r\n[ [   1,   1,   1],\r\n  [  10,  10,  10],\r\n  [ 100, 100, 100] ]\r\n```\r\nAnd the index is\r\n```python\r\n[ [ 0, 2 ],\r\n  [ 2, 3 ]]\r\n```\r\nwhich simply says the output tensor will have two rows (because the \"index\" have two rows), the first row is the sum of rows with row number i that satisfies `0 <= i < 2` in the input, and the second row is the sum of rows with row number 2. So the result should be\r\n```python\r\n[ [  11,  11,  11],\r\n  [ 100, 100, 100] ]\r\n```\r\n\r\nI don't find any existing operation that does this job, so I implement it (support only 2d matrix and GPU) by myself.  Since I already have an implementation, I'm not requesting a new feature here. But I do want to know that if the tensorflow team is interested in adding this operation as part of tensorflow. If the answer is yes, I will add CPU support (maybe also xla? I have no idea on how to add xla support yet), and then create a pull request for that.",
	"issue_comments": "0"
},
{
	"login": "stas00",
	"repo_name": "fastai/fastai",
	"issue_id": "411116954",
	"issue_number": "1652",
	"issue_state": "closed",
	"issue_title": "numpy upgrade",
	"issue_body": "\r\n**Reproduce: make test**\r\n\r\n_______________________ test_should_load_backwards_lm_1 ________________________\r\n\r\ndef test_should_load_backwards_lm_1():\r\n    \"assumes that a backwards batch starts where forward ends. Whether this holds depends on LanguageModelPreLoader\"\r\n    path = untar_data(URLs.IMDB_SAMPLE)\r\n\r\n    df = text_df(['neg','pos'])\r\n    data = TextLMDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=0, text_cols=[\"text\"],\r\n                                   bs=2, backwards=False)\r\n    batch_forward = data.one_batch(DatasetType.Valid)[0].numpy()\r\n\r\n    data = TextLMDataBunch.from_df(path, train_df=df, valid_df=df, label_cols=0, text_cols=[\"text\"],\r\n                                   bs=2, backwards=True)\r\n    batch_backwards = data.one_batch(DatasetType.Valid)[0].numpy()\r\n  np.testing.assert_array_equal(batch_backwards, np.flip(batch_forward))\r\nE TypeError: flip() missing 1 required positional argument: \u2018axis\u2019\r\n\r\ntests/test_text_data.py:92: TypeError\r\n\r\n\r\n**python -m fastai.utils.show_install**\r\n```text\r\n=== Software === \r\npython       : 3.6.6\r\nfastai       : 1.0.46.dev0\r\nfastprogress : 0.1.19\r\ntorch        : 1.0.0\r\ntorch cuda   : None / is **Not available** \r\n\r\n=== Hardware === \r\nNo GPUs available \r\n\r\n=== Environment === \r\nplatform     : Darwin-17.7.0-x86_64-i386-64bit\r\nconda env    : base\r\npython       : /Users/bherudek/miniconda3/bin/python\r\nsys.path     : \r\n/Users/bherudek/miniconda3/lib/python36.zip\r\n/Users/bherudek/miniconda3/lib/python3.6\r\n/Users/bherudek/miniconda3/lib/python3.6/lib-dynload\r\n/Users/bherudek/miniconda3/lib/python3.6/site-packages\r\n/Users/bherudek/Desktop/fastaigits/fastai-doctestcheckclsstas\r\nno supported gpus found on this system\r\n```\r\n\r\n**Resolution:**\r\npip install --upgrade numpy\r\n--> unfortunately I could not find logs for the previous version\r\n\r\n",
	"issue_comments": "5"
},
{
	"login": "stas00",
	"repo_name": "fastai/fastai",
	"issue_id": "358201787",
	"issue_number": "754",
	"issue_state": "opened",
	"issue_title": "fastText used in courses/dl2/translate.ipynb is a stuck runaway process",
	"issue_body": "FYI, the current dev version of fastText which is used in `courses/dl2/translate.ipynb` is broken. I opened an issue [here](https://github.com/facebookresearch/fastText/issues/618#issuecomment-419554225) (someone already reported a similar one). \r\n\r\nThe runaway happens after running:\r\n\r\n`vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}`\r\n\r\nI have no way of telling whether it has ever properly worked as this is the first time I used it. I tried conda-forge's fasttext-0.1.0 - and it fails the same way. \r\n\r\nPerhaps the problems has been there from the beginning - if you don't pay attention to a spinning at 100% CPU (e.g. remote shell) you may not notice the problem.\r\n",
	"issue_comments": "0"
},
{
	"login": "chsigg",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "357802521",
	"issue_number": "22123",
	"issue_state": "closed",
	"issue_title": "Incorrect results on GPU for reduce_* methods on large tensors",
	"issue_body": "-----------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0 / 1.5.0 / 1.10.1\r\n- **Python version**: 2.7.15 / 3.6.3\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: CUDA 9.0\r\n- **GPU model and memory**: K10, P100\r\n- **Exact command to reproduce**: see code below\r\n\r\n### Describe the problem\r\nFor tensors with large amount of values (2^28 seems to be the threshold) a few of the reduce_* (tested max, sum, min) methods don't work correctly. The incorrect values appear to be read randomly from memory. The issue was only observed on GPU. Other observations are that a tensor with int types works as expected. Also no problem if the tensor is read as tf.constant. \r\nThese posts seem to be related:\r\nhttps://github.com/tensorflow/tensorflow/issues/20094\r\nhttps://stackoverflow.com/questions/49520394/tf-reduce-sum-on-gpu-fails-in-combination-with-placeholder-as-input-shape\r\nhttps://stackoverflow.com/questions/50806742/tensorflow-reduce-sum-returns-partially-incorrect-output-given-a-large-input\r\n\r\n### Source code / logs\r\nhttps://colab.research.google.com/drive/1GNqzUfRTRRohyjiF8HqvWzvKE6LasQ-4\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nn = np.random.randint(1,9)\r\ninp = np.ones(shape=(140000000, 2)) * n\r\ntensor = tf.placeholder(tf.float32, shape=(None, None))\r\noutput = tf.reduce_max(tensor, axis=-1)\r\n\r\nwith tf.Session() as sess:\r\n    result = sess.run(output, feed_dict={tensor: inp})\r\n    print('output values')\r\n    print(result)\r\n    print('number of incorrect values')\r\n    print(np.sum(result != inp.max(axis=-1)))\r\n```\r\nOutput:\r\n```\r\noutput values\r\n[5. 5. 5. ... 0. 0. 0.]\r\nnumber of incorrect values\r\n5782272\r\n```\r\n\r\nPinging:\r\n@nuance-research",
	"issue_comments": "8"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "334235471",
	"issue_number": "575",
	"issue_state": "closed",
	"issue_title": "Clarifications about lr_find2()",
	"issue_body": "Hi. \r\n\r\nLe me say that I'not opening the present issue for complaining, but just for getting some clarifications.\r\n\r\nPerforming some experiments, I noticed (Feb 3, 2018) that the LR Finder didn't work on small dataset.\r\n\r\nI reported the issue in this blog post: http://forums.fast.ai/t/lesson-1-my-experiments-with-resnet34-and-some-questions/10857\r\n\r\nJeremy kindly encouraged me (as he often does with practitioners) in modifying, with his help, the code so that the finder could run more epochs in case of small dataset. \r\n\r\nI did it and **reported the full code later in the same thread** (proposing some other modification ideas). \r\n\r\nNo one acknowledged, but the bosses are pretty busy boys/girls, so I just waited. \r\n\r\nThen, on 20 March 2018 I wrote a PM to Jeremy. It was viewed but not answered. Probably he cannot answer to all the PMs he gets, so I waited.\r\n\r\nA week ago, I wrote another forum post, tagging Jeremy, Rachel, and Reshama. I waited, but no one answered.\r\n\r\nYersterday (19 June 2018) I decided to open a pull request.In those last months I obviously maintained my environment up to date. \r\nSo I opened learner.py to check the code for such a pull request, and doh! My proposed modification to the code was there, just with other names for functions and params (e.g `num_it` instead of `run_for`)..!\r\n\r\nNow like I said I don't want to complain, and obviously I do not have any claim upon the code (I'm just a student), but why not to say just \"Hey boy, we put it into the code.\"\r\n\r\nNo matter how little my contribution, It would have been reason of immense satisfaction for me.\r\n\r\nThank you, even if you won't answer.",
	"issue_comments": "1"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "374650661",
	"issue_number": "988",
	"issue_state": "closed",
	"issue_title": "Error rendering saleElapsed vs YearMade interaction plot in ml1/lesson2-rf_interpretation",
	"issue_body": "**Describe the bug**\r\n[`pdp_interact`](https://github.com/SauceCat/PDPbox/blob/master/pdpbox/pdp.py#L485) now requires 4 arguments. lesson2-rf_interpretation only provides three when attempting to plot saleElapsed vs YearMade.\r\n\r\n**To Reproduce**\r\nRun the current lesson2-rf_interpretation.ipynb and observe error:\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-51-b739d803a4ad> in <module>\r\n      1 feats = ['saleElapsed', 'YearMade']\r\n----> 2 p = pdp.pdp_interact(m, x, feats)\r\n      3 pdp.pdp_interact_plot(p, feats)\r\n\r\nTypeError: pdp_interact() missing 1 required positional argument: 'features'\r\n```\r\n\r\n**Expected behavior**\r\nInteraction plot is rendered, as in [lesson2-rf_interpretation.ipynb](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson2-rf_interpretation.ipynb)\r\n\r\n**Screenshots**\r\n<img width=\"1126\" alt=\"screenshot 2018-10-27 at 15 24 11\" src=\"https://user-images.githubusercontent.com/1101318/47605278-65efcb00-d9fc-11e8-8e51-7b45d307f320.png\">\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "304092112",
	"issue_number": "206",
	"issue_state": "closed",
	"issue_title": "ImageData.resize ignores new_path and always sets it to 'tmp'",
	"issue_body": "I've just noticed that the 'tmp' folder is hardcoded in `resize_imgs`, and the code suggest that the new_path should be used instead, here is the relevant line:\r\n\r\nhttps://github.com/fastai/fastai/blob/master/fastai/dataset.py#L30",
	"issue_comments": "0"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "316496360",
	"issue_number": "375",
	"issue_state": "closed",
	"issue_title": "when installing with pip, graphviz and sklearn_pandas are not contained in requirements.txt",
	"issue_body": "",
	"issue_comments": "1"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "302346033",
	"issue_number": "194",
	"issue_state": "closed",
	"issue_title": "Doc Strings for Various Library Elements",
	"issue_body": "I realize this is a mundane topic, but I figured I would bring it up. The class put a large emphasis on using various notebook commands to understand the code we are running, but I noticed some of the fastai abstraction methods/classes lack doc strings. For example some of the first code we run is from [conv_learn.py](https://github.com/fastai/fastai/blob/master/fastai/conv_learner.py). I noticed both on the repo some of the parameters are not very spelled out. Some of the methods/classes do have strings with information about the class or function but not all of them. Is there a logic here or just something on the to do list?\r\nAs the one raising the issue, if pointed to the relevant materials I am willing to try to issue a pull request to put in some of these doc strings. \r\n",
	"issue_comments": "3"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "317107501",
	"issue_number": "389",
	"issue_state": "closed",
	"issue_title": "Logo Design Offer as Open Source Contribution",
	"issue_body": "Hello Sir. I'm a UI/UX and Graphics Designer. I want provide a logo for you. Would you mind if I propose a new logo design for your application as my Open Source Contribution?\r\n\r\nThanks before.",
	"issue_comments": "1"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "302976047",
	"issue_number": "196",
	"issue_state": "closed",
	"issue_title": "Tornado Version Issues",
	"issue_body": "From a fresh clone and `conda env update`, `jupyter notebook` gives me the error `'IOLoop' has no attribute 'initialized'`.\r\n\r\nThis is the same error as in https://github.com/saltstack/salt/issues/46340 so I believe this due to `conda env update` installing Tornado 5, which was very recently released (see issue).\r\n\r\nDowngrading to Tornado **4.5.3** (with `conda install tornado=4.5.3`) **fixed** it -- the command works fine now.\r\n\r\nCreating an issue so someone can look into this more and make any changes that might be needed -- like enforcing tornado version <5. I've seen the issue appearing on the forums today (where there was a potential fix that did **not** work for me personally -- [forums here](http://forums.fast.ai/search?q=%27IOLoop%27%20has%20no%20attribute%20%27initialized%27))\r\n\r\nFull error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/corey/miniconda3/envs/fastai/bin/jupyter-notebook\", line 7, in <module>\r\n    from notebook.notebookapp import main\r\n  File \"/home/corey/miniconda3/envs/fastai/lib/python3.6/site-packages/notebook/notebookapp.py\", line 45, in <module>\r\n    ioloop.install()\r\n  File \"/home/corey/miniconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 210, in install\r\n    assert (not ioloop.IOLoop.initialized()) or \\\r\nAttributeError: type object 'IOLoop' has no attribute 'initialized'\r\n```",
	"issue_comments": "0"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "318789599",
	"issue_number": "418",
	"issue_state": "closed",
	"issue_title": "Need Unit Tests",
	"issue_body": "This repo and library need some Unit tests because in each time something is getting fixed, another problem occurs so repo should be maintained under the correct procedure. Otherwise, it will not be useful.\r\nThank you.",
	"issue_comments": "2"
},
{
	"login": "jph00",
	"repo_name": "fastai/fastai",
	"issue_id": "343442304",
	"issue_number": "646",
	"issue_state": "closed",
	"issue_title": "learn.TTA with tfm_y=TfmType.CLASS bug",
	"issue_body": "`learn.TTA` doesn't seem to comprise the segmentation case. \r\n\r\nIf I do `probs = learn.TTA(n_aug=2)`, probs shape is something like (3, num_images, img_sz, image_sz, channels).\r\n\r\nprobs[0] is the segmentation with image without augmentation, probs[1] is the segmentation of the image with first augmentation applied, probs[2] is the segmentation with 2nd segmentation applied.\r\nOne cannot average these results, as each augmentation transforms the output accordingly.\r\n\r\nSee example here: https://www.evernote.com/l/AZScajJNXAdLIpp66Qg_FkctMkeOK3kFY3EB/image.png\r\n(I also posted at http://forums.fast.ai/t/lesson-14-segmentation/19530/5)\r\n\r\nUnless we know how to inverse the augmentation transformation in the result, learn.TTA is useless.\r\n\r\nMy suggestion is that, knowing that the data has ` tfm_y=TfmType.CLASS`, the learn.TTA code should inverse the augmentation transform to probs[1] and probs [2] (in my example).  \r\n\r\n",
	"issue_comments": "4"
},
{
	"login": "ebrevdo",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "116808886",
	"issue_number": "201",
	"issue_state": "closed",
	"issue_title": "How To doc for tensor indexing and assigning ops",
	"issue_body": "If you're coming from numpy you're used to be able to index and assign into arrays in the usual way.",
	"issue_comments": "2"
},
{
	"login": "mrry",
	"repo_name": "tensorflow/tensorflow",
	"issue_id": "115894138",
	"issue_number": "2",
	"issue_state": "closed",
	"issue_title": "OSX Yosemite \"can't determine number of CPU cores: assuming 4\"",
	"issue_body": "```python\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('hello, tensorflow')\r\n>>> sess = tf.Session()\r\ncan't determine number of CPU cores: assuming 4\r\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4\r\ncan't determine number of CPU cores: assuming 4\r\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4\r\n```\r\n\r\ngot this warning but still works though",
	"issue_comments": "1"
},
{
	"login": "lukeyeager",
	"repo_name": "BVLC/caffe",
	"issue_id": "58468238",
	"issue_number": "1928",
	"issue_state": "opened",
	"issue_title": "Cropping the mean file",
	"issue_body": "Since the huge update, I'm having to fix lots of API changes with my python interfaces to caffe. How do I wade through the commit stream to find out what all needs to change?\r\n\r\nThis is my most recent problem. I try this:\r\n\r\n```python\r\nclassifier = caffe.Classifier(deploy_file, snapshot_file,\r\n             image_dims      = (height, width),\r\n             mean            = image_mean,\r\n             raw_scale       = 255,\r\n             channel_swap    = channel_swap,\r\n             )\r\nclassifier.predict([image], oversample=False)\r\n```\r\n\r\nAnd I get this error:\r\n\r\n    ValueError: operands could not be broadcast together with shapes (3,227,227) (3,256,256) (3,227,227)\r\n\r\nApparently, the mean_file has to be cropped before passing it to the Classifier constructor now. How was I supposed to know that? I don't see it in any of [these commits](https://github.com/BVLC/caffe/commits/master/python/caffe/classifier.py). And how am I supposed to do it? Should I be cropping it myself manually, or should I try to use Classifier.transformer.preprocess()?",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "414219226",
	"issue_number": "1715",
	"issue_state": "closed",
	"issue_title": "ClassificationInterpretation errors with nn.CrossEntropyLoss when weights are set (cuda)",
	"issue_body": "**Describe the bug**\r\nWhen weights have been passed to `nn.CrossEntropyLoss` and set as the `loss_func` on a `Learner`, `ClassificationInterpretation.from_learner` fails with `RuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'weight'`.\r\n\r\n**Provide your installation details**\r\n```text\r\n=== Software === \r\npython        : 3.6.8\r\nfastai        : 1.0.45\r\nfastprogress  : 0.1.19\r\ntorch         : 1.0.1.post2\r\nnvidia driver : 410.78\r\ntorch cuda    : 10.0.130 / is available\r\ntorch cudnn   : 7402 / is enabled\r\n\r\n=== Hardware === \r\nnvidia gpus   : 1\r\ntorch devices : 1\r\n  - gpu0      : 6069MB | GeForce GTX 1060 6GB\r\n\r\n=== Environment === \r\nplatform      : Linux-4.18.0-15-generic-x86_64-with-debian-buster-sid\r\ndistro        : #16-Ubuntu SMP Thu Feb 7 10:56:39 UTC 2019\r\nconda env     : fastai\r\npython        : /home/yeldarb/anaconda3/envs/fastai/bin/python\r\nsys.path      : /home/yeldarb/anaconda3/envs/fastai/lib/python36.zip\r\n/home/yeldarb/anaconda3/envs/fastai/lib/python3.6\r\n/home/yeldarb/anaconda3/envs/fastai/lib/python3.6/lib-dynload\r\n\r\n/home/yeldarb/anaconda3/envs/fastai/lib/python3.6/site-packages\r\n/home/yeldarb/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/extensions\r\n/home/yeldarb/.ipython\r\n```\r\n\r\n**To Reproduce**\r\n* Setup a learner, set a `loss_func` of `nn.CrossEntropyLoss` with the weight parameter:\r\n```python\r\nlearn = create_cnn(data, models.resnet18, metrics=error_rate)\r\nweights = torch.ones(data.c).float().cuda()\r\nlearn.loss_func = nn.CrossEntropyLoss(weight=weights)\r\n```\r\n* Train\r\n* Run `ClassificationInterpretation.from_learner(learn)`\r\n\r\n**Stack Trace**\r\n```text\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-51-aa7f7b70a42b> in <module>\r\n----> 1 interp = ClassificationInterpretation.from_learner(learn)\r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/learner.py in _cl_int_from_learner(cls, learn, ds_type, tta)\r\n    100 def _cl_int_from_learner(cls, learn:Learner, ds_type:DatasetType=DatasetType.Valid, tta=False):\r\n    101     \"Create an instance of `ClassificationInterpretation`. `tta` indicates if we want to use Test Time Augmentation.\"\r\n--> 102     preds = learn.TTA(ds_type=ds_type,with_loss=True) if tta else learn.get_preds(ds_type=ds_type, with_loss=True)\r\n    103     return cls(learn, *preds, ds_type=ds_type)\r\n    104 \r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py in get_preds(self, ds_type, with_loss, n_batch, pbar)\r\n    276         lf = self.loss_func if with_loss else None\r\n    277         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(self.callbacks),\r\n--> 278                          activ=_loss_func2activ(self.loss_func), loss_func=lf, n_batch=n_batch, pbar=pbar)\r\n    279 \r\n    280     def pred_batch(self, ds_type:DatasetType=DatasetType.Valid, batch:Tuple=None, reconstruct:bool=False) -> List[Tensor]:\r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py in get_preds(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\r\n     39     res = [torch.cat(o).cpu() for o in\r\n     40            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\r\n---> 41     if loss_func is not None: res.append(calc_loss(res[0], res[1], loss_func))\r\n     42     if activ is not None: res[0] = activ(res[0])\r\n     43     return res\r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/torch_core.py in calc_loss(y_pred, y_true, loss_func)\r\n    255         old_red = getattr(loss_func, 'reduction')\r\n    256         setattr(loss_func, 'reduction', 'none')\r\n--> 257         l = loss_func(y_pred, y_true)\r\n    258         setattr(loss_func, 'reduction', old_red)\r\n    259         return l\r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    487             result = self._slow_forward(*input, **kwargs)\r\n    488         else:\r\n--> 489             result = self.forward(*input, **kwargs)\r\n    490         for hook in self._forward_hooks.values():\r\n    491             hook_result = hook(self, input, result)\r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/loss.py in forward(self, input, target)\r\n    902     def forward(self, input, target):\r\n    903         return F.cross_entropy(input, target, weight=self.weight,\r\n--> 904                                ignore_index=self.ignore_index, reduction=self.reduction)\r\n    905 \r\n    906 \r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction)\r\n   1968     if size_average is not None or reduce is not None:\r\n   1969         reduction = _Reduction.legacy_get_string(size_average, reduce)\r\n-> 1970     return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\r\n   1971 \r\n   1972 \r\n\r\n~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)\r\n   1788                          .format(input.size(0), target.size(0)))\r\n   1789     if dim == 2:\r\n-> 1790         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\n   1791     elif dim == 4:\r\n   1792         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\n\r\nRuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'weight'\r\n```\r\n**Other Info**\r\nThis was [discussed on the fastai forums](https://forums.fast.ai/t/changing-default-loss-functions/28981/3) and setting `learn.loss_func = data.loss_func` prior to running `ClassificationInterpretation.from_learner` does work. But I wanted to log this issue here in case there's a way to make it work with the actual loss function the model was trained on.",
	"issue_comments": "8"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "390680336",
	"issue_number": "1331",
	"issue_state": "closed",
	"issue_title": "Multilabel classification: TypeError: an integer is required (got type NoneType) at the end of one cycle",
	"issue_body": "[Issue 1273](https://github.com/fastai/fastai/issues/1273) was resolved by @sgugger in [this commit](https://github.com/fastai/fastai/commit/9cc573f18a0ad9d5ec69f04813598d677b14cef3). That fix does not cover multiclass classification. \r\n\r\nExample repro with `from_csv` factory method:\r\n(Repro code assumes `./dev_data` directory exists with files 1.png ... 10.png)\r\n\r\n```\r\nfrom fastai.vision import *\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nPATH = './dev_data'\r\n\r\n# create unbalanced targets which will yield labels in validation that are not present in train.\r\ndf = pd.DataFrame({'id' : list(map(str, range(1,11))),\r\n                   'Target' : [' '.join(list(map(str, np.random.permutation(range(1, 1000))[:2]))) for _ in range(1, 11)]})\r\ndf.to_csv(f'{PATH}/train_dev.csv', index=False)\r\ndb = ImageDataBunch.from_csv(PATH, 'train', suffix='.png', csv_labels='train_dev.csv', size=32, bs=2, sep=' ')\r\nlearn = create_cnn(db, models.resnet18)\r\nlearn.fit(1)\r\n```\r\n\r\nThrows:\r\n```\r\nTypeError: list indices must be integers or slices, not NoneType\r\n```",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "424486264",
	"issue_number": "1867",
	"issue_state": "closed",
	"issue_title": "SaveModelCall back failing",
	"issue_body": "<!-- BEFORE POSTING AN ISSUE PLEASE MAKE SURE TO READ: https://docs.fast.ai/support.html -->\r\n\r\n<!-- **Important:** We try our best to fix all reported issue. The main difficulty we have is not being able to read your mind. If you don't follow the steps below, we have to follow up asking you to supply the required information, but we have already asked you to do so, so please don't waste our time and yours and supply it in first place. If you don't, your issue will be closed. You are free to resubmit this time with the required information. Thank you for helping us help you. -->\r\n\r\n<!-- **Please note**:\r\n- Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n\r\n- fastai github Issues are only for bugs in the library. If you want to suggest a new feature please use https://forums.fast.ai/t/fastai-v1-adding-features/23041. If you're unsure whether your bug comes from your code or the library, please use the forums to discuss your code first, then file an issue if needed.\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nI get the below error  possibly while using SaveModel Call back. I dint face this issue earlier any time. \r\n\r\n```\r\n    93         if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\r\n     94         else: #every=\"improvement\"\r\n---> 95             current = self.get_monitor_value()\r\n     96             if current is not None and self.operator(current, self.best):\r\n     97                 print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\r\n\r\n/opt/conda/lib/python3.6/site-packages/fastai/callbacks/tracker.py in get_monitor_value(self)\r\n     44                   'val_loss':self.learn.recorder.val_losses[-1:][0]}\r\n     45         for i, name in enumerate(self.learn.recorder.names[3:-1]):\r\n---> 46             values[name]=self.learn.recorder.metrics[-1:][0][i]\r\n     47         if values.get(self.monitor) is None:\r\n     48             warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {\", \".join(map(str, self.learn.recorder.names[1:]))}')\r\n\r\n```\r\n**IndexError: list index out of range**\r\n**Provide your installation details**\r\n<!-- We need to have some background to know how to fix your bug. -->\r\n<!-- Copy-n-paste the output of `show_install`, by either running this cell in jupyter notebook:\r\n```\r\nfrom fastai.utils.show_install import *\r\nshow_install()\r\n```\r\nor via your shell:\r\n```\r\npython -m fastai.utils.show_install\r\n```\r\nDouble-check you use the latest version which you can find here: https://github.com/fastai/fastai/releases.\r\n\r\nIt's also possible that the issue has already been fixed in git master, but hasn't been released yet, so if possible please try to see whether git master has it resolved. To install the git master do: `pip install git+https://github.com/fastai/fastai/`\r\n-->\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. Please give us a reproducible example so we can fix your bug.-->\r\n<!-- A gist to reproduce it is even better!-->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tree/master/tests/ that helps us reproduce the problem and will help with future regression testing. See https://docs.fast.ai/dev/test.html for details on how to run/write tests. -->\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help demonstrate your problem. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "445679540",
	"issue_number": "2097",
	"issue_state": "closed",
	"issue_title": "_check_kwargs ignores use_on_y in labellist#transform",
	"issue_body": "<!-- BEFORE POSTING AN ISSUE PLEASE MAKE SURE TO READ: https://docs.fast.ai/support.html -->\r\n\r\n<!-- **Important:** We try our best to fix all reported issue. The main difficulty we have is not being able to read your mind. If you don't follow the steps below, we have to follow up asking you to supply the required information, but we have already asked you to do so, so please don't waste our time and yours and supply it in first place. If you don't, your issue will be closed. You are free to resubmit this time with the required information. Thank you for helping us help you. -->\r\n\r\n<!-- **Please note**:\r\n- Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n\r\n- fastai github Issues are only for bugs in the library. If you want to suggest a new feature please use https://forums.fast.ai/t/fastai-v1-adding-features/23041. If you're unsure whether your bug comes from your code or the library, please use the forums to discuss your code first, then file an issue if needed.\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nI am trying to use [cutout](https://docs.fast.ai/vision.transform.html#_cutout) in object detection, but when I used `get_transforms(xtra_tfms=[cutout(use_on_y=False)]), tfm_y=True)` , an error occurred and it says \"TypeError: 'ImageBBox' object does not support item assignment\". This problem was fixed when I used `get_transforms(xtra_tfms=[cutout(use_on_y=False)]), tfm_y=False)` and then set train/valid subset's `tfm_y` True.\r\nI think [running _check_kwargs without filtering use_on_y](https://github.com/fastai/fastai/blob/master/fastai/data_block.py#L723) is the reason of this error.\r\n\r\n**Provide your installation details**\r\n<!-- We need to have some background to know how to fix your bug. -->\r\n<!-- Copy-n-paste the output of `show_install`, by either running this cell in jupyter notebook:\r\n```\r\nfrom fastai.utils.show_install import *\r\nshow_install()\r\n```\r\nor via your shell:\r\n```\r\npython -m fastai.utils.show_install\r\n```\r\nDouble-check you use the latest version which you can find here: https://github.com/fastai/fastai/releases.\r\n\r\nIt's also possible that the issue has already been fixed in git master, but hasn't been released yet, so if possible please try to see whether git master has it resolved. To install the git master do: `pip install git+https://github.com/fastai/fastai/`\r\n-->\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. Please give us a reproducible example so we can fix your bug.-->\r\n<!-- A gist to reproduce it is even better!-->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tree/master/tests/ that helps us reproduce the problem and will help with future regression testing. See https://docs.fast.ai/dev/test.html for details on how to run/write tests. -->\r\n\r\ncode:\r\n```\r\nfrom fastai import *\r\nfrom fastai.vision import *\r\n\r\ncoco = untar_data(URLs.COCO_TINY)\r\nimages, lbl_bbox = get_annotations(coco/'train.json')\r\nimg2bbox = dict(zip(images, lbl_bbox))\r\nget_y_func = lambda o:img2bbox[o.name]\r\n\r\ndata = (ObjectItemList.from_folder(coco)\r\n        #Where are the images? -> in coco and its subfolders\r\n        .split_by_rand_pct()                          \r\n        #How to split in train/valid? -> randomly with the default 20% in valid\r\n        .label_from_func(get_y_func)\r\n        #How to find the labels? -> use get_y_func on the file name of the data\r\n        .transform(get_transforms(xtra_tfms=[cutout(use_on_y=False)]), tfm_y=True)\r\n        #Data augmentation? -> Standard transforms; also transform the label images\r\n        .databunch(bs=16, collate_fn=bb_pad_collate))   \r\n        #Finally we convert to a DataBunch, use a batch size of 16,\r\n        # and we use bb_pad_collate to collate the data into a mini-batch\r\ndata.show_batch(3)\r\n```\r\n\r\nfixed code (this works, but a little awkward):\r\n```\r\nfrom fastai import *\r\nfrom fastai.vision import *\r\n\r\ncoco = untar_data(URLs.COCO_TINY)\r\nimages, lbl_bbox = get_annotations(coco/'train.json')\r\nimg2bbox = dict(zip(images, lbl_bbox))\r\nget_y_func = lambda o:img2bbox[o.name]\r\n\r\ndata = (ObjectItemList.from_folder(coco)\r\n        #Where are the images? -> in coco and its subfolders\r\n        .split_by_rand_pct()                          \r\n        #How to split in train/valid? -> randomly with the default 20% in valid\r\n        .label_from_func(get_y_func)\r\n        #How to find the labels? -> use get_y_func on the file name of the data\r\n        .transform(get_transforms(xtra_tfms=[cutout(use_on_y=False)]), tfm_y=False))\r\n\r\ndata.train.tfm_y = True\r\ndata.valid.tfm_y = True\r\ndata = data.databunch(bs=16, collate_fn=bb_pad_collate)\r\ndata.show_batch(3)\r\n```\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThe 'code' above works correctly.\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help demonstrate your problem. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "406651770",
	"issue_number": "1567",
	"issue_state": "closed",
	"issue_title": "plt.subplot typo - should be plt.subplots in ImageBBox.show",
	"issue_body": "**Describe the bug**\r\nSee this line: https://github.com/fastai/fastai/blob/master/fastai/vision/image.py#L374\r\n\r\n**Additional context**\r\nFurther reading: https://github.com/matplotlib/matplotlib/blob/v2.2.3/lib/matplotlib/pyplot.py#L1046",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "418309804",
	"issue_number": "1778",
	"issue_state": "closed",
	"issue_title": "AttributeError: 'ObjectCategoryProcessor' object has no attribute 'pad_idx' on DataBunch.load_empty",
	"issue_body": "Hi, I have some unexpected bug when I attempt to load data after export\r\nSo\r\n\r\n```text\r\n=== Software === \r\npython        : 3.6.7\r\nfastai        : 1.0.47\r\nfastprogress  : 0.1.20\r\ntorch         : 1.0.1.post2\r\nnvidia driver : 410.79\r\ntorch cuda    : 10.0.130 / is available\r\ntorch cudnn   : 7402 / is enabled\r\n\r\n=== Hardware === \r\nnvidia gpus   : 1\r\ntorch devices : 1\r\n  - gpu0      : 11441MB | Tesla K80\r\n\r\n=== Environment === \r\nplatform      : Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic\r\ndistro        : #1 SMP Wed Dec 19 21:19:13 PST 2018\r\nconda env     : Unknown\r\npython        : /usr/bin/python3\r\nsys.path      : \r\n/env/python\r\n/usr/lib/python36.zip\r\n/usr/lib/python3.6\r\n/usr/lib/python3.6/lib-dynload\r\n/usr/local/lib/python3.6/dist-packages\r\n/usr/lib/python3/dist-packages\r\n/usr/local/lib/python3.6/dist-packages/IPython/extensions\r\n/root/.ipython\r\n```\r\n\r\n**Code part:**\r\n``` \r\ndata = (ObjectItemList.from_df(pd.DataFrame(data=list(fn2bbox.keys())), path='/content/SDataset/train')\r\n        .split_by_rand_pct() \r\n        .label_from_func(get_y_func)\r\n        .databunch(bs=BS, num_workers=NUM_WORKERS)\r\n        .normalize(imagenet_stats))\r\n\r\ndata.export('/content/d.pkl')\r\nloaded_data = DataBunch.load_empty('/content', fname='d.pkl')\r\n```\r\n\r\nI received: **AttributeError: 'ObjectCategoryProcessor' object has no attribute 'pad_idx'** \r\nThe same error I have when I am using **load_learner** func for inference.\r\n\r\n**How can I fix this?**\r\n\r\n**Trace**\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-26-4fe3047396b9> in <module>()\r\n----> 1 dada = DataBunch.load_empty('/content', fname='d.pkl')\r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/data_block.py in _databunch_load_empty(cls, path, fname)\r\n    712 def _databunch_load_empty(cls, path, fname:str='export.pkl'):\r\n    713     \"Load an empty `DataBunch` from the exported file in `path/fname` with optional `tfms`.\"\r\n--> 714     sd = LabelLists.load_empty(path, fn=fname)\r\n    715     return sd.databunch()\r\n    716 \r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/data_block.py in load_empty(cls, path, fn)\r\n    560         path = Path(path)\r\n    561         state = torch.load(open(path/fn, 'rb'))\r\n--> 562         return LabelLists.load_state(path, state)\r\n    563 \r\n    564 def _check_kwargs(ds:ItemList, tfms:TfmList, **kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/data_block.py in load_state(cls, path, state)\r\n    551         \"Create a `LabelLists` with empty sets from the serialized `state`.\"\r\n    552         path = Path(path)\r\n--> 553         train_ds = LabelList.load_state(path, state)\r\n    554         valid_ds = LabelList.load_state(path, state)\r\n    555         return LabelLists(path, train=train_ds, valid=valid_ds)\r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/data_block.py in load_state(cls, path, state)\r\n    663         x = state['x_cls']([], path=path, processor=state['x_proc'], ignore_empty=True)\r\n    664         y = state['y_cls']([], path=path, processor=state['y_proc'], ignore_empty=True)\r\n--> 665         res = cls(x, y, tfms=state['tfms'], tfm_y=state['tfm_y'], **state['tfmargs']).process()\r\n    666         if state.get('tfms_y', False):    res.tfms_y    = state['tfms_y']\r\n    667         if state.get('tfmargs_y', False): res.tfmargs_y = state['tfmargs_y']\r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/data_block.py in process(self, xp, yp, name)\r\n    671     def process(self, xp:PreProcessor=None, yp:PreProcessor=None, name:str=None):\r\n    672         \"Launch the processing on `self.x` and `self.y` with `xp` and `yp`.\"\r\n--> 673         self.y.process(yp)\r\n    674         if getattr(self.y, 'filter_missing_y', False):\r\n    675             filt = array([o is None for o in self.y.items])\r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/data_block.py in process(self, processor)\r\n     72         if processor is not None: self.processor = processor\r\n     73         self.processor = listify(self.processor)\r\n---> 74         for p in self.processor: p.process(self)\r\n     75         return self\r\n     76 \r\n\r\n/usr/local/lib/python3.6/dist-packages/fastai/vision/data.py in process(self, ds)\r\n    328 \r\n    329     def process(self, ds:ItemList):\r\n--> 330         ds.pad_idx = self.pad_idx\r\n    331         super().process(ds)\r\n    332 \r\n\r\nAttributeError: 'ObjectCategoryProcessor' object has no attribute 'pad_idx'\r\n```",
	"issue_comments": "2"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "414147682",
	"issue_number": "1714",
	"issue_state": "closed",
	"issue_title": "How to use model_summary",
	"issue_body": "Hi. I am trying to figure out how to use model_summary\r\n```\r\ndep_var = 'closefwd'\r\nvalid_idx = range(len(X_train)-2000, len(X_train))\r\nprocs = [Normalize]\r\ndata = TabularDataBunch.from_df(path, X_train, dep_var, valid_idx=valid_idx,procs=procs, bs=1000)\r\nlearn = tabular_learner(data, layers=[200,100,75,50,25], metrics=mean_absolute_error )\r\nlearn.fit(50, 3.31E-02)\r\n```\r\nI am running this code successfully but then I try to run:\r\n`learn.model_summary`\r\nbut doesn't work. It says:\r\n`'Learner' object has no attribute 'model_summary'`",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "424661280",
	"issue_number": "1875",
	"issue_state": "closed",
	"issue_title": "tabular_learner factory method creates ReLu activation for first linear layer only ",
	"issue_body": "Factory method for `tabular_learner` should create non-linearity for each linear layer of the model, but  it creates a RelU   for the first layer only**\r\n\r\n**installation details**\r\n```text\r\n=== Software === \r\npython        : 3.6.8\r\nfastai        : 1.0.51.dev0\r\nfastprogress  : 0.1.20\r\ntorch         : 1.0.1.post2\r\nnvidia driver : 410.104\r\ntorch cuda    : 9.0.176 / is available\r\ntorch cudnn   : 7402 / is enabled\r\n\r\n=== Hardware === \r\nnvidia gpus   : 1\r\ntorch devices : 1\r\n  - gpu0      : 7949MB | GeForce RTX 2070\r\n\r\n=== Environment === \r\nplatform      : Linux-4.15.0-46-generic-x86_64-with-debian-buster-sid\r\ndistro        : Ubuntu 18.04 bionic\r\nconda env     : part2\r\npython        : /home/serge/anaconda3/envs/part2/bin/python\r\nsys.path      : /home/serge/anaconda3/envs/part2/lib/python36.zip\r\n/home/serge/anaconda3/envs/part2/lib/python3.6\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/lib-dynload\r\n\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/fastai-1.0.51.dev0-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/dataclasses-0.6-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/torchvision-0.2.2.post3-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/spacy-2.1.1.dev0-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/typing-3.6.6-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/torch-1.0.1.post2-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/scipy-1.2.1-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/requests-2.21.0-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/PyYAML-5.1-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/Pillow-5.4.1-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/packaging-19.0-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/pandas-0.24.2-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/nvidia_ml_py3-7.352.0-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/numpy-1.16.2-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/numexpr-2.6.9-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/matplotlib-3.0.3-py3.6-linux-x86_64.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/beautifulsoup4-4.7.1-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/fastprogress-0.1.20-py3.6.egg\r\n/home/serge/anaconda3/envs/part2/lib/python3.6/site-packages/IPython/extensions\r\n/home/serge/.ipython\r\n```\r\n**To Reproduce**\r\n```python\r\nlearn = tabular_learner(data,layers=[300,200,100], ps=[.5]*3)\r\nlearn.summary()\r\n```\r\n```text\r\n======================================================================\r\nLayer (type)         Output Shape         Param #    Trainable \r\n======================================================================\r\nBatchNorm1d          [39]                 78         True      \r\n______________________________________________________________________\r\nLinear               [300]                12,000     True      \r\n______________________________________________________________________\r\nReLU                 [100]                0          False     \r\n______________________________________________________________________\r\nBatchNorm1d          [300]                600        True      \r\n______________________________________________________________________\r\nDropout              [300]                0          False     \r\n______________________________________________________________________\r\nLinear               [200]                60,200     True      \r\n______________________________________________________________________\r\nBatchNorm1d          [200]                400        True      \r\n______________________________________________________________________\r\nDropout              [200]                0          False     \r\n______________________________________________________________________\r\nLinear               [100]                20,100     True      \r\n______________________________________________________________________\r\nBatchNorm1d          [100]                200        True      \r\n______________________________________________________________________\r\nDropout              [100]                0          False     \r\n______________________________________________________________________\r\nLinear               [1]                  101        True      \r\n______________________________________________________________________\r\n\r\nTotal params: 93,679\r\nTotal trainable params: 93,679\r\nTotal non-trainable params: 0\r\n```\r\n\r\n**Expected behavior**\r\nReLU module should be listed after Linear [200] and Linear [100] modules\r\n",
	"issue_comments": "3"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "384020366",
	"issue_number": "1238",
	"issue_state": "closed",
	"issue_title": "TextClasDataBunch.from_ids sometimes create unusable databunches.",
	"issue_body": "**Describe the bug**\r\nIn some situations, the `learn.fit` that runs on a databunch created by `TextClasDataBunch.from_ids` will throw the following error:\r\n```\r\nFile \"/home/pczapla/workspace/_oss/fastai/fastai/fastai/text/data.py\", line 90, in pad_collate\r\n    if pad_first: res[-len(s[0]):,i] = LongTensor(s[0])\r\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: double, float, float16, int64, int32, and uint8.\r\n```\r\n\r\n\r\n**To Reproduce**\r\nThis code throws an error\r\n```\r\ndef test_from_ids_works_for_equally_length_sentences():\r\n    ids = [np.array([0])]*10\r\n    lbl = [0]*10\r\n    data = TextClasDataBunch.from_ids('/tmp', vocab=Vocab({0: BOS, 1:PAD}),\r\n                                      train_ids=ids, train_lbls=lbl,\r\n                                      valid_ids=ids, valid_lbls=lbl, classes={0:0})\r\n    text_classifier_learner(data).fit(1)\r\n```\r\nThe following will work fine\r\n```\r\ndef test_from_ids_works_for_variable_length_sentences():\r\n    ids = [np.array([0]),np.array([0,1])]*5 # notice diffrent number of elements in arrays\r\n    lbl = [0]*10\r\n    data = TextClasDataBunch.from_ids('/tmp', vocab=Vocab({0: BOS, 1:PAD}),\r\n                                      train_ids=ids, train_lbls=lbl,\r\n                                      valid_ids=ids, valid_lbls=lbl, classes={0:0})\r\n    text_classifier_learner(data).fit(1)\r\n```\r\n\r\n**Additional context**\r\nThe issue is caused by a subtle \"feature\" of numpy, that can cast an object array of int arrays to one ndarray of objects. It is best shown by example:\r\n```\r\n>>> a = array([array([0]), array([0,1])], dtype=object); a\r\narray([array([0]), array([0, 1])], dtype=object) # is an object array of int arrays\r\n>>> b = array([array([0]), array([0])], dtype=object); b\r\narray([[0],\r\n       [0]], dtype=object) # becomes 2d ndarray of objects\r\n>>> a[0].dtype\r\ndtype('int64')\r\n>>> b[0].dtype\r\ndtype('O')\r\n````\r\nThe array is converted to ndarray in the `ItemList` constructor.  Here:\r\nhttps://github.com/fastai/fastai/blob/master/fastai/data_block.py#L45\r\n\r\nThe issue seems to be very exotic but it can be easily triggered when one write tests.\r\nIt took me quite some time to understand what is going on, as I haven't notice at first that the `array` becomes `ndarray`. \r\n\r\nI can propose a fix by adding a postprocessor to TextClasDataBunch.from_ids that converst the ndarray to object array of arrays of ints. Or we can simply add assert to warn ppl when this behaviour occurs. What do you prefer?\r\n\r\n\r\n",
	"issue_comments": "2"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "394572875",
	"issue_number": "1401",
	"issue_state": "closed",
	"issue_title": "Missing libraries",
	"issue_body": "Hello,\r\n\r\nI cloned the github repository in order to try to follow some courses but many Python libraries seem missing. \r\nMessages like: \r\n`ModuleNotFoundError: No module named <package_name> `\r\nare displayed while running the first ml \"lesson1-rf.ipynb\" notebook.\r\n\r\nHere are some libs which could be integrated (I actually wonder why it is not the case) to the **requirements.txt** or **setup.py** file:\r\n\r\n- bcolz\r\n- seaborn\r\n- graphviz\r\n- isoweek\r\n- sklearn_pandas\r\n- pdpbox\r\n- pandas_summary (this one is not recognized even after having installed it (fig.1)).\r\n- torchtext\r\n- plotnine \r\n- feather-format \r\n- jupyter_contrib_nbextensions\r\n- docrepr\r\n- awscli\r\n- kaggle-cli\r\n- (... and probably others)\r\n\r\nI'm on Ubuntu 18.04 (4.15.0-43-generic x86_64 GNU/Linux) using Python 3.6.7, pip 18.1 and virtualenv 16.1.0.\r\nThanks.\r\n\r\n![untitled](https://user-images.githubusercontent.com/19967599/50507246-fa1df300-0a7c-11e9-8807-efc79c14eae9.png)\r\n_**Fig.1**. \"pandas_summary\" is still missing even after having explicitly installed it._\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "384043648",
	"issue_number": "1242",
	"issue_state": "closed",
	"issue_title": "RNNLearner tries fitting test data",
	"issue_body": "**Describe the bug**\r\nWhen trying to fit an RNNLearner which was given a TextClasDataBunch containing a test dataset, the RNNLearner tries to fit the test dataset as well and fails.\r\n\r\n**To Reproduce**\r\n```py\r\npath = Path('data')\r\ndata = TextClasDataBunch.from_csv(path, 'train.csv', test='test.csv', label_cols='target')\r\nlearn = text_classifier_learner(data, drop_mult=0.5)\r\nlearn.freeze()\r\nlearn.lr_find()\r\nlearn.fit_one_cycle(1, max_lr=slice(1e-3, 1e-1), moms=(0.8,0.7))\r\n```\r\n\r\n**Expected behavior**\r\nlearn.fit_one_cycle return the same results as when trained using a TextClasDataBunch which doesn't have a test dataset.\r\n\r\n**Screenshots**\r\n![](https://i.imgur.com/GyRb3aM.png)\r\n\r\n<details>\r\n<summary>traceback</summary>\r\n\r\n```pytb\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-19-74e1eee4bf32> in <module>\r\n----> 1 learn.fit_one_cycle(1, max_lr=slice(1e-3, 1e-1), moms=(0.8,0.7))\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/train.py in fit_one_cycle(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\r\n     18     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\r\n     19                                         pct_start=pct_start, **kwargs))\r\n---> 20     learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)\r\n     21 \r\n     22 def lr_find(learn:Learner, start_lr:Floats=1e-7, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, **kwargs:Any):\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)\r\n    160         callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)\r\n    161         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\r\n--> 162             callbacks=self.callbacks+callbacks)\r\n    163 \r\n    164     def create_opt(self, lr:Floats, wd:Floats=0.)->None:\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)\r\n     92     except Exception as e:\r\n     93         exception = e\r\n---> 94         raise e\r\n     95     finally: cb_handler.on_train_end(exception)\r\n     96 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)\r\n     87             if hasattr(data,'valid_dl') and data.valid_dl is not None:\r\n     88                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,\r\n---> 89                                        cb_handler=cb_handler, pbar=pbar)\r\n     90             else: val_loss=None\r\n     91             if cb_handler.on_epoch_end(val_loss): break\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in validate(model, dl, loss_func, cb_handler, pbar, average, n_batch)\r\n     47     with torch.no_grad():\r\n     48         val_losses,nums = [],[]\r\n---> 49         for xb,yb in progress_bar(dl, parent=pbar, leave=(pbar is not None)):\r\n     50             if cb_handler: xb, yb = cb_handler.on_batch_begin(xb, yb, train=False)\r\n     51             val_losses.append(loss_batch(model, xb, yb, loss_func, cb_handler=cb_handler))\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastprogress/fastprogress.py in __iter__(self)\r\n     63         self.update(0)\r\n     64         try:\r\n---> 65             for i,o in enumerate(self._gen):\r\n     66                 yield o\r\n     67                 if self.auto_update: self.update(i+1)\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_data.py in __iter__(self)\r\n     45     def __iter__(self):\r\n     46         \"Process and returns items from `DataLoader`.\"\r\n---> 47         for b in self.dl:\r\n     48             y = b[1][0] if is_listy(b[1]) else b[1]\r\n     49             if not self.skip_size1 or y.size(0) != 1: yield self.proc_batch(b)\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py in __next__(self)\r\n    612     def __next__(self):\r\n    613         if self.num_workers == 0:  # same-process loading\r\n--> 614             indices = next(self.sample_iter)  # may raise StopIteration\r\n    615             batch = self.collate_fn([self.dataset[i] for i in indices])\r\n    616             if self.pin_memory:\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/sampler.py in __iter__(self)\r\n    158     def __iter__(self):\r\n    159         batch = []\r\n--> 160         for idx in self.sampler:\r\n    161             batch.append(idx)\r\n    162             if len(batch) == self.batch_size:\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/text/data.py in __iter__(self)\r\n     59     def __len__(self) -> int: return len(self.data_source)\r\n     60     def __iter__(self):\r\n---> 61         return iter(sorted(range_of(self.data_source), key=self.key, reverse=True))\r\n     62 \r\n     63 class SortishSampler(Sampler):\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/text/data.py in <lambda>(t)\r\n    244         dataloaders = [train_dl]\r\n    245         for ds in datasets[1:]:\r\n--> 246             sampler = SortSampler(ds.x, key=lambda t: len(ds[t][0].data))\r\n    247             dataloaders.append(DataLoader(ds, batch_size=bs, sampler=sampler, **kwargs))\r\n    248         return cls(*dataloaders, path=path, collate_fn=collate_fn)\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/data_block.py in __getitem__(self, idxs)\r\n    413     def __getitem__(self,idxs:Union[int,np.ndarray])->'LabelList':\r\n    414         if isinstance(try_int(idxs), int):\r\n--> 415             if self.item is None: x,y = self.x[idxs],self.y[idxs]\r\n    416             else:                 x,y = self.item   ,0\r\n    417             if self.tfms:\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/data_block.py in __getitem__(self, idxs)\r\n     80 \r\n     81     def __getitem__(self,idxs:int)->Any:\r\n---> 82         if isinstance(try_int(idxs), int): return self.get(idxs)\r\n     83         else: return self.new(self.items[idxs], xtra=index_row(self.xtra, idxs))\r\n     84 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/text/data.py in get(self, i)\r\n    309 \r\n    310     def get(self, i):\r\n--> 311         o = super().get(i)\r\n    312         return Text(o, self.vocab.textify(o))\r\n    313 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/fastai/data_block.py in get(self, i)\r\n     50     def __post_init__(self): pass\r\n     51     def __len__(self)->int: return len(self.items) or 1\r\n---> 52     def get(self, i)->Any: return self.items[i]\r\n     53     def __repr__(self)->str:\r\n     54         items = [self[i] for i in range(min(5,len(self.items)))]\r\n\r\nIndexError: index 56370 is out of bounds for axis 0 with size 56370\r\n```\r\n\r\n</details>\r\n\r\n**Additional context**\r\nThe reason I gave the optional test dataset to the TextClasDataBunch is so that I can use the `get_preds()` method from learn using the test dataset type\r\n```\r\ny_test = learn.get_preds(ds_type=DatasetType.Test)\r\n```\r\nThe lack of documentation makes it difficult to figure out this really common use case.\r\nAlso discussed in https://forums.fast.ai/t/text-classifier-learner-predict-all-rows-of-a-textclasdatabunch/30792/2",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "488686562",
	"issue_number": "2316",
	"issue_state": "closed",
	"issue_title": "Calling learn.get_preds and then learn.fit throws RuntimeError when using mixup",
	"issue_body": "**Describe the bug**\r\nMinimal example:\r\n\r\n```\r\nfrom fastai import *\r\nfrom fastai.vision import *\r\n\r\npath = untar_data(URLs.MNIST_SAMPLE)\r\ndata = ImageDataBunch.from_folder(path)\r\nlearn = cnn_learner(data, models.resnet18, metrics=accuracy).mixup()\r\n\r\nval_preds, val_y, val_losses = learn.get_preds(with_loss=True, ds_type = DatasetType.Valid)\r\n\r\nlearn.fit(1)\r\n```\r\n\r\nthrows\r\n```\r\nTraceback (most recent call last):                                               \r\n  File \"bug.py\", line 13, in <module>\r\n    learn.fit(1)\r\n  File \"/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages/fastai/basic_train.py\", line 202, in fit\r\n    fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)\r\n  File \"/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages/fastai/basic_train.py\", line 100, in fit\r\n    xb, yb = cb_handler.on_batch_begin(xb, yb)\r\n  File \"/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages/fastai/callback.py\", line 279, in on_batch_begin\r\n    self('batch_begin', mets = not self.state_dict['train'])\r\n  File \"/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages/fastai/callback.py\", line 251, in __call__\r\n    for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\r\n  File \"/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages/fastai/callback.py\", line 241, in _call_and_update\r\n    new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\r\n  File \"/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages/fastai/callbacks/mixup.py\", line 29, in on_batch_begin\r\n    new_target = torch.cat([last_target[:,None].float(), y1[:,None].float(), lambd[:,None].float()], 1)\r\nRuntimeError: invalid argument 0: Tensors must have same number of dimensions: got 2 and 3 at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THC/generic/THCTensorMath.cu:62\r\n```\r\nMaybe related to https://github.com/fastai/fastai/issues/2233 .\r\n\r\n**Installation**\r\n```text\r\n=== Software === \r\npython        : 3.7.3\r\nfastai        : 1.0.57\r\nfastprogress  : 0.1.21\r\ntorch         : 1.1.0\r\nnvidia driver : 430.40\r\ntorch cuda    : 10.0.130 / is available\r\ntorch cudnn   : 7501 / is enabled\r\n\r\n=== Hardware === \r\nnvidia gpus   : 1\r\ntorch devices : 1\r\n  - gpu0      : 2002MB | GeForce MX150\r\n\r\n=== Environment === \r\nplatform      : Linux-5.0.0-25-generic-x86_64-with-debian-buster-sid\r\ndistro        : #26-Ubuntu SMP Thu Aug 1 12:04:58 UTC 2019\r\nconda env     : mymlenv\r\npython        : /home/florian/miniconda3/envs/mymlenv/bin/python\r\nsys.path      : /home/florian/code/1909_fastai_bug\r\n/home/florian/miniconda3/envs/mymlenv/lib/python37.zip\r\n/home/florian/miniconda3/envs/mymlenv/lib/python3.7\r\n/home/florian/miniconda3/envs/mymlenv/lib/python3.7/lib-dynload\r\n/home/florian/miniconda3/envs/mymlenv/lib/python3.7/site-packages\r\n```\r\nThe bug is also there on master, installed via `pip install git+https://github.com/fastai/fastai/` on a clean conda env.",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "484494854",
	"issue_number": "2295",
	"issue_state": "closed",
	"issue_title": "RuntimeError: Expected object of scalar type Bool but got scalar type Byte for argument #2 'other'",
	"issue_body": "Hi,\r\n\r\nI got the following error while using accuracy_thresh_expand:\r\n`RuntimeError: Expected object of scalar type Bool but got scalar type Byte for argument #2 'other'`\r\n\r\n```\r\ndef accuracy_thresh_expand(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True)->Rank0Tensor:\r\n    \"Compute accuracy after expanding `y_true` to the size of `y_pred`.\"\r\n    if sigmoid: y_pred = y_pred.sigmoid()\r\n    return ((y_pred>thresh)==y_true[:,None].expand_as(y_pred).byte()).float().mean()\r\n```\r\n\r\nCurrently the function is implemented as above. I was able to solve the issue by replacing `.byte` with `.bool()`.",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "456883987",
	"issue_number": "2171",
	"issue_state": "closed",
	"issue_title": "Cannot select sampler when creating a TextClasDataBunch",
	"issue_body": "version 1.0.53.post2\r\n\r\n```\r\nclas_train_df, clas_valid_df, labels = load_dataframes(\r\n    df_path, split, uni_cats=False\r\n)\r\nweights = 1 / clas_train_df['label'].value_counts()\r\nsampler = WeightedRandomSampler(weights, len(clas_train_df), replacement=False)\r\ndata_clas = TextClasDataBunch.from_df(\r\n    output_dir,\r\n    clas_train_df,\r\n    clas_valid_df,\r\n    vocab=data_lang.train_ds.vocab,\r\n    classes=labels,\r\n    bs=32,\r\n    sampler=sampler\r\n)\r\n```\r\n\r\nErrors:\r\n```\r\n~/anaconda3/envs/nlp/lib/python3.6/site-packages/fastai/text/data.py in create(cls, train_ds, valid_ds, test_ds, path, bs, val_bs, pad_idx, pad_first, device, no_check, backwards, dl_tfms, **dl_kwargs)\r\n    263         collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\r\n    264         train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\r\n--> 265         train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\r\n    266         dataloaders = [train_dl]\r\n    267         for ds in datasets[1:]:\r\n\r\nTypeError: type object got multiple values for keyword argument 'sampler'\r\n```",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "465972549",
	"issue_number": "2212",
	"issue_state": "closed",
	"issue_title": "Cannot load learner if using MultiLabelFbeta as metric",
	"issue_body": "<!-- BEFORE POSTING AN ISSUE PLEASE MAKE SURE TO READ: https://docs.fast.ai/support.html -->\r\n\r\n<!-- **Important:** We try our best to fix all reported issue. The main difficulty we have is not being able to read your mind. If you don't follow the steps below, we have to follow up asking you to supply the required information, but we have already asked you to do so, so please don't waste our time and yours and supply it in first place. If you don't, your issue will be closed. You are free to resubmit this time with the required information. Thank you for helping us help you. -->\r\n\r\n<!-- **Please note**:\r\n- Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n\r\n- fastai github Issues are only for bugs in the library. If you want to suggest a new feature please use https://forums.fast.ai/t/fastai-v1-adding-features/23041. If you're unsure whether your bug comes from your code or the library, please use the forums to discuss your code first, then file an issue if needed.\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nUsing the `MultiLabelFbeta` class as a metric produces metrics that are seemingly correct, however the learner cannot be loaded after having been persisted. \r\n\r\n**Provide your installation details**\r\n<!-- We need to have some background to know how to fix your bug. -->\r\n<!-- Copy-n-paste the output of `show_install`, by either running this cell in jupyter notebook:\r\n```\r\nfrom fastai.utils.show_install import *\r\nshow_install()\r\n```\r\nor via your shell:\r\n```\r\npython -m fastai.utils.show_install\r\n```\r\nDouble-check you use the latest version which you can find here: https://github.com/fastai/fastai/releases.\r\n\r\nIt's also possible that the issue has already been fixed in git master, but hasn't been released yet, so if possible please try to see whether git master has it resolved. To install the git master do: `pip install git+https://github.com/fastai/fastai/`\r\n-->\r\n```text\r\n=== Software === \r\npython        : 3.6.7\r\nfastai        : 1.0.54\r\nfastprogress  : 0.1.21\r\ntorch         : 1.0.1\r\nnvidia driver : 390.116\r\ntorch cuda    : 10.0.130 / is **Not available** \r\n\r\n=== Hardware === \r\nnvidia gpus   : 1\r\nHave 1 GPU(s), but torch can't use them (check nvidia driver) \r\n\r\n=== Environment === \r\nplatform      : Linux-4.15.0-48-generic-x86_64-with-debian-buster-sid\r\ndistro        : #51-Ubuntu SMP Wed Apr 3 08:28:49 UTC 2019\r\nconda env     : fai\r\npython        : /home/ss/anaconda3/envs/fai/bin/python\r\nsys.path      : \r\n/home/ss/anaconda3/envs/fai/lib/python36.zip\r\n/home/ss/anaconda3/envs/fai/lib/python3.6\r\n/home/ss/anaconda3/envs/fai/lib/python3.6/lib-dynload\r\n/home/ss/.local/lib/python3.6/site-packages\r\n/home/ss/anaconda3/envs/fai/lib/python3.6/site-packages\r\n```\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. Please give us a reproducible example so we can fix your bug.-->\r\n<!-- A gist to reproduce it is even better!-->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tree/master/tests/ that helps us reproduce the problem and will help with future regression testing. See https://docs.fast.ai/dev/test.html for details on how to run/write tests. -->\r\n\r\nThe steps to reproduce can be seen in this gist: https://gist.github.com/svenski/38474ff6ba2fa3ddd026acb846a924ed \r\n\r\nI don't think it's the _fastest_ way to reproduce but I hope it's clear still.\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nNo error when loading the learner. \r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help demonstrate your problem. -->\r\n\r\nHere is the stack trace:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/workspace/fast_ai_bug/bla.py in <module>\r\n     26\r\n     27 learn_c.save('bla')\r\n---> 28 learn_c.load('bla')\r\n     29\r\n\r\n~/anaconda3/envs/fai/lib/python3.6/site-packages/fastai/basic_train.py in load(self, file, device, strict, with_opt\r\n, purge, remove_module)\r\n    261              with_opt:bool=None, purge:bool=True, remove_module:bool=False):\r\n    262         \"Load model and optimizer state (if `with_opt`) `file` from `self.model_dir` using `device`. `file`\r\n can be file-like (file or buffer)\"\r\n--> 263         if purge: self.purge(clear_opt=ifnone(with_opt, False))\r\n    264         if device is None: device = self.data.device\r\n    265         elif isinstance(device, int): device = torch.device('cuda', device)\r\n\r\n~/anaconda3/envs/fai/lib/python3.6/site-packages/fastai/basic_train.py in purge(self, clear_opt)\r\n    313\r\n    314         tmp_file = get_tmp_file(self.path/self.model_dir)\r\n--> 315         torch.save(state, open(tmp_file, 'wb'))\r\n    316         for a in attrs_del: delattr(self, a)\r\n    317         gc.collect()\r\n\r\n~/anaconda3/envs/fai/lib/python3.6/site-packages/torch/serialization.py in save(obj, f, pickle_module, pickle_proto\r\ncol)\r\n    217         >>> torch.save(x, buffer)\r\n    218     \"\"\"\r\n--> 219     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\r\n    220\r\n    221\r\n\r\n~/anaconda3/envs/fai/lib/python3.6/site-packages/torch/serialization.py in _with_file_like(f, mode, body)\r\n    142         f = open(f, mode)\r\n    143     try:\r\n--> 144         return body(f)\r\n    145     finally:\r\n    146         if new_fd:\r\n\r\n~/anaconda3/envs/fai/lib/python3.6/site-packages/torch/serialization.py in <lambda>(f)\r\n    217         >>> torch.save(x, buffer)\r\n    218     \"\"\"\r\n--> 219     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\r\n    220\r\n    221\r\n\r\n~/anaconda3/envs/fai/lib/python3.6/site-packages/torch/serialization.py in _save(obj, f, pickle_module, pickle_prot\r\nocol)\r\n    290     pickler = pickle_module.Pickler(f, protocol=pickle_protocol)\r\n    291     pickler.persistent_id = persistent_id\r\n--> 292     pickler.dump(obj)\r\n    293\r\n    294     serialized_storage_keys = sorted(serialized_storages.keys())\r\n\r\nTypeError: can't pickle weakref objects\r\n```\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "490195863",
	"issue_number": "2319",
	"issue_state": "closed",
	"issue_title": "Potencial bug in name on MultiLabelFbeta",
	"issue_body": "Hi\r\n\r\n**Describe the bug**\r\nSoory to bother you but I'm not sure if this is the intended behaviour or not. As MultiLabelFbeta is a LearnerCallback, you need to append to the metrics after the learner object has been created (https://forums.fast.ai/t/potential-bug-with-learnercallback/48313/4). However, this adds an extra column on the metrics table that isn't filled.\r\n\r\nI'm using fastai 1.0.57\r\n\r\n**To Reproduce**\r\n```\r\nlearn = cnn_learner(data, models.resnet18)\r\nlearn.metrics.append(MultiLabelFbeta(learn))\r\n```\r\n**Screenshots**\r\n![Screenshot 2019-09-06 at 10 18 03](https://user-images.githubusercontent.com/45995383/64412554-e442e200-d08f-11e9-94d2-a001def4f3af.png)\r\n\r\nLooking at the MultiLabelFbeta code, micro_fbeta is the intended name for the column.\r\n\r\n**Additional context**\r\nA workaround is to pass to callback_fns so the columns are correctly named. However,  the metric is wrong as it uses also the training examples (#2318)\r\n\r\nFinally, if you try to pass MultiLabelFbeta on metrics arguments, it fails when computes the metric. ",
	"issue_comments": "2"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "390801856",
	"issue_number": "1335",
	"issue_state": "closed",
	"issue_title": "Cannot train LM in fp16 mode",
	"issue_body": "**Describe the bug**\r\nCannot train language model in half precision mode. \r\nThat's what I got during training:\r\n```\r\n/opt/conda/lib/python3.7/site-packages/fastai/text/models.py in forward(self, words, scale)\r\n     69         if scale: masked_embed.mul_(scale)\r\n     70         return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\r\n---> 71                            self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)\r\n     72 \r\n     73 #def _repackage_var(h:Tensors)->Tensors:\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py in embedding(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\r\n   1452         # remove once script supports set_grad_enabled\r\n   1453         _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\r\n-> 1454     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\n   1455 \r\n   1456 \r\n\r\nRuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.HalfTensor instead (while checking arguments for embedding)\r\n```\r\n\r\n**To Reproduce**\r\nI tried to run examples/text.ipynb with mixed precision\r\nTo do that I modified the following line:\r\n`learn = language_model_learner(data_lm, pretrained_model=URLs.WT103_1).to_fp16()`\r\n\r\n\r\n**Additional context**\r\n`cifar.ipynb` example works fine with fp16.\r\n```text\r\n=== Software === \r\npython        : 3.7.1\r\nfastai        : 1.0.37\r\nfastprogress  : 0.1.18\r\ntorch         : 1.0.0\r\nnvidia driver : 384.111\r\ntorch cuda    : 9.0.176 / is available\r\ntorch cudnn   : 7401 / is enabled\r\n\r\n=== Hardware === \r\nnvidia gpus   : 8\r\ntorch devices : 8\r\n  - gpu0      : 16152MB | Tesla V100-SXM2-16GB\r\n  - gpu1      : 16152MB | Tesla V100-SXM2-16GB\r\n\r\n=== Environment === \r\nplatform      : Linux-4.4.0-112-generic-x86_64-with-debian-stretch-sid\r\ndistro        : #135-Ubuntu SMP Fri Jan 19 11:48:36 UTC 2018\r\nconda env     : Unknown\r\npython        : /opt/conda/bin/python\r\nsys.path      : /home/usr\r\n\r\n/opt/pytorch/pytorch/torch/lib/python3.6/site-packages\r\n/opt/conda/lib/python3.6/site-packages\r\n/usr/local/onnx\r\n/opt/conda/lib/python37.zip\r\n/opt/conda/lib/python3.7\r\n/opt/conda/lib/python3.7/lib-dynload\r\n/opt/conda/lib/python3.7/site-packages\r\n/opt/conda/lib/python3.7/site-packages/IPython/extensions\r\n/root/.ipython\r\n```\r\n",
	"issue_comments": "3"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "344758529",
	"issue_number": "656",
	"issue_state": "closed",
	"issue_title": "Can not use pytorch 0.3.1",
	"issue_body": "I use win10 with no GPU and the newest version.\r\n\r\nafter running the command \"conda env update -f environment-cpu.yml\"\r\neverything is OK, but when test is done, all 7 tests failed, because pytorch can not load the DLL:\r\n\r\nImportError while importing test module 'E:\\project_src\\fastai\\tests\\test_core.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\ntests\\__init__.py:3: in <module>\r\n    import cv2,torch\r\nE:\\Users\\baoyujian\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai-cpu\\lib\\site-packages\\torch\\__init__.py:76: in <module>\r\n    from torch._C import *\r\nE   ImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nHow to solve this?",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "353918810",
	"issue_number": "726",
	"issue_state": "closed",
	"issue_title": "if imdb_scripts can be run on windows computer?",
	"issue_body": "\r\n\r\nif https://github.com/fastai/fastai/tree/master/courses/dl2/imdb_scripts  can be run on windows computer, for example windows computer torch installation is impossible ",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "384481520",
	"issue_number": "1248",
	"issue_state": "closed",
	"issue_title": "text_classifier_learner doesn't use metrics from kwargs",
	"issue_body": "<!-- **Please note**: Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen running a standard example with the text_classifier_learner any metrics provided are overwritten by hardcoded metrics.\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. -->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tests that helps us reproduce the problem and will help with future regression testing -->\r\nRun the example for text classification from the docs and define the metrics:\r\n```\r\nf1 = partial(fbeta, beta=1)\r\nlearn = text_classifier_learner(data_cls, drop_mult=0.5, metrics=[f1])\r\nlearn.load_encoder('ft_enc_unfrozen')\r\nlearn.fit_one_cycle(1, 1e-2)\r\n```\r\n\r\nResults in \r\n\r\n```\r\nepoch | train_loss | valid_loss | accuracy\r\n-- | -- | -- | --\r\n```\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nExpected behavior would be to replace \"accuracy\" with the provided metrics, such as fbeta in the example.\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\nThe bug originates from line 55 of fastai.text.learner.\r\n\r\n```\r\n 47 class RNNLearner(Learner):\r\n 48     \"Basic class for a Learner in RNN.\"\r\n 49     def __init__(self, data:DataBunch, model:nn.Module, bptt:int=70, split_func:OptSplitFunc=None, clip:float=None,\r\n 50                  adjust:bool=False, alpha:float=2., beta:float=1., **kwargs):\r\n 51         super().__init__(data, model, **kwargs)\r\n 52         self.callbacks.append(RNNTrainer(self, bptt, alpha=alpha, beta=beta, adjust=adjust))\r\n 53         if clip: self.callback_fns.append(partial(GradientClipping, clip=clip))\r\n 54         if split_func: self.split(split_func)\r\n 55         self.metrics = [accuracy]\r\n```\r\n\r\nChanging line 55 to `self.metrics = kwargs['metrics']` doesn't resolve the issue for me. I've tried the partially applied fbeta (f1) from my initial example, fbeta, and accuracy. Accuracy works, but the others don't. Here's the stack trace:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-90-1dda766350bf> in <module>\r\n      1 learn.load_encoder('ft_enc_unfrozen')\r\n----> 2 learn.fit_one_cycle(1, 1e-2)\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/train.py in fit_one_cycle(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\r\n     18     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\r\n     19                                         pct_start=pct_start, **kwargs))\r\n---> 20     learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)\r\n     21 \r\n     22 def lr_find(learn:Learner, start_lr:Floats=1e-7, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, **kwargs:Any):\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)\r\n    160         callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)\r\n    161         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\r\n--> 162             callbacks=self.callbacks+callbacks)\r\n    163 \r\n    164     def create_opt(self, lr:Floats, wd:Floats=0.)->None:\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)\r\n     92     except Exception as e:\r\n     93         exception = e\r\n---> 94         raise e\r\n     95     finally: cb_handler.on_train_end(exception)\r\n     96 \r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)\r\n     87             if hasattr(data,'valid_dl') and data.valid_dl is not None:\r\n     88                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,\r\n---> 89                                        cb_handler=cb_handler, pbar=pbar)\r\n     90             else: val_loss=None\r\n     91             if cb_handler.on_epoch_end(val_loss): break\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py in validate(model, dl, loss_func, cb_handler, pbar, average, n_batch)\r\n     52             if not is_listy(yb): yb = [yb]\r\n     53             nums.append(yb[0].shape[0])\r\n---> 54             if cb_handler and cb_handler.on_batch_end(val_losses[-1]): break\r\n     55             if n_batch and (len(nums)>=n_batch): break\r\n     56         nums = np.array(nums, dtype=np.float32)\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/callback.py in on_batch_end(self, loss)\r\n    236         \"Handle end of processing one batch with `loss`.\"\r\n    237         self.state_dict['last_loss'] = loss\r\n--> 238         stop = np.any(self('batch_end', not self.state_dict['train']))\r\n    239         if self.state_dict['train']:\r\n    240             self.state_dict['iteration'] += 1\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/callback.py in __call__(self, cb_name, call_mets, **kwargs)\r\n    184     def __call__(self, cb_name, call_mets=True, **kwargs)->None:\r\n    185         \"Call through to all of the `CallbakHandler` functions.\"\r\n--> 186         if call_mets: [getattr(met, f'on_{cb_name}')(**self.state_dict, **kwargs) for met in self.metrics]\r\n    187         return [getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs) for cb in self.callbacks]\r\n    188 \r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/callback.py in <listcomp>(.0)\r\n    184     def __call__(self, cb_name, call_mets=True, **kwargs)->None:\r\n    185         \"Call through to all of the `CallbakHandler` functions.\"\r\n--> 186         if call_mets: [getattr(met, f'on_{cb_name}')(**self.state_dict, **kwargs) for met in self.metrics]\r\n    187         return [getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs) for cb in self.callbacks]\r\n    188 \r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/callback.py in on_batch_end(self, last_output, last_target, train, **kwargs)\r\n    269         if not is_listy(last_target): last_target=[last_target]\r\n    270         self.count += last_target[0].size(0)\r\n--> 271         self.val += last_target[0].size(0) * self.func(last_output, *last_target).detach().cpu()\r\n    272 \r\n    273     def on_epoch_end(self, **kwargs):\r\n\r\n/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/metrics.py in fbeta(y_pred, y_true, thresh, beta, eps, sigmoid)\r\n     11     y_pred = (y_pred>thresh).float()\r\n     12     y_true = y_true.float()\r\n---> 13     TP = (y_pred*y_true).sum(dim=1)\r\n     14     prec = TP/(y_pred.sum(dim=1)+eps)\r\n     15     rec = TP/(y_true.sum(dim=1)+eps)\r\n\r\nRuntimeError: The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 1\r\n```\r\n\r\nBTW: thanks for fast.ai: the MOOC and the library. Good stuff. (Although using fastai_v1 is quite tedious currently it seems to be getting better quickly.)\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "372822579",
	"issue_number": "939",
	"issue_state": "closed",
	"issue_title": "Error on  RNNLearner.language_model(...)",
	"issue_body": "I'm using the \"TextLMDataBunch.from_df()\" method ... and while I can iterate through the mini-batches and they all look good, I'm not getting an error when I run the following.  Everything was working fine until I got the latest.\r\n\r\n```\r\nlearn = RNNLearner.language_model(data_lm, pretrained_fnames=['lstm_wt103', 'itos_wt103'], drop_mult=0.5)\r\nlearn.fit_one_cycle(1, 1e-2)\r\n```\r\n... was working fine before but is now throwing an exception ...\r\n\r\n\"Target size (torch.Size([5920])) must be the same as input size (torch.Size([5920, 25951]))\"\r\n\r\n<img width=\"1020\" alt=\"screen shot 2018-10-22 at 11 04 10 pm\" src=\"https://user-images.githubusercontent.com/14000/47339055-e1ddc200-d64e-11e8-8428-51d1fabeed4e.png\">\r\n",
	"issue_comments": "2"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "381899642",
	"issue_number": "1203",
	"issue_state": "closed",
	"issue_title": "Running TTA() in fp16 / half mode raises \"RuntimeError: _th_cat is not implemented for type torch.HalfTensor\" + work-around",
	"issue_body": "**Describe the bug**\r\n\r\nThis is with fastai 1.0.24 and a fairly recent (a few days old) build of PyTorch master on CUDA 10.\r\n\r\nAfter successfully training and being able to call `get_preds()` normally, invoking `learn.TTA()` raises the following exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n    File \"<stdin>\", line 1, in <module>\r\n    File \"/home/cpbotha/Dropbox/work/code/kaggle/human-protein-atlas/exp_20181117_fastai_other_nets.py\", line 176, in <module>\r\n     vpreds, vtargs = learner.TTA()\r\n    File \"/home/cpbotha/miniconda3/envs/kag-protein/lib/python3.7/site-packages/fastai/vision/tta.py\", line 35, in _TTA\r\n     avg_preds = torch.stack(all_preds).mean(0)\r\nRuntimeError: _th_cat is not implemented for type torch.HalfTensor\r\n```\r\n\r\n**To Reproduce**\r\n\r\nTrain any network in half precision mode, then try TTA().\r\n\r\n**Expected behavior**\r\n\r\nTTA should run without raising exceptions.\r\n\r\nOne can work around this issue by replacing this line in `tta.py`:\r\n\r\n``` python\r\navg_preds = torch.stack(all_preds).mean(0)\r\n```\r\n\r\nwith this:\r\n\r\n``` python\r\navg_vpreds = torch.stack([p.float() for p in all_preds]).mean(0)\r\n```\r\n(It might be more compact to combine this float-converting list comprehension with the tta_only() generator invocation on the previous line, but I have not tested that. Let me know if I should make a PR.)",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "444898843",
	"issue_number": "2093",
	"issue_state": "closed",
	"issue_title": " TransformerXL Errors: shape '[64, 70, 10, 41]' is invalid for input of size 3673600",
	"issue_body": "when I'm trying to use TransformerXL model, such as:\r\n`path = untar_data(URLs.IMDB_SAMPLE) \r\ndata = TextLMDataBunch.from_csv(path, 'texts.csv') \r\nvocab_size = len(data.vocab.itos) \r\ntransformer_model = get_language_model(TransformerXL,vocab_size) \r\nlearn = LanguageLearner(data, transformer_model)\r\n learn.fit(1)`\r\n\r\nI received the error:\r\n`  File \"/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/models/transformer.py\", line 108, in <lambda>\r\n\r\n    wq,wk,wv = map(lambda x:x.view(bs, x_len, self.n_heads, self.d_head), (wq,wk,wv))\r\n\r\nRuntimeError: shape '[64, 70, 10, 41]' is invalid for input of size 3673600`\r\n\r\nbut if I replaced :\r\ntransformer_model = get_language_model(TransformerXL,vocab_size)\r\n\r\nwith\r\n\r\ntransformer_model = get_language_model(Transformer,vocab_size)\r\n\r\nIt worked. what's wrong?\r\n\r\nsome additional info:\r\nfastai:1.0.52\r\npytorch:1.10\r\nubuntu 16.04\r\n\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "504786996",
	"issue_number": "2368",
	"issue_state": "closed",
	"issue_title": "Definition of AdamW",
	"issue_body": "**Describe the bug**\r\n\r\nIn [torch_core line 67](https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L67) `AdamW` is defined as \r\n```\r\nAdamW = functools.partial(torch.optim.adam.Adam, betas=(0.9,0.99))\r\n```\r\n\r\nI would've expected it to be an extenstion of `torch.optim.adam.AdamW` -- is the current code correct or a typo?  And if correct, is there documentation somewhere that could help me understand how this is intended to work?\r\n\r\nThanks!\r\n~ Ben",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "423371905",
	"issue_number": "1849",
	"issue_state": "closed",
	"issue_title": "fastai.text:  learn.load(filename) failes first time and succed next time",
	"issue_body": "versiob : '1.0.51.dev0'\r\n\r\n\r\n**Preceeding the failiur**\r\nTEXT = \"Andrew Yan-Tak Ng is a Chinese English computer scientist, executive, investor, \"\r\nN_WORDS = 40\r\nN_SENTENCES = 5\r\n\r\nprint((\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75, sep=\"\") for _ in range(N_SENTENCES))).replace(\"\u2581\",\"\"))\r\nprint((\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.25, sep=\"\") for _ in range(N_SENTENCES))).replace(\"\u2581\",\"\"))\r\n\r\npd_train_loss = pd.DataFrame(data=np.hstack([learn.recorder.losses]),  columns=[\"train_loss\"])\r\npd_train_loss.to_csv(pathTrainValid/f\"models/{model.name}/{experiment_name}_train_loss.csv\", header=\"losses\")\r\n\r\npd_valid_loss = pd.DataFrame(data=np.column_stack((learn.recorder.val_losses, learn.recorder.metrics)),  columns=[\"val_loss\", \"accuracy\"])\r\npd_valid_loss.to_csv(pathTrainValid/f\"models/{model.name}/{experiment_name}_valid_loss.csv\", header=\"losses\")\r\npd_train_loss = pd_valid_loss=None\r\ngc.collect()\r\n\r\n**Failes in this line**\r\n**learn = learn.load(f'{model.name}/{experiment_name}')**\r\n\r\n**THE error message:**\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-99-6a62bf5b0534> in <module>\r\n----> 1 learn = learn.load(f'{model.name}/{experiment_name}')\r\n\r\nd:\\code\\fastai\\fastai\\basic_train.py in load(self, name, device, strict, with_opt, purge, remove_module)\r\n    259             remove_module:bool=False):\r\n    260         \"Load model and optimizer state (if `with_opt`) `name` from `self.model_dir` using `device`.\"\r\n--> 261         if purge: self.purge(clear_opt=ifnone(with_opt, False))\r\n    262         if device is None: device = self.data.device\r\n    263         elif isinstance(device, int): device = torch.device('cuda', device)\r\n\r\nd:\\code\\fastai\\fastai\\basic_train.py in purge(self, clear_opt)\r\n    320         self.callbacks = [load_callback(c,s, self) for c,s in cb_state.items()]\r\n    321         if not clear_opt and 'opt' in state:\r\n--> 322             self.opt = OptimWrapper.load_with_state_and_layer_group(state['opt'], self.layer_groups)\r\n    323         del state\r\n    324         gc.collect()\r\n\r\nd:\\code\\fastai\\fastai\\callback.py in load_with_state_and_layer_group(cls, state, layer_groups)\r\n    153                      bn_wd=state['bn_wd'])\r\n    154         res._mom,res._beta = state['mom'],state['beta']\r\n--> 155         res.load_state_dict(state['opt_state'])\r\n    156         return res\r\n    157 \r\n\r\nc:\\users\\kl\\appdata\\local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\optim\\optimizer.py in load_state_dict(self, state_dict)\r\n    112         saved_lens = (len(g['params']) for g in saved_groups)\r\n    113         if any(p_len != s_len for p_len, s_len in zip(param_lens, saved_lens)):\r\n--> 114             raise ValueError(\"loaded state dict contains a parameter group \"\r\n    115                              \"that doesn't match the size of optimizer's group\")\r\n    116 \r\n\r\nValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "467416294",
	"issue_number": "2219",
	"issue_state": "closed",
	"issue_title": "TextClasDataBunch not able to show batch",
	"issue_body": "**Describe the bug**\r\nThe TextClasDataBunch's method `show_batch` raises ` KeyError: tensor(0)`.\r\n\r\n```text\r\n=== Software === \r\npython       : 3.7.3\r\nfastai       : 1.0.56.dev0\r\nfastprogress : 0.1.21\r\ntorch        : 1.1.0.post2\r\ntorch cuda   : None / is **Not available** \r\n\r\n=== Hardware === \r\nNo GPUs available \r\n\r\n=== Environment === \r\nplatform     : Darwin-18.6.0-x86_64-i386-64bit\r\nconda env    : base\r\npython       : /anaconda3/bin/python\r\nsys.path     : \r\n/anaconda3/lib/python37.zip\r\n/anaconda3/lib/python3.7\r\n/anaconda3/lib/python3.7/lib-dynload\r\n/Users/jakobelben/.local/lib/python3.7/site-packages\r\n/anaconda3/lib/python3.7/site-packages\r\n/anaconda3/lib/python3.7/site-packages/aeosa\r\n/anaconda3/lib/python3.7/site-packages/haversine-1.0.2-py2.7.egg\r\nno supported gpus found on this system\r\n```\r\n\r\n\r\n**To Reproduce**\r\n```\r\nfrom fastai.text import *\r\nids = [np.array([0]),np.array([0,1])]*5 # notice diffrent number of elements in arrays\r\nlbl = [0]*10\r\ndata = TextClasDataBunch.from_ids('/tmp', vocab=Vocab({0: BOS, 1:PAD}),\r\n                                  train_ids=ids, train_lbls=lbl,\r\n                                  valid_ids=ids, valid_lbls=lbl, classes={0:0}, bs=8)\r\ndata.show_batch()\r\n```\r\n**Expected behavior**\r\nIt should show the batch.\r\n\r\n**Traceback**\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-7-08d0dd5c9f7c> in <module>\r\n----> 1 data.show_batch()\r\n\r\n/private/tmp/fastai/fastai/basic_data.py in show_batch(self, rows, ds_type, reverse, **kwargs)\r\n    187         n_items = rows **2 if self.train_ds.x._square_show else rows\r\n    188         if self.dl(ds_type).batch_size < n_items: n_items = self.dl(ds_type).batch_size\r\n--> 189         xs = [self.train_ds.x.reconstruct(grab_idx(x, i)) for i in range(n_items)]\r\n    190         #TODO: get rid of has_arg if possible\r\n    191         if has_arg(self.train_ds.y.reconstruct, 'x'):\r\n\r\n/private/tmp/fastai/fastai/basic_data.py in <listcomp>(.0)\r\n    187         n_items = rows **2 if self.train_ds.x._square_show else rows\r\n    188         if self.dl(ds_type).batch_size < n_items: n_items = self.dl(ds_type).batch_size\r\n--> 189         xs = [self.train_ds.x.reconstruct(grab_idx(x, i)) for i in range(n_items)]\r\n    190         #TODO: get rid of has_arg if possible\r\n    191         if has_arg(self.train_ds.y.reconstruct, 'x'):\r\n\r\n/private/tmp/fastai/fastai/text/data.py in reconstruct(self, t)\r\n    338         idx_min = (t != self.pad_idx).nonzero().min()\r\n    339         idx_max = (t != self.pad_idx).nonzero().max()\r\n--> 340         return Text(t[idx_min:idx_max+1], self.vocab.textify(t[idx_min:idx_max+1]))\r\n    341 \r\n    342     @classmethod\r\n\r\n/private/tmp/fastai/fastai/text/transform.py in textify(self, nums, sep)\r\n    132     def textify(self, nums:Collection[int], sep=' ') -> List[str]:\r\n    133         \"Convert a list of `nums` to their tokens.\"\r\n--> 134         return sep.join([self.itos[i] for i in nums]) if sep is not None else [self.itos[i] for i in nums]\r\n    135 \r\n    136     def __getstate__(self):\r\n\r\n/private/tmp/fastai/fastai/text/transform.py in <listcomp>(.0)\r\n    132     def textify(self, nums:Collection[int], sep=' ') -> List[str]:\r\n    133         \"Convert a list of `nums` to their tokens.\"\r\n--> 134         return sep.join([self.itos[i] for i in nums]) if sep is not None else [self.itos[i] for i in nums]\r\n    135 \r\n    136     def __getstate__(self):\r\n\r\nKeyError: tensor(0)\r\n```",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "387603126",
	"issue_number": "1287",
	"issue_state": "closed",
	"issue_title": "running finetuning.py  ,AttributeError: 'numpy.ndarray' object has no attribute 'x'AttributeError: 'numpy.ndarray' object has no attribute 'x'",
	"issue_body": "<!-- **Please note**: Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. -->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tests that helps us reproduce the problem and will help with future regression testing -->\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "430962152",
	"issue_number": "1950",
	"issue_state": "closed",
	"issue_title": "Destroying a hooks callback early on causes it to fail",
	"issue_body": "simple bug - \r\nException ignored in: <bound method HookCallback.__del__ of ActivationStats\r\nlearn: None\r\nmodules: None\r\ndo_remove: True>\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/site-packages/fastai/callbacks/hooks.py\", line 80, in __del__\r\n    def __del__(self): self.remove()\r\n  File \"/opt/conda/lib/python3.6/site-packages/fastai/callbacks/hooks.py\", line 79, in remove\r\n    def remove(self): self.hooks.remove()\r\n  File \"/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py\", line 423, in __getattr__\r\n    def __getattr__(self,k): return getattr(self.learn, k)\r\nAttributeError: 'NoneType' object has no attribute 'hooks'\r\n\r\nThis fixes the issue. \r\n```diff --git a/fastai/callbacks/hooks.py b/fastai/callbacks/hooks.py\r\nindex cc4ddaff..0c9e63db 100644\r\n--- a/fastai/callbacks/hooks.py\r\n+++ b/fastai/callbacks/hooks.py\r\n@@ -63,6 +63,7 @@ class HookCallback(LearnerCallback):\r\n     \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"\r\n     def __init__(self, learn:Learner, modules:Sequence[nn.Module]=None, do_remove:bool=True):\r\n         super().__init__(learn)\r\n+        self.hooks = None\r\n         self.modules,self.do_remove = modules,do_remove\r\n\r\n     def on_train_begin(self, **kwargs):\r\n@@ -76,7 +77,10 @@ class HookCallback(LearnerCallback):\r\n         \"Remove the `Hooks`.\"\r\n         if self.do_remove: self.remove()\r\n\r\n-    def remove(self): self.hooks.remove()\r\n+    def remove(self):\r\n+               if self.hooks:\r\n+                       self.hooks.remove()\r\n+```\r\nMaking a pull request for fixing this issue.",
	"issue_comments": "2"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "375128007",
	"issue_number": "1007",
	"issue_state": "closed",
	"issue_title": "Test Failing for tests/test_vision_train.py",
	"issue_body": "<!-- **Please note**: Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nas of commit 6c70f9c4fa62277273ca2fc0ec69f14089b84b2d if one runs the testing suite, the tests fail. specifically ``` def test_image_data``` in ```tests/test_vision_train.py``` is failing.\r\n\r\n<img width=\"1033\" alt=\"screenshot 2018-10-29 at 20 50 02\" src=\"https://user-images.githubusercontent.com/40219100/47667592-6474fd00-dbcc-11e8-864c-1e4513ec6008.png\">\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. -->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tests that helps us reproduce the problem and will help with future regression testing -->\r\nrun ```make coverage``` as of this (6c70f9c4fa62277273ca2fc0ec69f14089b84b2d) commit.\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nAll the tests should pass. the ```mean-0.2``` of the first image in the dataset is 0.1181. \r\n\r\nif we compare to 0.12 then all the tests pass. screenshot below. \r\n![image](https://user-images.githubusercontent.com/40219100/47667780-d77e7380-dbcc-11e8-9407-c132f0a3348f.png)\r\n\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "344709242",
	"issue_number": "655",
	"issue_state": "closed",
	"issue_title": "ModuleNotFoundError:Windows10 ",
	"issue_body": "Download project: `git clone https://github.com/fastai/fastai.git`\r\n1. Move into root folder: `cd fastai`\r\n1. Set up Python environment: `conda env update`\r\n1. Activate Python environment: `conda activate fastai`\r\n\r\nAfter performing the above steps in Windows10 Nvidia GPU system . I am able to activate the fastai environment and i was able to open jupyter notebook too. But when i open any notebook and run the notebook . I found the below Error. ModuleNotFoundError(refer to below screenshot)\r\n\r\n![fastai](https://user-images.githubusercontent.com/41332953/43244828-cff57e9a-90c9-11e8-9595-1644eaa535c2.PNG)\r\nKindly help me here \r\n\r\n\r\n\r\n\r\n",
	"issue_comments": "3"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "416414866",
	"issue_number": "1735",
	"issue_state": "closed",
	"issue_title": "Target output size mismatch",
	"issue_body": "<!-- BEFORE POSTING AN ISSUE PLEASE MAKE SURE TO READ: https://docs.fast.ai/support.html -->\r\n\r\n<!-- **Please note**:\r\n- Installation issues should be reported here:\r\n\r\nfastai-1.0.x: http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111\r\nfastai-0.7.x: http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652\r\n\r\n- fastai github Issues are only for bugs in the library. If you want to suggest a new feature please use https://forums.fast.ai/t/fastai-v1-adding-features/23041. If you're unsure whether your bug comes from your code or the library, please use the forums to discuss your code first, then file an issue if needed.\r\n-->\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\n input and target shapes do not match: input [48 x 5004], target [48] \r\nMy network output is of output channel 5004 depending on no of classes I have.My netowork has to multiclass classfication not binary so  I was expecting category list class to do single class hot encoding  like the way it happens for Multicategory list for each label in the target. \r\n\r\nI suspect this is a bug as one may not have just binary classes ,there can be multiclasses as well. \r\n\r\n**Provide your installation details**\r\n<!-- Copy-n-paste the output of `show_install`, by either running this cell in jupyter notebook:\r\n```\r\nfrom fastai.utils.show_install import *\r\nshow_install()\r\n```\r\nor via your shell:\r\n```\r\npython -m fastai.utils.show_install\r\n```\r\n-->\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. A gist to reproduce it is even better!-->\r\n<!-- If possible please add a new test for https://github.com/fastai/fastai/tree/master/tests/ that helps us reproduce the problem and will help with future regression testing. See https://docs.fast.ai/dev/test.html for details on how to run/write tests. -->\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help demonstrate your problem. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n",
	"issue_comments": "1"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "494871412",
	"issue_number": "2336",
	"issue_state": "closed",
	"issue_title": "Test set images end up in train and validation when valid_pct is used",
	"issue_body": "Steps to reproduce:\r\n1. Create a standard ImageNet folder structure:\r\n   ```\r\n   data/\r\n       train/\r\n           label_0/\r\n               img0.png\r\n               ...\r\n           label_1/\r\n               img0.png\r\n               ...\r\n       test/\r\n           img0.png\r\n           ...\r\n       labels.csv\r\n   ```\r\n   I used [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) and [mnist_to_imagenet_folders](https://www.kaggle.com/niladmirari/mnist-to-imagenet-folders).\r\n2. `ImageDataBunch.from_folder('data', valid_pct=0.2, test='test').classes` shows `['0', ... , '9', 'test']`.\r\n3. `ImageDataBunch.from_csv('data', valid_pct=0.2, test='test').classes` on the other hand works correctly and shows `[0, ..., 9]` only.",
	"issue_comments": "0"
},
{
	"login": "sgugger",
	"repo_name": "fastai/fastai",
	"issue_id": "349803135",
	"issue_number": "696",
	"issue_state": "closed",
	"issue_title": "Don't use import *",
	"issue_body": "This is a feature request, which is highly opinionated, but almost all python coding guidelines, recommends that all imports should be explicit, and that `from foo import *` should never be used. There are several reasons for this, including:\r\n\r\n* tractability - Where do I find the source code of a specific function?\r\n* function collisions - What if two modules declares a method with the same name?\r\n\r\nfastai makes heavily use of `import *` which makes the sources difficult to follow.",
	"issue_comments": "1"
}]