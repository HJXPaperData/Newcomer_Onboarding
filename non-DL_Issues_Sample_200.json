[{
	"login": "0polar",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "408456231",
	"issue_number": "1894",
	"issue_state": "opened",
	"issue_title": "Do not store `bad_files` & `hashfield` in `sites.json`",
	"issue_body": "Because these make `sites.json` too bloat, and slow down whole client.\r\nThere should be stored in `content.db` instead.",
	"issue_comments": "0"
},
{
	"login": "0polar",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "269497670",
	"issue_number": "1170",
	"issue_state": "opened",
	"issue_title": "Allow modals for iframe",
	"issue_body": "> http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Post/12h51ug6CcntU2aiBjhP8Ns2e5VypbWWtv/12gAes6NzDS9E2q6Q1UXrpUdbPS6nvuBPu/1509344044\r\n\r\n```\r\nIgnored call to 'confirm()'. The document is sandboxed, and the 'allow-modals' keyword is not set.\r\n```",
	"issue_comments": "0"
},
{
	"login": "abdulhannanali",
	"repo_name": "facebook/jest",
	"issue_id": "210916921",
	"issue_number": "3028",
	"issue_state": "opened",
	"issue_title": "Lint JavaScript in Markdown Files using eslint",
	"issue_body": "<!-- \r\nTHIS IS NOT A HELP FORUM. \r\nIf you are experiencing problems with setting up Jest, please make sure to visit our Help page: \r\nhttps://facebook.github.io/jest/help.html\r\n-->\r\n<!-- \r\nBefore creating an issue please check the following:\r\n* you are using the latest version of Jest\r\n* try re-installing your node_modules folder \r\n* run Jest once with `--no-cache` to see if that fixes the problem you are experiencing. \r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nFeature\r\n**What is the current behavior?**\r\nCurrently, the JavaScript code is not standardized at all, according to the JavaScript standards, which has lead to inconsistency in the docs. One such example, the use of semicolons and indentation is not consistent really. \r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and either a repl.it demo through https://repl.it/languages/jest or a minimal repository on GitHub that we can `yarn install` and `yarn test`.**\r\n\r\n**What is the expected behavior?**\r\n\r\nThe JavaScript examples should be manually checked for the standards either manually or using a tool. I would like to propose the usage of `eslint-plugin-markdown` to lint all the markdown files automatically and include this in the build step. \r\n\r\n**Please provide your exact Jest configuration and mention your Jest, node, yarn/npm version and operating system.**\r\n",
	"issue_comments": "0"
},
{
	"login": "edwardwang888",
	"repo_name": "apache/airflow",
	"issue_id": "944768653",
	"issue_number": "17005",
	"issue_state": "opened",
	"issue_title": "`retry_exponential_backoff` algorithm does not account for case when `retry_delay` is zero",
	"issue_body": "<!--\r\n\r\nWelcome to Apache Airflow!  For a smooth issue process, try to answer the following questions.\r\nDon't worry if they're not all applicable; just try to include what you can :-)\r\n\r\nIf you need to include code snippets or logs, please put them in fenced code\r\nblocks.  If they're super-long, please use the details tag like\r\n<details><summary>super-long log</summary> lots of stuff </details>\r\n\r\nPlease delete these comment blocks before submitting the issue.\r\n\r\n-->\r\n\r\n<!--\r\n\r\nIMPORTANT!!!\r\n\r\nPLEASE CHECK \"SIMILAR TO X EXISTING ISSUES\" OPTION IF VISIBLE\r\nNEXT TO \"SUBMIT NEW ISSUE\" BUTTON!!!\r\n\r\nPLEASE CHECK IF THIS ISSUE HAS BEEN REPORTED PREVIOUSLY USING SEARCH!!!\r\n\r\nPlease complete the next sections or the issue will be closed.\r\nThese questions are the first thing we need to know to understand the context.\r\n\r\n-->\r\n\r\n**Apache Airflow version**: 2.1.1\r\n\r\n\r\n**Kubernetes version (if you are using kubernetes)** (use `kubectl version`):\r\n\r\n**Environment**:\r\n\r\n- **Cloud provider or hardware configuration**:\r\n- **OS** (e.g. from /etc/os-release):\r\n- **Kernel** (e.g. `uname -a`):\r\n- **Install tools**:\r\n- **Others**:\r\n\r\n**What happened**:\r\nWhen `retry_exponential_backoff` is enabled and `retry_interval` is inadvertently set to zero, a divide by zero error occurs in the `modded_hash` calculation of the exponential backoff algorithm, causing the scheduler to crash indefinitely.\r\n\r\n<!-- (please include exact error messages if you can) -->\r\n\r\n**What you expected to happen**:\r\nScheduler should treat it as a task with `retry_delay` of zero.\r\n\r\n<!-- What do you think went wrong? -->\r\n\r\n**How to reproduce it**:\r\nCreate a task with `retry_delay=timedelta()` and `retry_exponential_backoff=True`.\r\n<!---\r\n\r\nAs minimally and precisely as possible. Keep in mind we do not have access to your cluster or dags.\r\n\r\nIf you are using kubernetes, please attempt to recreate the issue using minikube or kind.\r\n\r\n## Install minikube/kind\r\n\r\n- Minikube https://minikube.sigs.k8s.io/docs/start/\r\n- Kind https://kind.sigs.k8s.io/docs/user/quick-start/\r\n\r\nIf this is a UI bug, please provide a screenshot of the bug or a link to a youtube video of the bug in action\r\n\r\nYou can include images using the .md style of\r\n![alt text](http://url/to/img.png)\r\n\r\nTo record a screencast, mac users can use QuickTime and then create an unlisted youtube video with the resulting .mov file.\r\n\r\n--->\r\n\r\n\r\n**Anything else we need to know**:\r\nWilling to submit a PR; opened #17003 (WIP) with possible fix.\r\n\r\n<!--\r\n\r\nHow often does this problem occur? Once? Every time etc?\r\n\r\nAny relevant logs to include? Put them here in side a detail tag:\r\n<details><summary>x.log</summary> lots of stuff </details>\r\n\r\n-->\r\n",
	"issue_comments": "0"
},
{
	"login": "joyhchen",
	"repo_name": "zulip/zulip",
	"issue_id": "192114780",
	"issue_number": "2445",
	"issue_state": "opened",
	"issue_title": "Quality Assurance: Stream settings hidden menu overflow",
	"issue_body": "1. Minimize window to mobile width (365px)\r\n2. Press the hamburger menu icon to open list of streams\r\n3. Press the down chevron to the right of any stream's name\r\n\r\nThe stream settings that extend after pressing the down chevron should overflow and be hidden outside of the window's view as seen in the picture.\r\n\r\n![screenshot from 2016-11-27 18-13-44](https://cloud.githubusercontent.com/assets/7107181/20684655/91a3f796-b576-11e6-873f-a8108930e4ad.png)\r\n",
	"issue_comments": "0"
},
{
	"login": "MatrixManAtYrService",
	"repo_name": "apache/airflow",
	"issue_id": "878101866",
	"issue_number": "15708",
	"issue_state": "opened",
	"issue_title": "@task_group returns int, but it appears in @task as TaskGroup",
	"issue_body": "**Apache Airflow version**\r\n\r\n13faa6912f7cd927737a1dc15630d3bbaf2f5d4d\r\n\r\n**Environment**\r\n\r\n- **Configuration**: Local Executor\r\n- **OS** (e.g. from /etc/os-release): Mac OS 11.3\r\n- **Kernel** (e.g. `uname -a`): Darwin Kernel Version 20.4.0\r\n- **Install tools**: `pip install -e .`\r\n\r\n**The DAG**\r\n\r\n```python\r\n@task\r\ndef one():\r\n    return 1\r\n\r\n@task_group\r\ndef trivial_group(inval):\r\n\r\n    @task\r\n    def add_one(i):\r\n        return i + 1\r\n\r\n    outval = add_one(inval)\r\n    return outval\r\n\r\n@task\r\ndef print_it(inval):\r\n    print(inval)\r\n\r\n@dag(schedule_interval=None, start_date=days_ago(1), default_args={\"owner\": \"airflow\"})\r\ndef wrap():\r\n\r\n    x = one()\r\n    y = trivial_group(x)\r\n    z = print_it(y)\r\n\r\nwrap_dag = wrap()\r\n```\r\n\r\n**What happened**:\r\n`print_it` had no predecessors and received a `<airflow.utils.task_group.TaskGroup object at 0x128921940>`\r\n\r\n**What you expected to happen**:\r\n`print_it` comes after trivial_group.add_one and receives `2`\r\n\r\nThe caller ends up with the task group itself, equivalent in the traditional api to `tg_ref` in:\r\n```\r\nwith TaskGroup(\"trivial_group\") tg_ref:\r\n    pass\r\n````\r\n\r\nThis interrupts the ability to continue using the Task Flow api because passing it into a function annotated with `@task` fails to register the dependency with whatever magic gets it out of xcom and adds edges to the dag.",
	"issue_comments": "0"
},
{
	"login": "mitermayer",
	"repo_name": "facebook/jest",
	"issue_id": "163320443",
	"issue_number": "1236",
	"issue_state": "opened",
	"issue_title": "How to pass scriptPreprocessor throught the command line api ?",
	"issue_body": "How can we pass the path of a scriptPreprocessor throguh the cli ?",
	"issue_comments": "0"
},
{
	"login": "mvoitko",
	"repo_name": "apache/superset",
	"issue_id": "926719893",
	"issue_number": "15289",
	"issue_state": "opened",
	"issue_title": "AWS IAM policy with minimum set of permissions needed for Apache Superset to use Athena",
	"issue_body": "*Please make sure you are familiar with the SIP process documented*\r\n(here)[https://github.com/apache/superset/issues/5602]\r\n\r\n## [SIP] Proposal for XXX\r\n\r\n### Motivation\r\n\r\nIt is unclear which is the minimum set of permissions needed for Apache Superset to add Athena as a datasource.\r\n\r\n### Proposed Change\r\n\r\nThe example of the minumum IAM policy needed like https://github.com/dacort/metabase-athena-driver#example-iam-policy\r\n",
	"issue_comments": "0"
},
{
	"login": "Ood-Tsen",
	"repo_name": "google/ExoPlayer",
	"issue_id": "76239522",
	"issue_number": "458",
	"issue_state": "opened",
	"issue_title": "Do ExoPlayer support QUIC for youtube links ?",
	"issue_body": "When we test the YouTube dash example in demo app.\r\n>    new Sample(\"Google Glass\",\r\n        \"http://www.youtube.com/api/manifest/dash/id/bf5bb2419360daf1/source/youtube?\"\r\n        + \"as=fmp4_audio_clear,webm2_sd_hd_clear&sparams=ip,ipbits,expire,source,id,as&ip=0.0.0.0&\"\r\n        + \"ipbits=0&expire=19000000000&signature=249B04F79E984D7F86B4D8DB48AE6FAF41C17AB3.\"\r\n        + \"7B9F0EC0505E1566E59B8E488E9419F253DDF413&key=ik0\", DemoUtil.TYPE_DASH),\r\n\r\n\r\nI find the response header has including the \"Alternate-Protocol\" as following.\r\n\r\n> I/HttpDataSource(24744):  headers (Alternate-Protocol)[80:quic,p=0]\r\n\r\nDoes ExoPlayer will support [quic] (https://www.chromium.org/quic) or [spdy] (https://www.chromium.org/spdy/spdy-whitepaper) protocol in the future  ?\r\n",
	"issue_comments": "0"
},
{
	"login": "Ood-Tsen",
	"repo_name": "google/ExoPlayer",
	"issue_id": "62973128",
	"issue_number": "364",
	"issue_state": "opened",
	"issue_title": "SmoothStreaming doen't support format VC1 ",
	"issue_body": "ExoPlayer version 1.3.0 can't play this link \r\nhttp://playready.directtaps.net/smoothstreaming/TTLSS720VC1/To_The_Limit_720.ism/manifest .\r\n\r\nIt's video FOURCC is WMV1.\r\nthe audio FOURCE is WMAP.\r\n\r\nand the function fourCCToMimeType doesn't handle corresponding format.\r\n> SmothStreamingManifestParser.java\r\n>    private static String fourCCToMimeType(String fourCC) {\r\n> .....\r\n> }\r\n",
	"issue_comments": "0"
},
{
	"login": "Patrick0308",
	"repo_name": "pingcap/tidb",
	"issue_id": "657148556",
	"issue_number": "18584",
	"issue_state": "opened",
	"issue_title": "Run `make` command failed.",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n\r\nNow in master branch which's the last commit is  85679e9b4b1, run `make` command failed.\r\n\r\n### 2. What did you expect to see? (Required)\r\n\r\nmake success\r\n\r\n### 3. What did you see instead (Required)\r\n\r\nCGO_ENABLED=1 GO111MODULE=on go build  -tags codes  -ldflags '-X \"github.com/pingcap/parser/mysql.TiDBReleaseVersion=v4.0.0-beta.2-774-g85679e9b4-dirty\" -X \"github.com/pingcap/tidb/util/versioninfo.TiDBBuildTS=2020-07-15 07:54:04\" -X \"github.com/pingcap/tidb/util/versioninfo.TiDBGitHash=85679e9b4b1f4a36c492e4f9c6277dfe52493b06\" -X \"github.com/pingcap/tidb/util/versioninfo.TiDBGitBranch=master\" -X \"github.com/pingcap/tidb/util/versioninfo.TiDBEdition=Community\" ' -o bin/tidb-server tidb-server/main.go\r\ngo: github.com/ngaut/unistore@v0.0.0-20200630072006-0c4035925f69 requires\r\n        github.com/pingcap/tidb@v1.1.0-beta.0.20200604055950-efc1c154d098 requires\r\n        github.com/pingcap/br@v0.0.0-20200521085655-53201addd4ad requires\r\n        github.com/pingcap/tidb@v1.1.0-beta.0.20200509133407-a9dc72cf2558 requires\r\n        github.com/pingcap/pd/v4@v4.0.0-rc.1.0.20200422143320-428acd53eba2: invalid pseudo-version: revision 428acd53eba2 is not a descendent of preceding tag (v4.0.0-rc.1)\r\nmake: *** [server] Error 1\r\n\r\n### 4. Affected version (Required)\r\n\r\n<!-- v3.0.0, v4.0.0, etc -->\r\n\r\n### 5. Root Cause Analysis\r\n\r\n<!-- should be filled by the investigator before it's closed -->\r\n",
	"issue_comments": "0"
},
{
	"login": "RNHTTR",
	"repo_name": "apache/airflow",
	"issue_id": "800506600",
	"issue_number": "14051",
	"issue_state": "opened",
	"issue_title": "Docs Builder creates SpellingError for Sphinx error unrelated to spelling issues",
	"issue_body": "<!--\r\n\r\nWelcome to Apache Airflow!  For a smooth issue process, try to answer the following questions.\r\nDon't worry if they're not all applicable; just try to include what you can :-)\r\n\r\nIf you need to include code snippets or logs, please put them in fenced code\r\nblocks.  If they're super-long, please use the details tag like\r\n<details><summary>super-long log</summary> lots of stuff </details>\r\n\r\nPlease delete these comment blocks before submitting the issue.\r\n\r\n-->\r\n\r\n<!--\r\n\r\nIMPORTANT!!!\r\n\r\nPLEASE CHECK \"SIMILAR TO X EXISTING ISSUES\" OPTION IF VISIBLE\r\nNEXT TO \"SUBMIT NEW ISSUE\" BUTTON!!!\r\n\r\nPLEASE CHECK IF THIS ISSUE HAS BEEN REPORTED PREVIOUSLY USING SEARCH!!!\r\n\r\nPlease complete the next sections or the issue will be closed.\r\nThese questions are the first thing we need to know to understand the context.\r\n\r\n-->\r\n\r\n**Apache Airflow version**: 2.0.0\r\n\r\n\r\n**Kubernetes version (if you are using kubernetes)** (use `kubectl version`): n/a\r\n\r\n**Environment**: \r\n\r\n- **Cloud provider or hardware configuration**: n/a\r\n- **OS** (e.g. from /etc/os-release): n/a\r\n- **Kernel** (e.g. `uname -a`): n/a\r\n- **Install tools**: n/a\r\n- **Others**: n/a\r\n\r\n**What happened**:\r\nA sphinx warning unrelated to spelling issues running `sphinx-build` resulted in an instance of `SpellingError` to cause a docs build failure.\r\n\r\n```\r\nSpellingError(\r\n    file_path=None,\r\n    line_no=None,\r\n    spelling=None,\r\n    suggestion=None,\r\n    context_line=None,\r\n    message=(\r\n        f\"Sphinx spellcheck returned non-zero exit status: {completed_proc.returncode}.\"\r\n    )\r\n)\r\n\r\n# sphinx.errors.SphinxWarning: /opt/airflow/docs/apache-airflow-providers-google/_api/drive/index.rst:document isn't included in any toctree\r\n```\r\nThe actual issue was that I failed to include an `__init__.py` file in a directory that I created.\r\n\r\n<!-- (please include exact error messages if you can) -->\r\n\r\n**What you expected to happen**:\r\nI think an exception should be raised unrelated to a spelling error. Preferably one that would indicate that there's a directory that's missing an init file, but at least a generic error unrelated to spelling\r\n<!-- What do you think went wrong? -->\r\n\r\n**How to reproduce it**:\r\nCreate a new plugin directory (e.g. `airflow/providers/google/suite/sensors`) and don't include an `__init__.py` file, and run `./breeze build-docs -- --docs-only -v`\r\n<!---\r\n\r\nAs minimally and precisely as possible. Keep in mind we do not have access to your cluster or dags.\r\n\r\nIf you are using kubernetes, please attempt to recreate the issue using minikube or kind.\r\n\r\n## Install minikube/kind\r\n\r\n- Minikube https://minikube.sigs.k8s.io/docs/start/\r\n- Kind https://kind.sigs.k8s.io/docs/user/quick-start/\r\n\r\nIf this is a UI bug, please provide a screenshot of the bug or a link to a youtube video of the bug in action\r\n\r\nYou can include images using the .md style of\r\n![alt text](http://url/to/img.png)\r\n\r\nTo record a screencast, mac users can use QuickTime and then create an unlisted youtube video with the resulting .mov file.\r\n\r\n--->\r\n\r\n\r\n**Anything else we need to know**:\r\nI'm specifically referring to lines 139 to 150 in `docs/exts/docs_build/docs_builder.py`\r\n<!--\r\n\r\nHow often does this problem occur? Once? Every time etc?\r\n\r\nAny relevant logs to include? Put them here in side a detail tag:\r\n<details><summary>x.log</summary> lots of stuff </details>\r\n\r\n-->\r\n",
	"issue_comments": "0"
},
{
	"login": "trivikr",
	"repo_name": "facebook/jest",
	"issue_id": "253916785",
	"issue_number": "4390",
	"issue_state": "opened",
	"issue_title": "Improve documentation/error message when Jest config file is present in a different folder",
	"issue_body": "_From @trivikr on August 26, 2017 19:18_\n\n- Issue\r\nJest tests fail when Jest configuration file is present in a different folder. The `Validation Error` is not very helpful to understand that *--rootDir* has to be passed when Jest configuration file is read from some place other than workplace root\r\n\r\n- Expected behavior\r\nImprove the error description so that user knows that *--rootDir* has to be passed when Jest configuration file is read from some place other than workplace root\r\n\r\n- Link to a minimal repo that reproduces this issue\r\n[ts-jest-external-config-repro](https://github.com/trivikr/ts-jest-external-config-repro/)\n\n_Copied from original issue: kulshekhar/ts-jest#301_",
	"issue_comments": "0"
},
{
	"login": "wolfier",
	"repo_name": "apache/airflow",
	"issue_id": "731005750",
	"issue_number": "11901",
	"issue_state": "opened",
	"issue_title": "DAGs remain in the UI after renaming the dag_id in the same python file",
	"issue_body": "<!--\r\n\r\nWelcome to Apache Airflow!  For a smooth issue process, try to answer the following questions.\r\nDon't worry if they're not all applicable; just try to include what you can :-)\r\n\r\nIf you need to include code snippets or logs, please put them in fenced code\r\nblocks.  If they're super-long, please use the details tag like\r\n<details><summary>super-long log</summary> lots of stuff </details>\r\n\r\nPlease delete these comment blocks before submitting the issue.\r\n\r\n-->\r\n\r\n<!--\r\n\r\nIMPORTANT!!!\r\n\r\nPLEASE CHECK \"SIMILAR TO X EXISTING ISSUES\" OPTION IF VISIBLE\r\nNEXT TO \"SUBMIT NEW ISSUE\" BUTTON!!!\r\n\r\nPLEASE CHECK IF THIS ISSUE HAS BEEN REPORTED PREVIOUSLY USING SEARCH!!!\r\n\r\nPlease complete the next sections or the issue will be closed.\r\nThese questions are the first thing we need to know to understand the context.\r\n\r\n-->\r\n\r\n**Apache Airflow version**: 1.10.12\r\n\r\n**What happened**:\r\n\r\nWhen I rename the dag_id, the new dag_id shows up in the UI but the old dag_id does not disappear and remains in the UI. \r\n\r\n<!-- (please include exact error messages if you can) -->\r\n\r\n**What you expected to happen**:\r\n\r\n<!-- What do you think went wrong? -->\r\n\r\nWhen Airflow [lists out the python files](https://github.com/apache/airflow/blob/1.10.12/airflow/utils/file.py#L105-L161) and tries to [deactivate the deleted dags during dag processing](https://github.com/apache/airflow/blob/1.10.12/airflow/utils/dag_processing.py#L951-L955), the old DAG's file location is still in the list of the alive DAG location because the new DAG is now defined in the old DAG's python file. Even when you manually set is_active to False in the metastore, the dag processing process will set it back to True.\r\n\r\nThis happens whether or not DAG serialization is enabled.\r\n\r\n**How to reproduce it**:\r\n<!---\r\n\r\nAs minimally and precisely as possible. Keep in mind we do not have access to your cluster or dags.\r\n\r\nIf you are using kubernetes, please attempt to recreate the issue using minikube or kind.\r\n\r\n## Install minikube/kind\r\n\r\n- Minikube https://minikube.sigs.k8s.io/docs/start/\r\n- Kind https://kind.sigs.k8s.io/docs/user/quick-start/\r\n\r\nIf this is a UI bug, please provide a screenshot of the bug or a link to a youtube video of the bug in action\r\n\r\nYou can include images using the .md style of\r\n![alt text](http://url/to/img.png)\r\n\r\nTo record a screencast, mac users can use QuickTime and then create an unlisted youtube video with the resulting .mov file.\r\n\r\n--->\r\n\r\nI was able to reproduce it by following these steps:\r\n1. Add a python file in the dags folder and initialize the DAG\r\n2. Verify the dag shows up in the UI\r\n3. Change the dag_id in the same file to something else\r\n4. Verify the new dag shows up in the UI\r\n5. Both the old DAG and the new DAG are visible on the UI as well as the metadata db.\r\n\r\n```\r\n\u279c  dags pwd\r\n/Users/alan/projects/astro/dags\r\n\u279c  dags ls\r\nwow.py\r\n```\r\n```python\r\nfrom datetime import datetime\r\n\r\nfrom airflow.models import DAG\r\n\r\n\r\ndag = DAG(\r\n    dag_id='yay',\r\n    schedule_interval='@once',\r\n    start_date=datetime(2020, 1, 1),\r\n    catchup=False\r\n)\r\n```\r\n\r\nIn the screenshot, both DAGs are marked as active but there only one DAG defined in `wow.py`.\r\n<img width=\"1502\" alt=\"Screen Shot 2020-10-27 at 6 31 40 PM\" src=\"https://user-images.githubusercontent.com/5952735/97380092-8cfb6480-1883-11eb-8315-1b386ffb00d8.png\">\r\n\r\n\r\n**Anything else we need to know**:\r\n\r\n<!--\r\n\r\nHow often does this problem occur? Once? Every time etc?\r\n\r\nAny relevant logs to include? Put them here in side a detail tag:\r\n<details><summary>x.log</summary> lots of stuff </details>\r\n\r\n-->\r\n",
	"issue_comments": "0"
},
{
	"login": "Yexiaoxing",
	"repo_name": "rclone/rclone",
	"issue_id": "503665434",
	"issue_number": "3601",
	"issue_state": "opened",
	"issue_title": "bug: rcserver not checking the existence of static files",
	"issue_body": "#### What is the problem you are having with rclone?\r\n\r\nrclone is accepting `--rc` as a global config to enable the rcserver. However, it is not checking if the web GUI exists or not and trying to serve it directly. This will cause exception if the web gui is not here.\r\n\r\n\r\n#### What is your rclone version (output from `rclone version`)\r\n\r\nrclone v1.49.5\r\n- os/arch: darwin/amd64\r\n- go version: go1.12.10\r\n\r\n\r\n#### The command you were trying to run (eg `rclone copy /tmp remote:tmp`)\r\n\r\nMinimum reproductive: `rclone config --rc --rc-web-gui`\r\n\r\nExpected: Download the web gui tarball and unzip it\r\n\r\nException: shows 404 instead.\r\n\r\n\r\n#### Possible fix\r\n\r\nCheck if the GUI exists or not as `rclone gcd` does.\r\n\r\nPlease also refer to https://forum.rclone.org/t/beta-testing-webgui-for-rclone/11156/106 for a reproduction.",
	"issue_comments": "0"
},
{
	"login": "zhouqiang-cl",
	"repo_name": "pingcap/tidb",
	"issue_id": "442524161",
	"issue_number": "10413",
	"issue_state": "opened",
	"issue_title": "session unit test seems sometimes hang",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n1. What did you do?\r\nJust run ci\r\n\r\n\r\n2. What did you expect to see?\r\nci will finish in 3 minutes\r\n\r\n\r\n3. What did you see instead?\r\nCI takes 10 minutes and still not end\r\n```\r\nok  \tgithub.com/pingcap/tidb/planner/failtest\t0.803s\tcoverage: 0.0% of statements\r\n\r\nok  \tgithub.com/pingcap/tidb/planner/implementation\t0.095s\tcoverage: 50.0% of statements\r\n\r\nok  \tgithub.com/pingcap/tidb/planner/memo\t0.092s\tcoverage: 88.2% of statements\r\n\r\n?   \tgithub.com/pingcap/tidb/planner/property\t[no test files]\r\n\r\nok  \tgithub.com/pingcap/tidb/plugin\t0.078s\tcoverage: 2.8% of statements\r\n\r\nok  \tgithub.com/pingcap/tidb/plugin/conn_ip_example\t0.087s\tcoverage: 0.0% of statements [no tests to run]\r\n\r\n?   \tgithub.com/pingcap/tidb/privilege\t[no test files]\r\n\r\nok  \tgithub.com/pingcap/tidb/privilege/privileges\t8.163s\tcoverage: 83.2% of statements\r\n\r\nok  \tgithub.com/pingcap/tidb/server\t23.396s\tcoverage: 56.6% of statements\r\n\r\nSending interrupt signal to process\r\n\r\nKilling processes\r\n\r\nsh: line 1: 41415 Terminated              JENKINS_SERVER_COOKIE=$jsc '/bin/sh' -xe '/home/jenkins/workspace/tidb_ghpr_check_2/go/src/github.com/pingcap/tidb@tmp/durable-7da2c803/script.sh' > '/home/jenkins/workspace/tidb_ghpr_check_2/go/src/github.com/pingcap/tidb@tmp/durable-7da2c803/jenkins-log.txt' 2>&1\r\n\r\nkill finished with exit code 0\r\n\r\nmake: *** [gotest] Terminated\r\n\r\nscript returned exit code 143\r\n```\r\nNo more details, just ci's job in https://internal.pingcap.net/idc-jenkins/blue/organizations/jenkins/tidb_ghpr_check_2/detail/tidb_ghpr_check_2/883/pipeline/41\r\n\r\n4. What version of TiDB are you using (`tidb-server -V` or run `select tidb_version();` on TiDB)?\r\ntidb in https://github.com/pingcap/tidb/pull/10121\r\n",
	"issue_comments": "0"
},
{
	"login": "zhouqiang-cl",
	"repo_name": "pingcap/tidb",
	"issue_id": "416706529",
	"issue_number": "9540",
	"issue_state": "opened",
	"issue_title": "test sync jira",
	"issue_body": "## General Question\r\n\r\nBefore asking a question, make sure you have:\r\n\r\n- Searched existing Stack Overflow questions.\r\n- Googled your question.\r\n- Searched open and closed [GitHub issues](https://github.com/pingcap/tidb/issues?utf8=%E2%9C%93&q=is%3Aissue)\r\n- Read the documentation:\r\n  - [TiDB Readme](https://github.com/pingcap/tidb)\r\n  - [TiDB Doc](https://github.com/pingcap/docs)\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "zhouqiang-cl",
	"repo_name": "pingcap/tidb",
	"issue_id": "416706529",
	"issue_number": "9540",
	"issue_state": "closed",
	"issue_title": "test sync jira",
	"issue_body": "## General Question\r\n\r\nBefore asking a question, make sure you have:\r\n\r\n- Searched existing Stack Overflow questions.\r\n- Googled your question.\r\n- Searched open and closed [GitHub issues](https://github.com/pingcap/tidb/issues?utf8=%E2%9C%93&q=is%3Aissue)\r\n- Read the documentation:\r\n  - [TiDB Readme](https://github.com/pingcap/tidb)\r\n  - [TiDB Doc](https://github.com/pingcap/docs)\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "zhouqiang-cl",
	"repo_name": "pingcap/tidb",
	"issue_id": "457300730",
	"issue_number": "10831",
	"issue_state": "opened",
	"issue_title": "Is there any possible to define TxnEntrySizeLimit and innodb_log_file_size in config file",
	"issue_body": "## General Question\r\n\r\nWe use TiDB as  backend for jira/confluence.  which need set TxnEntrySizeLimit/innodb_log_file_size more large then default.\r\nNow we use `sed` to modify the two const value in tidb's code.\r\nIs there any possible to define TxnEntrySizeLimit and innodb_log_file_size in config file",
	"issue_comments": "0"
},
{
	"login": "dsinni",
	"repo_name": "aframevr/aframe",
	"issue_id": "316964017",
	"issue_number": "3551",
	"issue_state": "opened",
	"issue_title": "'material=\"visible: false;\"` is not ignored by raycaster when `raycaster=\"objects: ... ;\"` is defined",
	"issue_body": "**Description:**\r\n\r\nAccording to the A-Frame docs (https://aframe.io/docs/0.8.0/components/material.html#properties_visible), raycasters should ignore entities that have `material=\"visible: false;\"`. This doesn't seem to be the case when `raycaster=\"objects: ... ;\"` is defined. In this case, all qualifying objects are raycasted regardless of visibility.\r\n\r\nShould `material.visible` not still affect raycasting on these entities?\r\n\r\n- A-Frame Version: `0.7.*` - `0.8.*`\r\n- Reproducible Code Snippet or URL: https://codepen.io/dansinni/pen/deYXZa\r\n\r\n<!-- If you have a support question, please ask at https://stackoverflow.com/questions/ask/?tags=aframe rather than filing an issue. -->\r\n",
	"issue_comments": "0"
},
{
	"login": "dsinni",
	"repo_name": "aframevr/aframe",
	"issue_id": "316965525",
	"issue_number": "3552",
	"issue_state": "opened",
	"issue_title": "Raycaster ignores `visible=\"false\"` rather than 'material=\"visible: false;\"` when no raycaster objects are defined",
	"issue_body": "**Description:**\r\n\r\nAccording to the A-Frame docs (https://aframe.io/docs/0.8.0/components/material.html#properties_visible), raycasters should ignore entities with `material=\"visible: false;\"` rather than those with `visible=\"false\"`.\r\n\r\nIt appears that the opposite is happening.\r\n\r\n- A-Frame Version: `0.7.*` - `0.8.*`\r\n- Reproducible Code Snippet or URL: https://codepen.io/dansinni/pen/bMEKxQ\r\n\r\n<!-- If you have a support question, please ask at https://stackoverflow.com/questions/ask/?tags=aframe rather than filing an issue. -->\r\n",
	"issue_comments": "0"
},
{
	"login": "andelf",
	"repo_name": "pingcap/tidb",
	"issue_id": "201246402",
	"issue_number": "2492",
	"issue_state": "opened",
	"issue_title": "Feature request: json as log format",
	"issue_body": "We should support json as log format.\r\n\r\nrelated:\r\nhttps://github.com/pingcap/tikv/issues/1532",
	"issue_comments": "0"
},
{
	"login": "ankur0493",
	"repo_name": "rclone/rclone",
	"issue_id": "510571346",
	"issue_number": "3650",
	"issue_state": "opened",
	"issue_title": "RClone Counts Errors twice for Copy operations",
	"issue_body": "<!--\r\n\r\nWelcome :-) We understand you are having a problem with rclone; we want to help you with that!\r\n\r\nIf you've just got a question or aren't sure if you've found a bug then please use the rclone forum:\r\n\r\n    https://forum.rclone.org/\r\n\r\ninstead of filing an issue for a quick response.\r\n\r\nIf you think you might have found a bug, please can you try to replicate it with the latest beta?\r\n\r\n    https://beta.rclone.org/\r\n    \r\nIf you can still replicate it with the latest beta, then please fill in the info below which makes our lives much easier.  A log with -vv will make our day :-)\r\n\r\nThank you\r\n\r\nThe Rclone Developers\r\n\r\n-->\r\n\r\n#### What is the problem you are having with rclone?\r\nRClone counts errors twice for the copy operations\r\n\r\n\r\n#### What is your rclone version (output from `rclone version`)\r\nRClone 1.49.3\r\n\r\n\r\n#### Which OS you are using and how many bits (eg Windows 7, 64 bit)\r\nUbuntu 18.04 LTS, 64 but\r\n\r\n\r\n####  Which cloud storage system are you using? (eg Google Drive)\r\nDeveloping a new backend for RClone\r\n\r\n\r\n#### The command you were trying to run (eg `rclone copy /tmp remote:tmp`)\r\ncopy\r\n\r\n\r\n#### A log from the command with the `-vv` flag (eg output from `rclone -vv copy /tmp remote:tmp`)\r\n\r\n![image](https://user-images.githubusercontent.com/7876747/67278197-201df380-f4e6-11e9-9b2f-ca719b5dcbc0.png)\r\n\r\nThis happens because `fs.CountError(err)` is called once from within the `Copy()` function in `operations.go` and is then again called as part of `tr.Done(err)`. This results in the errors being counted twice. \r\n\r\nIt looks like `fs.CountError` is again being called once at the end of all files, though I couldn't trace from where it is called. For every error, the count is 2n+1.\r\n",
	"issue_comments": "0"
},
{
	"login": "blainekasten",
	"repo_name": "facebook/react",
	"issue_id": "57527424",
	"issue_number": "3131",
	"issue_state": "opened",
	"issue_title": "Abnormal workflow prevents onChange to be fired in IE 8",
	"issue_body": "I've included a test link:\r\n\r\nhttp://jsfiddle.net/53n8kgu3/10/\r\n\r\n(an alert should happen when you change a select item)\r\n\r\nEssentially, i'm letting my back end rendered DOM, drive what should be converted to React Components as I don't have the freedom to render on the back. But, when following this route, it works fine always except for in IE8, `onChange` events aren't fired.\r\n\r\nI think it may have something to do with the fact that i'm calling `React.createElement` with a component instance instead of a string. So if that is the case, it either should reject the component instance, or the events should trigger properly.",
	"issue_comments": "0"
},
{
	"login": "brigand",
	"repo_name": "facebook/react",
	"issue_id": "54016114",
	"issue_number": "2839",
	"issue_state": "opened",
	"issue_title": "Catch invalid dom nesting on initial render",
	"issue_body": "Currently, you get an error when react tries to update the DOM, and things aren't as expected.  Early errors are much better, so in development React should give clear errors based on valid HTML structures. \r\n\r\nFor example, the select element has 1 valid child: option.  The option element has 1 valid child: text node.  Forms have one invalid deep child: form; and tables have a quite a few rules.\r\n\r\nThe suggested error format:\r\n\r\n    InvariantViolation: at FooComponent <select> may only have <option> children, but encountered: option, option, select, option, option\r\n\r\nForms.  The element:N means displayName:childIndexIfNotZero.\r\n\r\n    InvariantViolation at FooComponent: <form> may not have any deep <form> children.  Culprit is form > div > form\r\n    InvariantViolation at FooComponent: <form> may not have any deep <form> children.  Culprit is form -> div > div:3 > section:2 > BarComponent > div > form:1\r\n\r\nTables\r\n\r\n    InvariantViolation at FooComponent: <table> may only have <caption>, <thead>, <tfoot>, and <tbody> children, but encountered thead, tr*100\r\n\r\n    InvariantViolation at FooComponent: <table> may only have one <thead> child, but encountered thead, thead, tr*100\r\n\r\n    InvariantViolation at FooComponent: <table> may only have one <thead> child, but encountered thead, thead, tr*100\r\n\r\nThe less frequently encountered situations can be pushed to a different release, but I think it's important to have.  These are bad habits that people are used to, because they're allowed in most other situations.\r\n\r\nThese are examples of people who have run into this problem.  \r\n\r\nselect/option\r\n\r\n - https://github.com/facebook/react/issues/2620 \r\n - http://stackoverflow.com/questions/27776780/react-js-invariant-violation-findcomponentroot\r\n\r\nnested forms:\r\n\r\n - https://github.com/facebook/react/pull/1987\r\n\r\ntables\r\n\r\n- http://stackoverflow.com/questions/21594009/removing-row-from-table-results-in-typeerror\r\n- http://stackoverflow.com/questions/26689900/react-js-invariant-violation-processupdates-when-rendering-a-table-with-a-di\r\n- http://stackoverflow.com/questions/26809950/reactjs-dynamically-hiding-and-showing-table-column-causes-invariant-violation\r\n- http://stackoverflow.com/questions/25026399/uncaught-error-invariant-violation-findcomponentroot-110-unable-to",
	"issue_comments": "0"
},
{
	"login": "cccs-jc",
	"repo_name": "apache/superset",
	"issue_id": "839126858",
	"issue_number": "13755",
	"issue_state": "opened",
	"issue_title": "Add free from \"tags\" field in the dataset + column model",
	"issue_body": "**Is your feature request related to a problem? Please describe.**\r\nSuperset can render dates using a data time pattern configured per column.\r\n\r\nWe would like to render other business types like IP, email etc. For example rendering a link to other web apps or formatting the data which is stored differently then how it is rendered. We are implementing a custom viz to do this. However we need a means to attach metadata information to the columns in the dataset model.\r\n\r\n**Describe the solution you'd like**\r\nWe would like to be able to \"tag\" columns with additional information. Perhaps something similar to the \"extra\" field found on the dataset but on a column basis and also available on the client side.\r\n\r\n**Describe alternatives you've considered**\r\nAt the moment we are using the type field of the column and setting it to IPv4, Domain, Email. However this field is probably not the best choice.\r\n\r\n\r\n<img width=\"99\" alt=\"column-metadata\" src=\"https://user-images.githubusercontent.com/56140112/112218891-afa76480-8bfa-11eb-941f-fc671ad45e2a.png\">\r\n",
	"issue_comments": "0"
},
{
	"login": "ClSlaid",
	"repo_name": "pingcap/tidb",
	"issue_id": "770240877",
	"issue_number": "21867",
	"issue_state": "opened",
	"issue_title": "Is anything wrong with tidb.util.codec?",
	"issue_body": "## General Question\r\n\r\n<!--\r\n\r\nBefore asking a question, make sure you have:\r\n\r\n- Searched existing Stack Overflow questions.\r\n- Googled your question.\r\n- Searched open and closed [GitHub issues](https://github.com/pingcap/tidb/issues?utf8=%E2%9C%93&q=is%3Aissue)\r\n- Read the documentation:\r\n  - [TiDB Readme](https://github.com/pingcap/tidb)\r\n  - [TiDB Doc](https://github.com/pingcap/docs)\r\n\r\n-->\r\nI've been trying out for `PingCAP`'s `talent-plan` path 1, project 1. However I encountered with a confusing problem this week.\r\n\r\nWhen trying to decode the prefix of the table I tried with function `func DecodeInt()` returning []byte, decoded_int, err from `github.com/tidb/util/codec`. According to the docs DecodeInt could be considered as an inverse function of `func EncodeInt()`. Infact the decoded_int is not equal to encode_int in some cases...\r\n\r\nThis problem should be able to generated by code below:\r\n\r\n```go\r\n// go version 1.15.6 on x86_64 windows\r\npackage main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\r\n\t\"github.com/pingcap/tidb/util/codec\"\r\n)\r\n\r\nfunc main() {\r\n\tkey := []byte{116, 128, 0, 0, 0, 0, 0, 0, 4, 95, 105}\r\n\tidxID := int64(5)\r\n\tfmt.Println(\"original key is:\", key)\r\n\tkey = codec.EncodeInt(key, idxID)\r\n\tfmt.Println(\"index is:\", idxID)\r\n\tfmt.Println(\"encoding...\")\r\n\tfmt.Println(key)\r\n\r\n\tfmt.Println(\"decoding...\")\r\n\tkey, idxID, err := codec.DecodeInt(key)\r\n\tif err != nil {\r\n\t\tfmt.Println(\"error: \", err)\r\n\t\treturn\r\n\t}\r\n\tfmt.Println(\"everything is fine right?\")\r\n\tfmt.Println(\"index is:\", idxID)\r\n\tfmt.Println(\"key is:\", key)\r\n\treturn\r\n\r\n}\r\n\r\n\r\n```\r\nMaybe it was all my bad to use those function improperly...\r\n\r\norz",
	"issue_comments": "0"
},
{
	"login": "dertuxmalwieder",
	"repo_name": "allinurl/goaccess",
	"issue_id": "849983881",
	"issue_number": "2075",
	"issue_state": "opened",
	"issue_title": "Non-GNU Linux systems are mislabeled as GNU+Linux recently",
	"issue_body": "In 2e15d8ef21edc5952ba6ba3ad321b5976a165861, several pull requests from @throwaway1037 were merged which included renaming \"Linux\" to \"GNU+Linux\". Now that would mean that all Linux systems which are detected are GNU systems instead of (e.g.) Busybox-based Linuces, like Tiny Core Linux and Alpine Linux.\r\n\r\nAs there is no safe way to detect these libc-related differences, the commit - in opposite to what it *should* have done - has made the OS detection **less** correct under some circumstances, because all Linux systems use the Linux kernel, but not all Linux systems use the GNU userland.\r\n\r\nI suggest to undo this part of the commit.",
	"issue_comments": "0"
},
{
	"login": "fcor",
	"repo_name": "aframevr/aframe",
	"issue_id": "294558961",
	"issue_number": "3377",
	"issue_state": "opened",
	"issue_title": "Embedded Scene with iframe not going fullscreen on mobile",
	"issue_body": "Hi,\r\nI'm trying to embbed a scene using iframe, it's working on desktop, but there is no fullscreen on mobile. I set width=\"100%\" height=\"100%\" allowfullscreen=\"yes\" allowvr=\"yes\" scrolling=\"no\" but still not working.\r\n\r\nDo I have to set some particular styles on top of this component in order to work on mobile? Thanks\r\n\r\nThis is a reproducible code snippet:\r\n\r\n```html\r\n<!DOCTYPE html>\r\n<html>\r\n  <head>\r\n    <meta charset=\"utf-8\">\r\n    <title>VR Scene</title>\r\n    <script src=\"https://aframe.io/releases/0.7.1/aframe.min.js\"></script>\r\n  </head>\r\n  <body>\r\n    <iframe title=\"VR\" src=\"https://killcloud.nyc3.digitaloceanspaces.com/Static-HTML/image.html\" width=\"100%\" height=\"100%\" allowfullscreen=\"yes\" allowvr=\"yes\" scrolling=\"no\">\r\n    </iframe>\r\n  </body>\r\n</html>\r\n`````",
	"issue_comments": "0"
},
{
	"login": "hailanwhu",
	"repo_name": "pingcap/tidb",
	"issue_id": "445270400",
	"issue_number": "10518",
	"issue_state": "opened",
	"issue_title": "Generate IndexMergePath for DNF filters",
	"issue_body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nIn order to access a table using multiple indexes, we first need to generate the possible access paths using multiple indexes. \r\n\r\n**Describe the feature you'd like:**\r\nAfter logical optimization, all constraints for a table are collected and we can combine these constraints with current accessible indexes to generate possible `IndexMergePath`.\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered.  #--> \r\n**Teachability, Documentation, Adoption, Migration Strategy:**\r\n<!-- If you can, explain some scenarios how users might use this, situations it would be helpful in. Any API designs, mockups, or diagrams are also helpful. -->",
	"issue_comments": "0"
},
{
	"login": "JaySon-Huang",
	"repo_name": "pingcap/tidb",
	"issue_id": "627091256",
	"issue_number": "17530",
	"issue_state": "opened",
	"issue_title": "Downcast column from int to tinyint is accepted by v4.0",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n\r\n```\r\nmysql> create table t2 (i int32);\r\nmysql> alter table t2 MODIFY COLUMN i tinyint;\r\nERROR 8200 (HY000): Unsupported modify column: length 4 is less than origin 11\r\nmysql> alter table t2 MODIFY COLUMN i tinyint(11);\r\nQuery OK, 0 rows affected (0.07 sec)\r\nmysql> show create table t2;\r\n+-------+----------------------------------------------------------------------------------------------------------------+\r\n| Table | Create Table                                                                                                   |\r\n+-------+----------------------------------------------------------------------------------------------------------------+\r\n| t2    | CREATE TABLE `t2` (\r\n  `i` tinyint(11) DEFAULT NULL\r\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin |\r\n+-------+----------------------------------------------------------------------------------------------------------------+\r\n```\r\n\r\n### 2. What did you expect to see? (Required)\r\n\r\nFor v4.0, we don't support downcast column type. `alter table t2 MODIFY COLUMN i tinyint(11);` and other similar ddl operations should be rejected.\r\n\r\n### 3. What did you see instead (Required)\r\n\r\nAlter from int to tiny int is accepted.\r\n\r\n### 4. Affected version (Required)\r\n\r\nv4.0.0\r\n\r\n### 5. Root Cause Analysis\r\n\r\n<!-- should be filled by the investigator before it's closed -->\r\n",
	"issue_comments": "0"
},
{
	"login": "kfarr",
	"repo_name": "aframevr/aframe",
	"issue_id": "202060181",
	"issue_number": "2299",
	"issue_state": "opened",
	"issue_title": "vive-controls component raising console errors for rotation and material of undefined",
	"issue_body": "**Description:**\r\nUpon scene init, vive-controls component raises `Uncaught TypeError: Cannot read property 'rotation' of undefined`. Upon button press, vive-controls raises `Uncaught TypeError: Cannot read property 'material' of undefined`\r\n\r\nQ are you using the built-in vive controller model?\r\nA yes no change\r\n\r\nQ do you inject controls / hands, or declare them a priori in your scene?  are tracked-controls there right off the bat (too early?) or does it wait for vive-controls or oculus-touch-controls to inject them?\r\nA vive controls injected\r\n\r\n- A-Frame Version: 0.4.0 (master 18-01-2017 commit #1b9bea1)\r\n- Platform / Device: Windows 10 / Chromium 2016-12-23 build / HTC Vive\r\n- Reproducible Code Snippet or URL: kfarr.github.io/aframe-city-builder",
	"issue_comments": "0"
},
{
	"login": "krzotr",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "428804030",
	"issue_number": "1955",
	"issue_state": "opened",
	"issue_title": "ZeroNet WEB interface has been blocked by \"Loaded json\" message",
	"issue_body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: **Current - 0.6.5 ba6a75f8d7c8d12**\r\n  * Operating system: **Centos 7**\r\n  * Web browser: **Chrome**\r\n  * Tor status: **available**\r\n  * Opened port: **yes**\r\n  * Special configuration: \r\n```\r\nmultiuser_local\r\n\r\noptional_limit = 1024\r\nfileserver_ip_type=ipv4\r\nlog_dir=/zeronet/log\r\ndata_dir=/zeronet/data\r\nfileserver_port=26552\r\nfileserver_ip=0.0.0.0\r\nuse_openssl=true\r\nui_ip=127.0.0.1\r\ndownload_optional=auto\r\nui_trans_proxy\r\nautodownload_bigfile_size_limit = 3900\r\nbigfile_size_limit = 5000\r\nworkers=10\r\nconnected_limit=20\r\nglobal_connected_limit=2048\r\n```\r\n\r\n### Step 2: Describe the problem:\r\n\r\nWeb interface is not working correctly. I checked logs and saw, the web interface has been blocked by `Loaded json: ` command.\r\n\r\n```[2019-04-03 14:21:58,394] DEBUG    Site:1uPLoa..dmQc Loaded json: 44923100 (latest: data/users/1QHVkerVSwMQF8LtzEb5XQSZxGeu9dRHmL/content.json)```\r\n\r\n#### Steps to reproduce:\r\n\r\nI use ZeroFrame API to download (should be \"to request\", because **fileNeed** does not download files instantly) all files from ZeroUP (1uPLoaDwKzP6MCGoVzw48r4pxawRBdmQc) - (commands **optionalFileList** and **fileNeed**, where i added to filename '|all' at the end. I made similar on YouTube and KopyKate BIG OFFICIAL.\r\n\r\n#### Observed Results:\r\n\r\nAfter restart ZeroNet (I changed configuration) web interface not working correctly. In logs, I saw: `Loaded json: X` messages\r\n\r\n```\r\n[2019-04-03 07:19:54,146] DEBUG    Site:1uPLoa..dmQc Loaded json: 100 (latest: data/users/15LYZz82LwdFA4tqWVgv3zJ8ZsWam784VV/content.json)\r\n[2019-04-03 07:19:54,569] DEBUG    Site:1uPLoa..dmQc Loaded json: 200 (latest: data/users/1CwbqLCD6TdkinNNNb4GneZxbsoJ6Mw6oE/content.json)\r\n[2019-04-03 07:19:56,393] DEBUG    Site:1uPLoa..dmQc Loaded json: 300 (latest: data/users/15LYZz82LwdFA4tqWVgv3zJ8ZsWam784VV/content.json)\r\n[2019-04-03 07:19:57,397] DEBUG    Site:1uPLoa..dmQc Loaded json: 400 (latest: data/users/1Mx5xcSVsv8mdsXtKwBPD8X1SEfzN2VR5u/content.json)\r\n```\r\n\r\nAfter a few hours, python has been killed - Out Of Memor\r\n\r\n```\r\n[2019-04-03 14:21:58,321] DEBUG    Site:1uPLoa..dmQc Loaded json: 44922800 (latest: data/users/1DiRWRFXcVgQQ75cXnAG2pyxxjGo2VaH5/content.json)\r\n[2019-04-03 14:21:58,346] DEBUG    Site:1uPLoa..dmQc Loaded json: 44922900 (latest: data/users/1Hfhfqq1dC9cPDrLHGmX5QYFYX3BmeGi6w/content.json)\r\n[2019-04-03 14:21:58,369] DEBUG    Site:1uPLoa..dmQc Loaded json: 44923000 (latest: data/users/1FZYhmAxsjUgUsDb3maysDUc9nRjfJNQm5/content.json)\r\n[2019-04-03 14:21:58,394] DEBUG    Site:1uPLoa..dmQc Loaded json: 44923100 (latest: data/users/1QHVkerVSwMQF8LtzEb5XQSZxGeu9dRHmL/content.json)\r\n[2019-04-03 14:21:58,416] DEBUG    Site:1uPLoa..dmQc Loaded json: 44923200 (latest: data/users/1L3kWGTi9tCFGLrt9EXGN55W1oNv7CU5Hj/content.json)\r\n[2019-04-03 14:21:58,443] DEBUG    Site:1uPLoa..dmQc Loaded json: 44923300 (latest: data/users/19QH9sZCo9RB6TA7648YQsX6rda7toiBnB/content.json)\r\n[2019-04-03 14:21:58,468] DEBUG    Site:1uPLoa..dmQc Loaded json: 44923400 (latest: data/users/12qJ8Wiyw72qWbKDnzg7qDGdL1fLUBzeXQ/content.json)\r\n```\r\n\r\nAs you can see, the application tries to load different **content.json** user files over **44922800** times. In a data directory, I have only **594** user directories.\r\n\r\n```\r\n# ls -la /zeronet/data/1uPLoaDwKzP6MCGoVzw48r4pxawRBdmQc/data/users/ | wc -l\r\n594\r\n```\r\n\r\n#### Expected Results:\r\n\r\nInitialization of ZeroNet should be very fast.\r\n\r\nWhy application check content.json user file many times? Should be some kind of cache to prevent load the same file several times.\r\n\r\nAt the moment I cannot get access to Web Interface of ZeroNet\r\n",
	"issue_comments": "0"
},
{
	"login": "millsjustin",
	"repo_name": "allinurl/goaccess",
	"issue_id": "294131246",
	"issue_number": "1004",
	"issue_state": "opened",
	"issue_title": "Inconsistent date range for the same logs",
	"issue_body": "When I run goaccess with ```date-spec date``` I get a date range of ```01/Jan/2018 \u2014 31/Jan/2018``` but when I run goaccess on the same logs with ```date-spec hr``` I get a date range of ```06/Jan/2018 \u2014 31/Jan/2018``` all other numbers in the report except ```Unique Visitors``` are the same.\r\n\r\nDo you have any idea what might be causing this problem?\r\n\r\nI'm running the latest version compiled from github just a few days ago.",
	"issue_comments": "0"
},
{
	"login": "PadmaB",
	"repo_name": "gardener/gardener",
	"issue_id": "422555362",
	"issue_number": "835",
	"issue_state": "opened",
	"issue_title": "Explore the various flags/options of API Server and its influence on the behavior  ",
	"issue_body": "",
	"issue_comments": "0"
},
{
	"login": "PadmaB",
	"repo_name": "gardener/gardener",
	"issue_id": "427515860",
	"issue_number": "885",
	"issue_state": "opened",
	"issue_title": "[Feature] Expose VPA recommendations as Prometheus metrics",
	"issue_body": "# Story\r\nAs an operator, I would like to expose the recommendations from VPA as prometheus metrics\r\n\r\n# Motivation\r\nRun the VPA in the \"Off\" mode and observe its recommendations for a certain period of time and compare with the actual resource usage before actually applying those recommendations.\r\nHowever, at the moment there is no way to expose the recommendations as prometheus metrics - will be convenient to have an exporter which does this job\r\n\r\n# Acceptance Criteria\r\n- [ ] To be able to view the recommendations from VPA as Prometheus Metrics and be able to create grafana dashboards for the same",
	"issue_comments": "0"
},
{
	"login": "pyon-yx",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "681887033",
	"issue_number": "20458",
	"issue_state": "opened",
	"issue_title": "Create Object Store Container and Object Store Object by using Openstack Swift provider.",
	"issue_body": "Hello!\r\nI have met an issue on using object storage.\r\nI have added OpenStack cloud provider in Compute->Clouds->Providers, as a result of that, I could find \"openstack cloud provider Cinder Manager\" in Storage->BlockStorage->Managers and \"openstack cloud provider Swift Manager\" in Storage->ObjectStorage->Managers.\r\nNow, block storage is working well.\r\nMy issue is related with object storage. When I move into Storage->Object Storage->Object Store Containers, \"Configuration\" button is always disabled, so that I can not add new object container.\r\n![object_storage_issue](https://user-images.githubusercontent.com/69880931/90647683-26e2d780-e26b-11ea-94a8-56314cdee537.png)\r\nWould you like to resolve this issue?\r\nThank you.",
	"issue_comments": "0"
},
{
	"login": "wojtekmaj",
	"repo_name": "facebook/react",
	"issue_id": "304413622",
	"issue_number": "12354",
	"issue_state": "opened",
	"issue_title": "[15.6.2setState callback does not fire",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\n\r\n**What is the current behavior?**\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\n\r\n**What is the expected behavior?**\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n",
	"issue_comments": "0"
},
{
	"login": "zsmatyas",
	"repo_name": "google/ExoPlayer",
	"issue_id": "278634258",
	"issue_number": "3534",
	"issue_state": "opened",
	"issue_title": "CEA608 - Padding might get into negative ranges",
	"issue_body": "The following line calculates the end padding of the Cue for positioning: \r\n\r\nhttps://github.com/google/ExoPlayer/blob/e7c60a2a234ab11bc75335453a7836fef9509610/library/core/src/main/java/com/google/android/exoplayer2/text/cea/Cea608Decoder.java#L727\r\n\r\nThe values are:\r\n`int endPadding = 32 - padding - StringLength. `\r\n\r\nIn unexpected cases (mostly caused by improper content) StringLength might be bigger than 32.\r\n\r\nThe problem is that some content - specifically beginnings of commercials in live channels - are missing the Preamble Address Code for the very first line (setting up the position where the line starts). So the first two lines are handled as one, incoming characters for both are added into a single StringBuilder, and will end up as a single Cue of possibly longer then 32 characters.\r\n\r\nThis line does not restrict the range, might result in a padding being negative if the character count is bigger than 32. Negative values will cause the SubtitlePainter have invalid ranges and will position the Subtitle completely incorrectly.\r\n\r\nThis is caused by incorrect content, but happens quite frequently. Could we add a simple check for negative values to correct this? Something like:\r\n`endPadding = Math.max(endPadding, 0); `\r\n\r\nThis would correct the calculations so all interim values will stay in the valid range. This does not fix the issue, the originally 2 lines of subtitles will be shown in a single line, but at least inside the visible screen area. \r\n",
	"issue_comments": "0"
},
{
	"login": "zsmatyas",
	"repo_name": "google/ExoPlayer",
	"issue_id": "153520017",
	"issue_number": "1506",
	"issue_state": "opened",
	"issue_title": "EOFException during playback of specific ogg file",
	"issue_body": "Ogg sample throws and exception. Might be a problem with the content, but I cannot tell the cause at the moment. Other ogg files play correctly.\r\n\r\n**CALLSTACK**\r\n```\r\n java.io.EOFException\r\nat com.google.android.exoplayer.extractor.ogg.OggUtil.populatePageHeader(OggUtil.java:108)\r\nat com.google.android.exoplayer.extractor.ogg.OggReader.readGranuleOfLastPage(OggReader.java:119)\r\nat com.google.android.exoplayer.extractor.ogg.OggVorbisExtractor.read(OggVorbisExtractor.java:118)\r\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractingLoadable.load(ExtractorSampleSource.java:836)\r\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:209)\r\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\r\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\r\nat java.lang.Thread.run(Thread.java:818)\r\n```\r\n\r\n**Repro steps:**\r\n- Add sample to Samples.java:\r\n\r\n`new Sample( \"Short ogg file\", \"http://www.w3schools.com/tags/horse.ogg\", Util.TYPE_OTHER),`\r\n- attempt to play it\r\n\r\n**Content:**\r\n`http://www.w3schools.com/tags/horse.ogg`\r\n**\r\nThe version of ExoPlayer being used:**\r\n```\r\n    android:versionCode=\"1507\"\r\n    android:versionName=\"1.5.7\"\r\n```\r\n\r\n- Reproduced on all android devices I have, like Nexus 5x, Nexus player.\r\n\r\n[bugreport.txt](https://github.com/google/ExoPlayer/files/252903/bugreport.txt)\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "zsmatyas",
	"repo_name": "google/ExoPlayer",
	"issue_id": "175646205",
	"issue_number": "1807",
	"issue_state": "opened",
	"issue_title": "EAI-708 support",
	"issue_body": "Previous version of the v1 and v2-dev branches had the entire SEI data put into a buffer and then read by the Eia608Parser. The parser had a check that the type and validity bits are set to channel 1 of the 608 content, and everything else was dropped. See: [V1](https://github.com/google/ExoPlayer/blob/release-v1/library/src/main/java/com/google/android/exoplayer/text/eia608/Eia608Parser.java#L141)\r\n`      if (ccType != 0) {\r\n        seiBuffer.skipBits(16);\r\n        continue;\r\n}`\r\nHere the ccType values mean:\r\n- 0 = channel 1 and 2 of EIA-608\r\n- 1 = channel 3 and 4 of EIA-608\r\n- 2 = Start of EIA-708 content (channel ID is defined inside the stream)\r\n- 3 = Chunk of EIA-708 content\r\n\r\nAs only value 0 was handled, and no additional checks were used to separate channel 1 and 2: a single 608 channel was supported. I added my additional channel and EIA-708 support by updating the Eia608Parser to collect the data instead of dropping it, so channel 3-4 and EIA-708 bits were collected and parsed appropriately. \r\n\r\nIn the latest v2 code, all these additional data are dropped at SeiReader level:\r\n[V2](https://github.com/google/ExoPlayer/blob/dev-v2/library/src/main/java/com/google/android/exoplayer2/extractor/ts/SeiReader.java#L65)\r\nlike:\r\n`\r\nif (ccValidityAndType != 0x04) {\r\n      seiBuffer.skipBytes(2);\r\n  }\r\n`\r\nThe change was: [Link](https://github.com/google/ExoPlayer/commit/a0c15957259384f3fd4a8c893324c50b2c3f1ab2)\r\n\r\nSeiReader seems to be the correct location to filter 608/708 and channel information, but needs serious changes in the architecture I had. Are you guys planning to ever support EIA-708 (as it is an FCC requirement from 2017)? Did you consider supporting the other channels of EIA-608? Any similar changes like the one you made in the v2-dev branch requires lots of changes to support all subtitles correctly, that is why I am interested in the plans about supported formats. \r\n\r\nAre you willing to accept pull requests related to these features or are you maybe already working on these issues?\r\n\r\nBig Thanks!",
	"issue_comments": "0"
},
{
	"login": "anoadragon453",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "240000726",
	"issue_number": "1004",
	"issue_state": "opened",
	"issue_title": "Strikethrough 'File transactions are not compressed' in README?",
	"issue_body": "With the ability to compress files with zip and 7zip now, should this line be removed or is compression not entirely implemented yet?",
	"issue_comments": "0"
},
{
	"login": "doniyor2109",
	"repo_name": "facebook/react",
	"issue_id": "388694203",
	"issue_number": "14402",
	"issue_state": "closed",
	"issue_title": "Disable react-devtools to track component tree",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\n\r\n*feature*\r\n\r\n**What is the current behavior?**\r\n\r\nI saw question on StackOverflow which is about user is able to edit component state and props which stores credentials  via `react-devtools` extension [secure-payment-with-paypal](https://stackoverflow.com/questions/53545118/secure-payment-with-paypal).\r\n\r\nCurrently any user who has `react-devtools` extension can edit Component props or state easily. I love this feature which is very handy for developing.\r\n\r\nI know that developer should not depend on only client side validation and should validate any credentials both client and server. \r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\n\r\n**What is the expected behavior?**\r\n\r\n I thought how about disabling `react-devtools` to tack component tree and editing components if user does not wants any changes in production. Maybe to pass some flag?\r\n\r\nSorry if it is silly issue \ud83d\ude48",
	"issue_comments": "0"
},
{
	"login": "eharris",
	"repo_name": "rclone/rclone",
	"issue_id": "529590211",
	"issue_number": "3769",
	"issue_state": "opened",
	"issue_title": "Improve crypt overlay standard filename encryption to handle longer names",
	"issue_body": "Using rclone v1.50.2-DEV, when using crypt overlay with \"standard\" filename encryption, the usable filename length limit seems to be 143 characters.  In my testing, a 143-char long original filename ends up as a 231-char long \"encrypted\" filename on a remote with a 255-char real filename length limit.  That's a 44% reduction in usable filename length (255 to 143), which seems quite excessive.\r\n\r\nIsn't there some more reasonable way to encode the filenames without so much space wasted on overhead?  For instance, I think a 20% loss to encoding overhead would be an absolute maximum limit, which would still allow for more than 200-chars of usable filename length compared to the current 143-char limit.  But even with an added 128bits of base64 encoded salt should only take up 22 chars, which should leave 233 chars of filename length usable.",
	"issue_comments": "0"
},
{
	"login": "excitement-engineer",
	"repo_name": "facebook/jest",
	"issue_id": "190315700",
	"issue_number": "2129",
	"issue_state": "opened",
	"issue_title": "Programatically fail a test",
	"issue_body": "In the jest docs it mentions an example in the async [tutorial](\r\n\r\n```js\r\n// Or try-catch.\r\nit('tests error with async/await', async () => {\r\n  try {\r\n    await user.getUserName(2);\r\n  } catch (object) {\r\n    expect(object.error).toEqual('User with 2 not found.');\r\n  }\r\n});\r\n```\r\n\r\nI think that this code should be written like this: \r\n\r\n```js\r\n// Or try-catch.\r\nit('tests error with async/await', async () => {\r\n  try {\r\n    await user.getUserName(2);\r\n    fail();\r\n  } catch (object) {\r\n    expect(object.error).toEqual('User with 2 not found.');\r\n  }\r\n});\r\n```\r\n\r\nThe `fail()` will prevent the test from passing if `getUserName()` does not throw an error. \r\n\r\nHowever, I see no mention of the `fail()` command anywhere in the docs, is this a supported API?",
	"issue_comments": "0"
},
{
	"login": "mjpieters",
	"repo_name": "apache/airflow",
	"issue_id": "688118673",
	"issue_number": "10629",
	"issue_state": "opened",
	"issue_title": "Several statsd timers record seconds rather than milliseconds",
	"issue_body": "**Apache Airflow version**: 1.10.11\r\n\r\n**What happened**:\r\n\r\nStatsd timers for 3 categories are reporting values 1000x off as the code passes seconds, rather rather than milliseconds (or a `timedelta()` instance) to [`StatsClient.timing()`](https://statsd.readthedocs.io/en/v3.3/reference.html#StatsClient.timing).\r\n\r\n**What you expected to happen**:\r\n\r\nThe timings should be reported in milliseconds.\r\n\r\n**How to reproduce it**:\r\n\r\nEnable the `statsd` client and track reporting timings for:\r\n\r\n* `dag.loading-duration.*` (emitted from `models/dagbag.py`)\r\n* `dag.<dag_id>.<task_id>.duration` (emitted from `models/taskinstance.py`)\r\n* `dag_processing.last_duration.<filename>` (emitted from `utils/dag_processing.py`) and it's deprecated alias `dag_processing.last_runtime.*`\r\n\r\n**Anything else we need to know**:\r\n\r\nThis was reported before, for the `dag_processing.last_*` stats, at https://issues.apache.org/jira/browse/AIRFLOW-6088.\r\nThe accompanying pull request #6682, fixed 2 out of 3 of these, but only for Airflow 2.0.\r\n",
	"issue_comments": "0"
},
{
	"login": "strifel",
	"repo_name": "zulip/zulip",
	"issue_id": "607044704",
	"issue_number": "14763",
	"issue_state": "opened",
	"issue_title": "Add support for BigBlueButton as Video Chat Provider",
	"issue_body": "It would be great to have Zulip support [Big Blue Button](https://bigbluebutton.org/) as a Video Chat Provider.\n\nFor the time beeing I worked around this by writing a Bot to generate a Link to Big Blue Button, but it would be really great to have it directly integrated.",
	"issue_comments": "0"
},
{
	"login": "ysc3839",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "188002358",
	"issue_number": "633",
	"issue_state": "opened",
	"issue_title": "Trayicon disappear after restart \"explorer.exe\"",
	"issue_body": "",
	"issue_comments": "0"
},
{
	"login": "cclauss",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "246737523",
	"issue_number": "1064",
	"issue_state": "opened",
	"issue_title": "Three undefined name errors",
	"issue_body": "https://travis-ci.org/HelloZeroNet/ZeroNet/builds/259342067#L655-L664",
	"issue_comments": "0"
},
{
	"login": "eldk",
	"repo_name": "facebook/fresco",
	"issue_id": "133945880",
	"issue_number": "995",
	"issue_state": "opened",
	"issue_title": "CacheStats return - 1 on app update",
	"issue_body": "Hello,\r\n\r\nI don't know if it's the same as https://github.com/facebook/fresco/issues/984 .\r\n\r\nWhen app is update (or suppressed and reinstalled: \r\n`mDiskCacheUsedSize = Fresco.getImagePipelineFactory().getMainDiskStorageCache().getSize();`\r\nreturn -1 thus all files are in cache.\r\n\r\nThis has been tested using : \r\n`.setBaseDirectoryPath(getExternalCacheDir())`\r\nor\r\n`.setBaseDirectoryPath(context.getApplicationContext().getCacheDir())`\r\nas diskCacheConfig\r\n\r\nThanks,\r\n\r\nEric",
	"issue_comments": "0"
},
{
	"login": "eldk",
	"repo_name": "facebook/fresco",
	"issue_id": "126892339",
	"issue_number": "917",
	"issue_state": "opened",
	"issue_title": "How to enable webp support in Fresco 0.9.0",
	"issue_body": "Hello,\r\n\r\nI've updated to Fresco 0.9.0.\r\nHow to enable webpSupport ?\r\n\r\nGreatings,\r\n\r\nEric",
	"issue_comments": "0"
},
{
	"login": "eldk",
	"repo_name": "facebook/fresco",
	"issue_id": "161031426",
	"issue_number": "1310",
	"issue_state": "reopened",
	"issue_title": ".setDownsampleEnabled(true) - Which Android versions are supported ?",
	"issue_body": "Hello,\r\n\r\nTesting Fresco with .setDownsampleEnabled(true) on one API 17 device, I don't have the downsample fresco logs (RequestLoggingListener).\r\n\r\nWith another device, that is API 10, files are well downsampled. I could see the RequestLoggingListener lines.\r\n\r\nThe API 10 device, with same Fresco settings (downsample and resize to same size) is fastest (about x2 to x4 ) to decode picture that the API 17 one.\r\n\r\nAPI 10 : \r\n`RequestLoggingListener: time 210302582: onProducerFinishWithSuccess: {requestId: 11, producer: DecodeProducer, elapsedTime: 273 ms, extraMap: {bitmapSize=1600x1067, queueTime=0, imageType=DEFAULT, isFinal=true, hasGoodQuality=true}}`\r\n\r\nAPI 17 : \r\n`RequestLoggingListener: time 89545018: onProducerFinishWithSuccess: {requestId: 52, producer: DecodeProducer, elapsedTime: 928 ms, extraMap: {bitmapSize=1600x1067, queueTime=2, imageType=DEFAULT, isFinal=true, hasGoodQuality=true}}`\r\n\r\nOn API 10, I can find the Downsample log line : \r\n`DownsampleUtil: Downsample - Specified size: 2048x2048, image size: 1600x1067 ratio: 1.3 x 1.9, ratio: 1.919 for http://domain.tl/picture.jpg`\r\n\r\nThus I can't in API 17.\r\n\r\nI have read this (http://frescolib.org/docs/configure-image-pipeline.html#_) and see downsample is experimental, but which Android version are supported, and which are not ?\r\n\r\nThis have been tested with fresco 0.10.0, 0.11.0.\r\nAll tested pictures are prefetch to disk and stored there before to be displayed.\r\n\r\nGreatings,\r\n\r\nEric",
	"issue_comments": "2"
},
{
	"login": "IanDBird",
	"repo_name": "google/ExoPlayer",
	"issue_id": "66881100",
	"issue_number": "386",
	"issue_state": "opened",
	"issue_title": "Unexpected delay in fetching manifests",
	"issue_body": "Branch: `dev`\r\nDevice: `Google Nexus Player`\r\n\r\nI'm looking into a delay when playing some videos, and it appears that it's caused by an extermely slow request to fetch the manifest. My initial thought was that the server was taking far too long to respond. However, after looking through the server logs, and using Curl to manually hit the server, it's taking roughly 200-300ms to respond which doesn't explain why the manifest fetcher is taking over 8 seconds. After adding in lots of logging, i've found the following code to be the cause of the 8 second delay (in `DefaultHttpDataSource`):\r\n\r\n```java\r\n    // Check for a valid response code.\r\n    int responseCode;\r\n    try {\r\n      Log.i(\"[IABI]\", \"getting response\");\r\n      responseCode = connection.getResponseCode();\r\n      Log.i(\"[IABI]\", \"got response\");\r\n    } catch (IOException e) {\r\n      throw new HttpDataSourceException(\"Unable to connect to \" + dataSpec.uri.toString(), e,\r\n          dataSpec);\r\n    }\r\n```\r\n\r\nThis seems to suggest that the network request is taking a long time to succeed. I hadn't noticed this issue on any other requests to the same server, so I decided to add my own AsyncTask which is executed on a separate scheduler to hit the server with the same URL. My own AsyncTask is completing the network request in 200-300ms, but the one used by the `DefaultHttpDataSource` continues to block.\r\n\r\nAny thoughts on what might be the cause of this? I initially considered that it might be some type of connection caching issue, but subsequently added in a random UUID into the URL to make sure it changed between requests. This unfortunately did not resolve the issue",
	"issue_comments": "0"
},
{
	"login": "mengxin9014",
	"repo_name": "pingcap/tidb",
	"issue_id": "937559008",
	"issue_number": "25986",
	"issue_state": "opened",
	"issue_title": "Unstable test testPessimisticSuite.TestAmendForUniqueIndex and testStatsSuite.TestAnalyzeGlobalStatsWithOpts2",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n```shell\r\n[2021-07-06T05:27:13.697Z] ----------------------------------------------------------------------\r\n[2021-07-06T05:27:13.697Z] FAIL: pessimistic_test.go:2212: testPessimisticSuite.TestAmendForUniqueIndex\r\n[2021-07-06T05:27:13.697Z] \r\n[2021-07-06T05:27:13.697Z] pessimistic_test.go:2276:\r\n[2021-07-06T05:27:13.697Z]     tk.MustExec(\"commit\")\r\n[2021-07-06T05:32:10.544Z] \r\n[2021-07-06T05:32:10.544Z] ----------------------------------------------------------------------\r\n[2021-07-06T05:32:10.544Z] FAIL: handle_test.go:938: testStatsSuite.TestAnalyzeGlobalStatsWithOpts2\r\n[2021-07-06T05:32:10.544Z] \r\n[2021-07-06T05:32:10.544Z] handle_test.go:949:\r\n```\r\n\r\n### 1. Minimal reproduce step (Required)\r\nin ci https://ci.pingcap.net/blue/organizations/jenkins/tidb_ghpr_check_2/detail/tidb_ghpr_check_2/14699/pipeline\r\n\r\n<!-- a step by step guide for reproducing the bug. -->\r\n\r\n### 2. What did you expect to see? (Required)\r\n\r\n### 3. What did you see instead (Required)\r\n\r\n### 4. What is your TiDB version? (Required)\r\n\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360328",
	"issue_number": "38",
	"issue_state": "closed",
	"issue_title": "Investigate Vault Integration with Kubernetes",
	"issue_body": "**Issue by [vasu1124](https://github.com/vasu1124)**\n_Wednesday Sep 20, 2017 at 12:29 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/110_\n\n----\n\nVault 0.8.3 now supports Kubernetes integration via the TokenReview API.\r\nhttps://www.vaultproject.io/docs/auth/kubernetes.html\r\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360211",
	"issue_number": "15",
	"issue_state": "closed",
	"issue_title": "Broken Node Detection & Retirement",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\n_Wednesday Jul 19, 2017 at 18:44 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/29_\n\n----\n\n# Story\n* As operator I want broken nodes to be removed automatically, so that nothing gets scheduled there anymore, the existing workload is drained/moved, the nodes dont count into my budget (in general/financially and also into the auto-scaler).\n\n# Motivation\nCost saving, business continuity, depending on the reason for the retirement also security.\n\n# Acceptance Criteria\n- [ ] Nodes are retired if:\n  - [ ] Kubelet fails to call home\n  - [ ] Kubelet indicates health issues\n  - [ ] Ephemeral disk is full\n- [ ] Retirement means (cordoning; actually implicit with next step), draining, and finally terminating the VM so that a new one can be recreated by the scaling group\n\n# Implementation Proposal\nSee e.g. [KUBE-70](https://jtrack.removed/browse/KUBE-70).\n\n# Definition of Done\n\n- [ ] Knowledge is distributed: Have you spread your knowledge in pair programming/code review?\n- [ ] Unit Tests are provided: Have you written automated unit tests or added manual NGPTT tickets?\n- [ ] Integration Tests are provided: Have you written automated integration tests?\n- [ ] Minimum API exposure: If you have added public API, was it really necessary/is it minimal?\n- [ ] Operations guide: Have you updated the [operations guide](https://git.infra.removed/kubernetes/kube-docs/wiki/Operations%20Guide)?\n\n:information_source: Migrated from Jira issue [KUBE-236](https://jtrack.removed/browse/KUBE-236)\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360256",
	"issue_number": "25",
	"issue_state": "closed",
	"issue_title": "Kubelet as Pod",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\n_Wednesday Jul 19, 2017 at 18:45 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/43_\n\n----\n\n# Acceptance Criteria\n- [ ] Bootstrap/deploy the kubelet as pod if possible, so that it can be conveniently updated\n\n(!) Beware if kubelet is run in a docker container: Volume attachment does not work/needs a lot of time (works with --containerized)\n\n:information_source: Migrated from Jira issue [KUBE-159](https://jtrack.removed/browse/KUBE-159)\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360175",
	"issue_number": "9",
	"issue_state": "reopened",
	"issue_title": "Provision via ACS",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\n_Wednesday Jul 19, 2017 at 18:44 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/16_\n\n----\n\n# Stories\n* As provider I want to provision Kubernetes via ACS, so that we dont have to provision Kubernetes ourselves on Azure (when SAP or customers need to run it side-by-side) and benefit from a probably more competitive solution than whatever we can do (in terms of full management and pricing).\n\n# Motivation\nDo not engage in Kubernetes provisioning when there are competitive native solutions, especially when customers already run on that infrastructure and use/manage/operate the same native solutions.\n\n# Acceptance Criteria\n- [ ] ACS Kubernetes cluster can be created via the Gardener and offers about the same functionality as what we have on AWS (to be clarified)\n\n:information_source: Migrated from Jira issue [KUBE-83](https://jtrack.removed/browse/KUBE-83)\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360242",
	"issue_number": "20",
	"issue_state": "closed",
	"issue_title": "Investigate EFK Stack",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\n_Wednesday Jul 19, 2017 at 18:44 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/34_\n\n----\n\nPlease check out the EFK Stack (Elasticsearch + fluentd + Kibana; see various blogs, e.g. https://logz.io/blog/kubernetes-log-analysis). Is it what we should use? If so, how can it be integrated into the seed & shoot cluster approach. Please report results here.\n\n:information_source: Migrated from Jira issue [KUBE-98](https://jtrack.removed/browse/KUBE-98)\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "314495023",
	"issue_number": "129",
	"issue_state": "opened",
	"issue_title": "Delete failed",
	"issue_body": "I created a couple of clusters for testing and deleted them. I did not use the programmatic interface and I did not fiddle around with the IaaS resources or opened the console, but I got this error (`canary`: `core`/`vlerencaw9`):\r\n\r\n```\r\nDelete Processing\r\nCurrently executing (CloudBotanist).DestroyInfrastructure\r\nLast Error\r\nOperation failed as there are dependent objects on cloud provider level\r\nFailed to delete Shoot cluster: Errors occurred during flow execution: '(CloudBotanist).DestroyInfrastructure' returned 'Terraform execution job 'vlerencaw9.infra.tf-job' could not be completed. The following issues have been found in the logs:\r\n\r\n-> Pod 'vlerencaw9.infra.tf-job-zpldk' reported:\r\n* aws_vpc.vpc (destroy): 1 error(s) occurred:\r\n* aws_vpc.vpc: DependencyViolation: The vpc 'vpc-3264fd59' has dependencies and cannot be deleted.\r\n\tstatus code: 400, request id: <omitted>'\r\n```",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360221",
	"issue_number": "17",
	"issue_state": "closed",
	"issue_title": "ETCD Backup & Restore",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\n_Wednesday Jul 19, 2017 at 18:44 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/31_\n\n----\n\n# Story\r\n* As provider I want etcd backups for my shoot clusters, so that I can restore them should they be lost.\r\n* Later: As provider I want etcd backups to be restored automatically should the PV be definitely lost or the current etcd can't start from the current state.   \r\n\r\n# Motivation\r\nBusiness continuity.\r\n\r\n# Acceptance Criteria\r\n- [x] Regular etcd backups are taken by the garden operator for all shoot clusters and are made known to the Gardener UI via TPRs/CRDs\r\n  - [x] AWS\r\n  - [x] Azure\r\n  - [ ] GCP\r\n  - [ ] OpenStack\r\n\r\n# Resources\r\n* Take a look at the [CoreOS etcd operator](https://github.com/coreos/etcd-operator) if you can\r\n* Maybe [Heptio Ark](https://blog.heptio.com/announcing-two-new-heptio-open-source-projects-heptio-ark-and-heptio-sonobuoy-7cef88a06f8) (disaster recovery) may be interesting to check out\r\n* See also https://github.com/coreos/etcd/blob/master/Documentation/op-guide/recovery.md#restoring-a-cluster\r\n\r\n# Open Questions\r\nHow frequent can we backup the data? Can we replicate the data on a lower level with a sidecar deployment or would we need an etcd cluster then? Is there something like point in time recovery for etcd?\r\n\r\n# Definition of Done\r\n- [ ] Knowledge is distributed: Have you spread your knowledge in pair programming/code review?\r\n- [ ] Unit Tests are provided: Have you written automated unit tests or added manual NGPTT tickets?\r\n- [ ] Integration Tests are provided: Have you written automated integration tests?\r\n- [ ] Minimum API exposure: If you have added public API, was it really necessary/is it minimal?\r\n- [ ] Operations guide: Have you updated the [operations guide](https://git.infra.removed/kubernetes/kube-docs/wiki/Operations%20Guide)?\r\n\r\n:information_source: Migrated from Jira issue [KUBE-158](https://jtrack.removed/browse/KUBE-158)\r\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360163",
	"issue_number": "2",
	"issue_state": "closed",
	"issue_title": "Internal Monitoring",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\r\n_Wednesday Jul 19, 2017 at 18:43 GMT_\r\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/8_\r\n\r\n----\r\n\r\n# Stories\r\n* As operator I want internal monitoring, so that I can check on my cluster(s).\r\n* As operator I want alerts on issues available in internal monitoring, so that I dont have to check on my cluster(s) manually all the time.\r\n\r\n# Motivation\r\nWe need means to monitor our own cluster(s).\r\n\r\n# Acceptance Criteria\r\n- [x] All key metrics are exposed to admins in a remotely accessible UI\r\n  - [x] Number of nodes, pods, containers, services (running, failing)\r\n  - [x] Corresponding infrastructure components\r\n  - [x] Cluster load, free memory, free disk space\r\n  - [x] Key data is put onto a dashboard\r\n- [x] Historic data is kept for the past two weeks\r\n- [x] When we reach certain thresholds, alerts are sent to pre-configured e-mail address(es)\r\n\r\n:information_source: Migrated from Jira issue [KUBE-21](https://jtrack.removed/browse/KUBE-21)\r\n\r\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "296485836",
	"issue_number": "82",
	"issue_state": "reopened",
	"issue_title": "Guard against illegal cloud profile modifications",
	"issue_body": "As discussed in #14 @rfranzke noted that we should prohibit illegal cloud profile modifications, e.g. dropping a Kubernetes version or machine type while a shoot cluster still uses it. So let's write a small admission controller that prevents that in general (droppings/modifications) or that prevents that only from happening if there are clusters still using it (otherwise allows it).",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "298283630",
	"issue_number": "87",
	"issue_state": "opened",
	"issue_title": "Canary Update - Halt On Update Issues",
	"issue_body": "# Stories\r\n* As user I want the latest version with all security patches and bug fixes, so that my cluster is safe and sound.\r\n* As provider I can update the OS, so that I can deploy important security patches and bug fixes quickly.\r\n* As provider I can update Kubernetes and its components, so that I can deploy important security patches and bug fixes quickly.\r\n\r\n# Motivation\r\nSee above.\r\n\r\n# Acceptance Criteria\r\n- [x] Modification of shoot CRDs with a kubernetesVersion (e.g. v1.5), and an operatorVersion (that was used to create or last update the cluster, e.g. v1.35.0)\r\n- [x] Rolling update when:\r\n  - [x] OS version gets updated\r\n  - [x] Kubelet version (only for new Kubernetes minor versions, otherwise by updating the cloud-config secrets)\r\n- [x] Idempotent cluster update (Terraform & Control Plane) in all other cases (operator changes, Kubernetes patches, image or configuration changes)\r\n- [x] Support multiple shoot cluster Kubernetes versions\r\n- [ ] Run the update following a Canary process, i.e. first migrate one cluster and validate it, then migrate more clusters batch by batch (max-in-flight) or in customer-defined maintenance time window\r\n\r\n# Further Considerations\r\n* Kubernetes version upgrades (e.g. v1.5->v1.6) must be approved and scheduled by the end-user.\r\n* We agreed to postpone CoreOS Container Linux FastPatch updates (#37), because the nodes require a restart also with FastPatch and this isn't worth the effort on an IaaS platform where we can simply run a rolling-update of the nodes.\r\n\r\n# Definition of Done\r\n- [ ] Knowledge is distributed: Have you spread your knowledge in pair programming/code review?\r\n- [ ] Unit Tests are provided: Have you written automated unit tests or added manual NGPTT tickets?\r\n- [ ] Integration Tests are provided: Have you written automated integration tests?\r\n- [ ] Minimum API exposure: If you have added public API, was it really necessary/is it minimal?\r\n- [ ] Operations guide: Have you updated the [operations guide](https://github.wdf.sap.corp/kubernetes/kube-docs/wiki/Operations%20Guide)?\r\n",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "313244457",
	"issue_number": "127",
	"issue_state": "opened",
	"issue_title": "Consider Azure AZs",
	"issue_body": "We do not support AZs for Azure, but there seem to be some now: https://azure.microsoft.com/de-de/blog/introducing-azure-availability-zones-for-resiliency-and-high-availability/ -> https://azure.microsoft.com/en-us/global-infrastructure/availability-zones\r\nWhat are the advantages of those AZs and should we support them (?instead? of the update and fault domains)?",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360176",
	"issue_number": "10",
	"issue_state": "closed",
	"issue_title": "Investigate ACS",
	"issue_body": "**Issue by [kubernetes-jenkins](https://github.com/kubernetes-jenkins)**\n_Wednesday Jul 19, 2017 at 18:44 GMT_\n_Originally opened as https://git.removed/kubernetes-attic/garden-operator/issues/17_\n\n----\n\nCheck out https://azure.microsoft.com/services/container-service. What would be necessary to do in order to remotely provision/manage/operate/access those clusters (instead of our native ones on that IaaS) and what would be the limitations? Please report results here.\n\n:information_source: Migrated from Jira issue [KUBE-88](https://jtrack.removed/browse/KUBE-88)\n\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "297797274",
	"issue_number": "86",
	"issue_state": "opened",
	"issue_title": "Replace Terraform DNS with DNS Provider",
	"issue_body": "@mandelsoft has shown usage of the [DNS provider](https://github.com/kubernetes-incubator/external-dns) in our sister project [Kubify](https://github.com/gardener/kubify). Can we switch over to it for our DNS entries like the shoot API server? That would reduce the dependency to Terraform further, which we want to eliminate completely eventually (because of the poor error handling and other reasons).",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "319905912",
	"issue_number": "156",
	"issue_state": "opened",
	"issue_title": "Prometheus Ingress Resource on Wrong Port",
	"issue_body": "The Prometheus ingress resource uses port 8080, but should use port 80 instead (regression introduced after refactoring as it seems).",
	"issue_comments": "0"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "299600754",
	"issue_number": "92",
	"issue_state": "closed",
	"issue_title": "Issue with Scaling down the nodes",
	"issue_body": "Using Gardener, I have created a cluster on AWS with 5 worker groups with auto scaling limits set minimum as 5 and maximum as 10.\r\n**Observation1:**  I expect gardener to create a 25 Node Cluster but it created 20 node cluster(no errors from my AWS console regarding the quota limits).\r\n**Observation2:** Using kubectl, I have deleted 19 nodes out of 20 and the nodes got deleted successfully. So when I execute kubectl get nodes -- shows only one node.\r\nBut surprisingly when I look in to AWS EC2 console I still see that 20 Instances are still running. Shouldn't it delete all the un-needed VM's?\r\n**Observation3:** I need to cut down my AWS costs, so I have deleted all the un-needed 19 VM's from the EC2 console manually. But due to the auto scaling groups AWS again spawned up 20 more VM's. But surprisingly, when I now execute kubectl get nodes-- gives me 20 nodes back again.\r\nCould someone explain this behavior which is pretty odd. \r\n",
	"issue_comments": "1"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "317985635",
	"issue_number": "146",
	"issue_state": "closed",
	"issue_title": "Kube-proxy and Kube-dns were down during a scalability test ",
	"issue_body": "While doing a scalability test in Gardener, we checked  Gardener dashboard.\r\nKube-dns was down.\r\nKube-proxy was down.\r\n\r\n![image](https://user-images.githubusercontent.com/5903934/39302447-41904cac-4970-11e8-8a9c-5082fd42a044.png)\r\n\r\nWe are not sure why it is down in the cluster.",
	"issue_comments": "5"
},
{
	"login": "vlerenc",
	"repo_name": "gardener/gardener",
	"issue_id": "288360411",
	"issue_number": "57",
	"issue_state": "closed",
	"issue_title": "DNS intermittent delay",
	"issue_body": "By @swapnilgm: It seems like there is issue with kube-DNS. It sometimes takes time to setup DNS entry for services. \r\n\r\nIssue was first found with deployment of etcd backing shoot clusters.  Etcd while bootstrapping, tries to find peers in cluster using peer urls. We setup headless service for this peer URL's. But since sometimes, DNS resolution takes extra time, etcd runs through timeout and fails on bootstrap. \r\n\r\nWhile digging up I found this isn't etcd specific issue, and can occur with other deployments in future. There are already existing related issues on kubernetes porjects, as listed below,\r\nhttps://github.com/kubernetes/kubernetes/issues/56903\r\nhttps://github.com/kubernetes/kubernetes/issues/45976\r\n\r\n",
	"issue_comments": "1"
},
{
	"login": "Win-Man",
	"repo_name": "pingcap/tidb",
	"issue_id": "665014819",
	"issue_number": "18771",
	"issue_state": "opened",
	"issue_title": "Separate general log from tidb.log",
	"issue_body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\nTiDB will write general log in tidb.log when enabled general log. Suggest to separate general log from `tidb.log`. Because it's not easy to analysis general log when there are lots of error log in `tidb.log`.\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Teachability, Documentation, Adoption, Migration Strategy:**\r\n<!-- If you can, explain some scenarios how users might use this, situations it would be helpful in. Any API designs, mockups, or diagrams are also helpful. -->\r\n",
	"issue_comments": "0"
},
{
	"login": "yuqi1129",
	"repo_name": "pingcap/tidb",
	"issue_id": "893228306",
	"issue_number": "24690",
	"issue_state": "opened",
	"issue_title": "Optimize warning information when query table information_schema.cluster_config",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n\r\n<!-- a step by step guide for reproducing the bug. -->\r\n\r\nSet up a cluster with at least one tiflash server\r\n\r\n### 2. What did you expect to see? (Required)\r\n```\r\nautopilot@c3-youpin-merge-tidb01.bj(order_merge) > select * from information_schema.cluster_config where `key` = 'x';\r\nEmpty set, 2 warnings (0.01 sec)\r\n\r\nMon May 17 19:16:12 2021\r\nautopilot@c3-youpin-merge-tidb01.bj(order_merge) > show warnings;\r\n+---------+------+------------------------------------------------+\r\n| Level   | Code | Message                                        |\r\n+---------+------+------------------------------------------------+\r\n| Warning | 1105 | unknown node type: tiflash(10.142.129.11:3930) |\r\n| Warning | 1105 | unknown node type: tiflash(10.136.168.12:3930) |\r\n+---------+------+------------------------------------------------+\r\n2 rows in set (0.00 sec)\r\n```\r\nMon May 17 19:16:17 2021\r\n\r\n\r\n### 3. What did you see instead (Required)\r\n\r\nnode `tiflash` is a tiflash node, maybe the initial meanings was 'Can't get config from tiflash node', so we need to change the warnning infomationn like 'Currently we do not support get config from node ....'\r\n\r\n### 4. What is your TiDB version? (Required)\r\nmaster branch\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "abhigyank",
	"repo_name": "zulip/zulip",
	"issue_id": "297005713",
	"issue_number": "8377",
	"issue_state": "opened",
	"issue_title": "Avatar: Cannot upload same image after deleting ",
	"issue_body": "In `settings/your account`, after uploading a avatar, if you delete that avatar in the same settings popup, and upload new avatar with same file name, nothing happens, i.e. avatar isn't uploaded.\r\n\r\n**Steps to Reproduce**\r\nIn `settings/your account`:\r\nUpload an avatar with file name say, `pic.jpg`.\r\nWithout closing the settings, Delete avatar.\r\nNow again upload an avatar with same file name `pic.jpg` (can be a different picture with same name (same path)).\r\n\r\nBehavior: The avatar isn't uploaded.\r\nExpected behavior: The avatar should be uploaded.",
	"issue_comments": "0"
},
{
	"login": "bhavaniravi",
	"repo_name": "apache/airflow",
	"issue_id": "612356239",
	"issue_number": "8714",
	"issue_state": "opened",
	"issue_title": "Container level securityContext support for kubernetes",
	"issue_body": "**Description**\r\n\r\nKubernetesExecutor/KubernetesPodOperator supports `securityContext` for pods but I am working on a case where I want to set a `privileged` mode for base container.\r\n\r\n**Use case / motivation**\r\n\r\nMounting s3 to worker pods using s3fuse needs to run the base container in privileged mode\r\n",
	"issue_comments": "0"
},
{
	"login": "TerraTech",
	"repo_name": "allinurl/goaccess",
	"issue_id": "258720676",
	"issue_number": "886",
	"issue_state": "opened",
	"issue_title": "Relational diagrams for tcb storage",
	"issue_body": "@allinurl do you have any tcb relational storage diagrams that can be posted up, so I can see how they interrelate to one another?  In particular, how to identify all records associated with a particular date.  A graphviz dot file would be awesome but I'll take anything even if scribbled on the back of a napkin with magic ink.  :)\r\n\r\nThe project is trying to figure out how to prune out any entries that are older than 31 days.  The end goal is to inject a new log file at end of day and remove anything older than the set window.\r\n\r\nThe main reason is I'm working with some pretty big log files that are getting drug down to around ~200/s to ~900/s, with my peak speeds being around 5.7K/s.  I have all panels enabled FWIW.  One set of log files I'm working with, it cranks for a few days worth, then bogs down into heavy disk I/O which is most likely from heavy hash collisions on the referrers.  Even with the stock config, it will still bog down.\r\nhttps://github.com/TerraTech/goaccess/wiki/Performance\r\n\r\nIn conclusion:\r\n1) keep a current 31 day rolling window (non-compressed)\r\n2) ability to extract >31 days to a separate directory and store in tcb files for archival, most likely will store current year (stored on a btrfs compressed filesystem)\r\n\r\nOverall, I really like how goaccess represents the log file data visually, but I'm running into a brick wall on how to implement this with nightly processing on a massive scale that runs in a reasonable time for a large number of domains.  For those with small log files, it runs great (~5K/s - 6K/s) - but the larger log files, the processing time hits a major brick wall (<900/s) as the data accumulates and periodically stalls during processing by heavy disk I/O.  My nightly stats processing window, is roughly two hours and handles several gigabytes of gzip'd (-9) logs per server.",
	"issue_comments": "0"
},
{
	"login": "zhaoxugang",
	"repo_name": "pingcap/tidb",
	"issue_id": "761351342",
	"issue_number": "21653",
	"issue_state": "opened",
	"issue_title": "haven't track the memroy usage of PointGet/BatchPointGet",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n\r\n1.drop table if exists t1;\r\n2.create table t1(a int primary key);\r\n3.set tidb_mem_quota_query=1;\r\n4.select * from t1 where a = 1;\r\n5.select /*+ MEMORY_QUOTA(0 GB) */ * from t1 where a = 1;\r\n6.select /*+ MEMORY_QUOTA(1 GB) */ * from t1 where a = 1;\r\n\r\n### 2. What did you expect to see? (Required)\r\nafter step 4\r\nERROR 1105 (HY000): Out Of Memory Quota![conn_id=2199023255555]\r\nafter step 5 or 6\r\n+---+\r\n| a |\r\n+---+\r\n| 1 |\r\n+---+\r\n### 3. What did you see instead (Required)\r\nafter step 4\r\n+---+\r\n| a |\r\n+---+\r\n| 1 |\r\n+---+\r\nafter 5 or 6\r\n+---+\r\n| a |\r\n+---+\r\n| 1 |\r\n+---+\r\n### 4. What is your TiDB version? (Required)\r\nmaster branch\r\n| Release Version: None\r\nEdition: Community\r\nGit Commit Hash: None\r\nGit Branch: None\r\nUTC Build Time: None\r\nGoVersion: go1.14.4\r\nRace Enabled: false\r\nTiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n",
	"issue_comments": "0"
},
{
	"login": "dandv",
	"repo_name": "facebook/jest",
	"issue_id": "234399426",
	"issue_number": "3763",
	"issue_state": "opened",
	"issue_title": "Poor experience with the Discord channel",
	"issue_body": "As a new Jest user, I tried to chat with more experience users in the #jest channel, as advised in the [Join Community help section](http://facebook.github.io/jest/en/help.html). The experience was pretty poor:\r\n\r\n* I had no Discordapp account. After creating one (no OAuth? gah), I was invited to create a server (?)\r\n* After creating a server, I landed in an empty `#general` room\r\n* Clicked the [#jest](https://discordapp.com/channels/102860784329052160/103622435865104384) link again - no luck, place still seems empty\r\n\r\nBy comparison, Gitter is much, much better. Everyone can login with their GitHub credentials and land in actually functional web-based chat.",
	"issue_comments": "0"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "782485780",
	"issue_number": "12371",
	"issue_state": "opened",
	"issue_title": "[Explore]Data table pagination bar should be sticky to bottom on scroll",
	"issue_body": "5. Scrolling (both horizontally and vertically) moves the pagination bar\r\n    ![scrolling](https://user-images.githubusercontent.com/335541/104058817-2e1e6980-51a9-11eb-8d06-c4a1aff38f2e.gif)\r\n    which makes it almost unusable.\r\n\r\nNot sure how feasible it is, maybe it's worth looking into rendering this table with `DataTable` from the table viz plugin. It handles many rendering issues like 4 and 5. I had a plan to generalize that implementation, but didn't have time to finish. If someone can pick it up from where it was left, that would also be great.\r\n\r\n_Originally posted by @ktmud in https://github.com/apache/superset/issues/12257#issuecomment-756967446_\r\n\r\n\r\nconfirmed in master \r\n",
	"issue_comments": "0"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "781837262",
	"issue_number": "12346",
	"issue_state": "opened",
	"issue_title": "[Home] +DASHBOARD and +CHART button don't work",
	"issue_body": "![ezgif-4-6d28580b6945](https://user-images.githubusercontent.com/67837651/103974778-5feeec00-5127-11eb-817d-25091a996f01.gif)\r\n\r\nExpected behavior:\r\nwhen users click +DASHBOARD, it takes users to empty dashboard edit mode\r\nwhen users click +CHATR, it takes users to Create a new chart page\r\n\r\n![ezgif-4-e468e13b54d2](https://user-images.githubusercontent.com/67837651/103975023-03400100-5128-11eb-8c34-4a4d061a8b71.gif)\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "782489566",
	"issue_number": "12372",
	"issue_state": "opened",
	"issue_title": "[Explore]popover opens behind the Data section",
	"issue_body": "<img width=\"1790\" alt=\"Screen Shot 2021-01-08 at 5 57 28 PM\" src=\"https://user-images.githubusercontent.com/67837651/104080104-0811bd00-51db-11eb-8fbc-4c99143c7026.png\">\r\n<img width=\"1792\" alt=\"Screen Shot 2021-01-08 at 5 57 37 PM\" src=\"https://user-images.githubusercontent.com/67837651/104080106-09db8080-51db-11eb-8cd1-79381a2384cd.png\">\r\n\r\nTo reproduce:\r\n1. Open any charts \r\n2. Open Filter popover, see it opens behind the Data section \r\n\r\ncc : @kgabryje ",
	"issue_comments": "0"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "781318253",
	"issue_number": "12328",
	"issue_state": "closed",
	"issue_title": "[Explore]add Annotation layers dropdowns do not respond for click",
	"issue_body": "I cannot modify dropdown options for annotation layers (chart explore view)\r\n### Expected results\r\n\r\nDropdowns can be open.\r\n### Actual results\r\n\r\nDropdowns do not react on click.\r\n\r\n#### Screenshots\r\n\r\n\r\nhttps://user-images.githubusercontent.com/25153919/103898333-108fc800-50f5-11eb-92d5-2697cb2fd092.mov\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Launch application with: CYPRESS_CONFIG=true docker-compose up\r\n2. Go to chart ```Rise & Fall of Video Game Consoles```\r\n3. Click on Add annotation layer\r\n4. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\ncommit master f48284909dde84d13276bb40ddd91ec6935f10e5\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ x] I have reproduced the issue with at least the latest released version of superset.\r\n- [ x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\n",
	"issue_comments": "5"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "770304463",
	"issue_number": "12102",
	"issue_state": "closed",
	"issue_title": "[Explore]chart/data split view resizing height does not work properly ",
	"issue_body": "Expected behavior:\r\nwhen user resizes screen vertically, both Chart and Data section should adjust their height accordingly, making sure the data section is alway accessible to user despite the screen sizes. \r\n\r\nresizing from the bottom \u274c\r\n<img width=\"1572\" alt=\"Screen Shot 2020-12-17 at 11 16 57 AM\" src=\"https://user-images.githubusercontent.com/67837651/102532942-96ba7080-4059-11eb-8ab4-da5c23f22ea8.png\">\r\n<img width=\"1534\" alt=\"Screen Shot 2020-12-17 at 11 17 20 AM\" src=\"https://user-images.githubusercontent.com/67837651/102532950-991cca80-4059-11eb-8575-ca127fcb629b.png\">\r\nfrom the side \u2705\r\n<img width=\"718\" alt=\"Screen Shot 2020-12-17 at 11 17 40 AM\" src=\"https://user-images.githubusercontent.com/67837651/102533391-34ae3b00-405a-11eb-8ea9-273c3f832e48.png\">\r\nFrom the corner \u2705 side first then bottom\r\nFrom the corner \u274c bottom first then side\r\n<img width=\"1417\" alt=\"Screen Shot 2020-12-17 at 11 17 57 AM\" src=\"https://user-images.githubusercontent.com/67837651/102532957-9de17e80-4059-11eb-853a-c31085d524e5.png\">\r\n\r\n\r\n",
	"issue_comments": "3"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "781792942",
	"issue_number": "12345",
	"issue_state": "closed",
	"issue_title": "[Explore]make data panel search box sticky to top on scroll",
	"issue_body": "Committed enhancement: setting the search box sticky to top on scroll\r\n\r\nAlthough both sections(Metrics and Columns) of the Data panel display a maximum of 50 entries, they can easily exceed the height of a page. Once entries exceed page height, users need to scroll up and down the page to find the search box, which causes some inconvenience. \r\n\r\n![ezgif-6-87b22df12ca3](https://user-images.githubusercontent.com/67837651/103967045-f9150700-5115-11eb-8e9a-fa460b8d0dbc.gif)\r\n",
	"issue_comments": "1"
},
{
	"login": "junlincc",
	"repo_name": "apache/superset",
	"issue_id": "778551967",
	"issue_number": "12265",
	"issue_state": "closed",
	"issue_title": "[dashboard]CSS Templates not working",
	"issue_body": "A clear and concise description of what the bug is.\r\n\r\n### Expected results\r\n\r\nBlack background is preserved after refresh\r\n\r\n### Actual results\r\n\r\nBlack background missing after refresh\r\n\r\n#### Screenshots\r\n![dsvyXHvQ1B](https://user-images.githubusercontent.com/28984703/103603819-74c25880-4f4a-11eb-9e1d-46f867b82954.gif)\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Go to 'Any dashboard'\r\n2. Click on 'Edit dashboard > Edit CSS'\r\n3. Save CSS template\r\n4. Refresh browser\r\n5. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `0.38.0`\r\n- python version: `based on superset version 0.38.0`\r\n- node.js version: `based on superset version 0.38.0`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "1"
},
{
	"login": "kolbe",
	"repo_name": "pingcap/tidb",
	"issue_id": "286987407",
	"issue_number": "5592",
	"issue_state": "closed",
	"issue_title": "Some questions about using tidb-binlog tool",
	"issue_body": "Hi, we want to use tidb-binlog tool to subscribe to TiDB\u2019s incremental data but we still have some questions.\r\n1) Does this tool ensure data ordering? For example, T1 writes to TiServer1, and T2 writes to TiServer2, is it possible for Drain downstream to get T2->T1 which is not ordered? \r\n2) Will Kafka partition affect ordering? Since kafka only guarantees ordering in one partition.\r\n3) How to ensure data is no loss if pump crashes? \r\n\r\nPlease give me some introductions, Thanks.\r\n  ",
	"issue_comments": "2"
},
{
	"login": "palmerj3",
	"repo_name": "facebook/jest",
	"issue_id": "203107080",
	"issue_number": "2695",
	"issue_state": "opened",
	"issue_title": "Question: guidance on mocking local es6 modules",
	"issue_body": "I am having difficulty mocking a redux action on a local project and am looking for some guidance on how to proceed.\r\n\r\nHere is an example of the files in play here:\r\n\r\nactions/foo.js\r\n```javascript\r\nimport {\r\n  CONST1,\r\n  CONST2,\r\n  CONST3,\r\n} from '../somelib';\r\n\r\nexport const thing = {\r\n  'key': 'value'\r\n};\r\n\r\nexport const thingIWantToMock = (enabledState = 'Enabled') => (dispatch) => {\r\n  // Implementation\r\n}\r\n```\r\n\r\nactions/index.js\r\n```javascript\r\nexport * from './foo';\r\nexport * from './otherfoo';\r\nexport * from './otherfoo2';\r\nexport * from './otherfoo3';\r\n```\r\n\r\nSomewhere else I have a file that's actually consuming the es6 module I want to mock:\r\n```javascript\r\nimport { thingIWantToMock } from '../actions';\r\n```\r\n\r\nIn jest I feel like I've tried everything and I cannot mock \"thingIWantToMock\"..\r\n\r\nI have tried creating a files in actions/__mocks__/foo.js and actions/__mocks__/index.js and then using jest.mock('/path/to/actions/foo') or jest.mock('/path/to/actions') but that hasn't worked.\r\n\r\nMy most recent attempt was:\r\n```javascript\r\n    jest.setMock('path/to/actions', require('path/to/actions/__mocks__/index'));\r\n```\r\n\r\nIn all cases I cannot get my mock to be used when:\r\n```javascript\r\nimport { thingIWantToMock } from '../actions';\r\n```\r\n\r\nIs called.\r\n\r\nIs there any guidance here? Tutorials I could look at, documentation I could read, etc?\r\n\r\nThank you!",
	"issue_comments": "0"
},
{
	"login": "jbduncan",
	"repo_name": "google/guava",
	"issue_id": "138710773",
	"issue_number": "2411",
	"issue_state": "opened",
	"issue_title": "Feature Request: Tree inplementation in com.google.common.graph",
	"issue_body": "I'd like to request the addition of a [Tree](http://mathworld.wolfram.com/Tree.html) data structure, which would be similar to a `DirectedGraph` but which has a single root, disallows cycles and self-looping edges, and is fully connected.\r\n\r\nMy use case for such a feature would be to model a sequence of actions, which may branch depending on some criteria.\r\n\r\nI'm aware that such a data structure already exists in JUNG 2 (and this is probably the solution I'll use in the meantime), but I believe it would be something that users of the `com.google.common.graph` package, in a future stable version of Guava, would appreciate.",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "964414567",
	"issue_number": "16155",
	"issue_state": "opened",
	"issue_title": "[card view] card size shrink in dashboard list and chart list",
	"issue_body": "Card size shrink in dashboard list and chart list\r\n\r\n### Expected results\r\n\r\n<img width=\"1786\" alt=\"Screen Shot 2021-08-09 at 11 49 31 AM\" src=\"https://user-images.githubusercontent.com/81597121/128778343-881ec516-d996-4569-aaf6-13013ee61a05.png\">\r\n\r\n\r\n### Actual results\r\n\r\ncard size in dashboard list and chart list shrink to a shorter size\r\n\r\n#### Screenshots\r\n\r\ndashboard list \r\n<img width=\"1767\" alt=\"Screen Shot 2021-08-09 at 2 40 36 PM\" src=\"https://user-images.githubusercontent.com/81597121/128778158-fe7f9a73-42f3-4969-b783-d3b0fe7bf370.png\">\r\n\r\nchart list\r\n<img width=\"1783\" alt=\"Screen Shot 2021-08-09 at 2 40 21 PM\" src=\"https://user-images.githubusercontent.com/81597121/128778216-b1b8d295-ef8b-425d-a198-eada6cce9d98.png\">\r\n\r\n#### How to reproduce the bug\r\nThumbnail enable:\r\n\r\n1. Go to dashboard list or chart list\r\n2. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: latest master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "962487210",
	"issue_number": "16111",
	"issue_state": "opened",
	"issue_title": "[explore][cosmetic] popover is not stayed with the filed when scrolling up and down",
	"issue_body": "## Screenshot\r\nhttps://user-images.githubusercontent.com/81597121/128475346-99016c79-552a-4376-87fd-484041802d41.mov\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "945804688",
	"issue_number": "15726",
	"issue_state": "opened",
	"issue_title": "[dashboard edit] drag inner tab to outer tab in dashboard edit will show error message and dashboard crashed",
	"issue_body": "Drag inner tab to outer tab in dashboard edit will show error \r\n\r\n### Expected results\r\n\r\ninner tab component is not able to drag to outer tab and dashboard still good to continue edit\r\n\r\n### Actual results\r\n\r\ninner tab component is able to drag to outer tab and dashboard show error, user need to refresh to show dashboard\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/125865736-efdac496-1148-4ab1-a26a-a6d9dff585bc.mov\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Go to dashboard edit mode\r\n2. create outer tab\r\n3. create iner tab\r\n4. drag inter tab to outer tab, drop in the droppable space in outer tab (see a blue line)\r\n5. see error\r\n\r\n### Environment\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "928870502",
	"issue_number": "15348",
	"issue_state": "opened",
	"issue_title": "[cosmetic][dashboard] chart 3 dot menu is behind the chart title panel in chart maximize mode",
	"issue_body": "## Screenshot\r\n\r\n<img width=\"1792\" alt=\"Screen Shot 2021-06-23 at 10 45 23 PM\" src=\"https://user-images.githubusercontent.com/81597121/123209110-ffedc700-d474-11eb-91f1-16002273460a.png\">\r\n\r\n## Description\r\n\r\nchart 3 dot menu is behind the chart title panel in chart maximize mode\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "961536758",
	"issue_number": "16083",
	"issue_state": "opened",
	"issue_title": "[d&d][big number with trend line] Move Metric from 'METRIC' filed will lead to unexpected error",
	"issue_body": "when moving metric from the field,  'Run' button showed and after Run, show unexpected error message\r\n\r\n### Expected results\r\n\r\nno error when moving metric  and no Run button show\r\n\r\n### Actual results\r\n\r\nwhen moving metric from the field Run button showed and after Run, unexpected error showed\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/128310305-3cf873a1-6ab3-4495-8c86-9e47b5e8c36a.mov\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1.  Create a big number chart with trend line\r\n2. move the metric from the field a bit\r\n3. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: latest master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "858517822",
	"issue_number": "14158",
	"issue_state": "opened",
	"issue_title": "[dashboard] dashboard card view is not showing thumbnail in preset",
	"issue_body": "dashboard card view is not showing thumbnail in preset\r\n\r\n### Expected results\r\n\r\ndashboard card view will show thumbnail\r\n\r\n### Actual results\r\n\r\ndashboard card view is not showing thumbnail\r\n\r\n#### Screenshots\r\n\r\n<img width=\"1792\" alt=\"Screen Shot 2021-04-14 at 10 49 05 PM\" src=\"https://user-images.githubusercontent.com/81597121/114820541-00caf400-9d74-11eb-92c8-898c613a496d.png\">\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Go to 'Dashboards\r\n2. Click on card view icon on the left corner  of the tool bar\r\n\r\n### Environment\r\n\r\n- superset version:  preset 2021.15.0 Development\r\n\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [Y] I have reproduced the issue with at least the latest released version of superset.\r\n- [Y] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "944875102",
	"issue_number": "15697",
	"issue_state": "opened",
	"issue_title": "[annotation][time-series chart]",
	"issue_body": "Annotation on time-series chart will fail and show error message initially, then change chart type to line chart, the same annotation will show and then change back to time-series chat, annotation will show correctly \r\n\r\n### Expected results\r\n\r\nAnnotation will show correctly on time-series chart initially\r\n\r\n### Actual results\r\n\r\nAnnotation not show correctly on time-series chart initially\r\n\r\n#### Screenshots\r\n<img width=\"1792\" alt=\"Screen Shot 2021-07-13 at 11 06 19 PM\" src=\"https://user-images.githubusercontent.com/81597121/125706493-08d1f2f4-6a00-4cd3-b04d-8c4b36ba21d7.png\">\r\n\r\nhttps://user-images.githubusercontent.com/81597121/125705583-bc576a0d-fb80-46b0-8c98-5c0d848b47d4.mov\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Create an annotation with time range 2000-2004\r\n2. Open time-series chart (use cleaned_sales_data, metric: sum(sales)) and apply the annotation\r\n3. See error\r\n4. change the chart type to line chart and apply annotation again\r\n5. change the chart type to time series chart and apply annotation again\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "1007470961",
	"issue_number": "16846",
	"issue_state": "opened",
	"issue_title": "[dnd] reordering of multiple column/metrics is not working smoothly",
	"issue_body": " Reordering of multiple column/metrics is not working smoothly, some times can not drag a component to the desired order by dnd\r\n\r\n### Expected results\r\ncan drag component to desired position for ordering\r\n\r\n### Actual results\r\n\r\nsometimes can not drag component to desired position for ordering\r\n\r\n#### Screenshots\r\n\r\n\r\nhttps://user-images.githubusercontent.com/81597121/134820334-40d6a271-42f9-4f5d-80d2-540f4f8ec61b.mov\r\n\r\n\r\n#### How to reproduce the bug\r\nPrecondition: Turn on drag and drop\r\n1. Go to explore\r\n2. add multiple metric or add multiple column to filter\r\n3. reordering the metrics or columns by dnd\r\n4. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- browser type and version:\r\n- superset version: superset 1.3 RC2\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "910068421",
	"issue_number": "14961",
	"issue_state": "opened",
	"issue_title": "[dashboard] 'toggle to full screen' option in 3 dot menu do not turn dashboard to full screen",
	"issue_body": " 'toggle to full screen' option in 3 dot menu  do not turn dashboard to full screen\r\n\r\n### Expected results\r\n\r\nclick on 'toggle to full screen' will turn dashboard to full screen\r\n\r\n### Actual results\r\n\r\ndashboard stay the same\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/120584309-997d0800-c3e4-11eb-8ce9-fced16e92287.mov\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1. open a dashboard\r\n2. Click on 'toggle to full screen' option in 3 dot menu\r\n3. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "957960700",
	"issue_number": "16021",
	"issue_state": "opened",
	"issue_title": "[drag & drop][Tree chart] 'Metric' for Tree chart is not drag and droppable",
	"issue_body": "'Metric' for Tree chart is not drag and droppable when d&d enable.\r\n\r\n### Expected results\r\n\r\nMetrics for Tree chart is drag and droppable \r\n\r\n### Actual results\r\n\r\nMetrics for Tree chart is not drag and droppable \r\n\r\n#### Screenshots\r\n\r\n<img width=\"1791\" alt=\"Screen Shot 2021-08-02 at 2 40 44 AM\" src=\"https://user-images.githubusercontent.com/81597121/127840940-50e21496-7b16-4712-836d-cc55e6863c9a.png\">\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Select Tree chart in viz type\r\n2. go to 'Metric'\r\n3. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `lastest master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "1010590740",
	"issue_number": "16888",
	"issue_state": "opened",
	"issue_title": "[dashboard][filter indicator] time range filter box with 'no filter' will appear in applied filter in indicator",
	"issue_body": "time range in filter box with 'no filter' will appear in applied filter in indicator\r\n\r\n#### How to reproduce the bug\r\n\r\n1. go to video games sales dashboard\r\n2. create a time range native filter\r\n3. apply time range filter to all charts in the dashboard\r\n4. open indicator on the chart\r\n5. observe applied filter in indicator\r\n6. see error\r\n\r\n### Expected results\r\n\r\ntime range in filter box with 'no filter' should not be in applied filter section\r\n\r\n### Actual results\r\n\r\ntime range in filter box with 'no filter' is in applied filter section\r\n\r\n#### Screenshots\r\n\r\n<img width=\"1792\" alt=\"Screen Shot 2021-09-29 at 12 18 31 AM\" src=\"https://user-images.githubusercontent.com/81597121/135221938-1d491e51-f3e8-4a3a-bc58-c0f4b68b1503.png\">\r\n\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- browser type and version:\r\n- superset version: superset master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "928841659",
	"issue_number": "15345",
	"issue_state": "opened",
	"issue_title": "[explore][mixed time series chart] 'Sort by' function is not taking effect  ",
	"issue_body": " 'Sort by' function is not taking effect when sort by metrics is defined\r\n\r\n### Expected results\r\n\r\ndata will sort in order\r\n\r\n### Actual results\r\n\r\ndata is not sorted in order\r\n\r\n#### Screenshots\r\n\r\n<img width=\"1758\" alt=\"Screen Shot 2021-06-23 at 9 27 41 PM\" src=\"https://user-images.githubusercontent.com/81597121/123203743-aa60ec80-d46b-11eb-88d1-295fc43cf680.png\">\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1, use dataset 'clean_sales_data'\r\n2, select 'Mixed time series chart as view type\r\n3, for query A, select metrics 'Max(sales)'\r\n4, for query B, select metrics 'Min(sales)'\r\n5, select 'Max(sales') in 'Sort by'\r\n6, select SORT DESCENDING option\r\n7, create chart and observe Data panel\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "946011096",
	"issue_number": "15730",
	"issue_state": "opened",
	"issue_title": "[dashboard edit] when create new outer tab is not showing blank content",
	"issue_body": "Currently when creating new outer tab, it is not showing blank content under the tab, instead it show dashboard content from the 1st tab and looks like user need to drag the content into the tab (like the inter tab) which is not allow.\r\n\r\nhttps://user-images.githubusercontent.com/81597121/125907253-4ee50ace-abf4-4f66-a203-b3e65782f917.mov\r\n\r\n**Describe the solution you'd like**\r\nWhen create new tab should show blank in the content as a 'new' tab\r\n\r\n**Describe alternatives you've considered**\r\nOr have the same behavior when user create inter tab, user can drag charts into different tab\r\n\r\n**Additional context**\r\nI think it will be more preferred to show blank page when create outer tab, like open new a chrome tab \r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "1010497520",
	"issue_number": "16886",
	"issue_state": "opened",
	"issue_title": "[color theme] color theme 'D3 category 10' is duplicated in explore",
	"issue_body": " color theme 'D3 category 10' is duplicated in explore\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Go to explore\r\n2. Click on color theme\r\n3. See error\r\n\r\n### Expected results\r\ncolor theme is unique in the drop down menu\r\n\r\n### Actual results\r\n\r\nD3 category 10 is duplicated in color theme\r\n\r\n#### Screenshots\r\n\r\n<img width=\"321\" alt=\"Screen Shot 2021-09-28 at 10 13 34 PM\" src=\"https://user-images.githubusercontent.com/81597121/135207322-9e160945-4382-4811-9708-95f7225d9d2e.png\">\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- browser type and version:\r\n- superset version: superset master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "950123378",
	"issue_number": "15826",
	"issue_state": "opened",
	"issue_title": "[cosmetic][pivot table v2]",
	"issue_body": "Currently Pivot table chart border is styled in grey, pivot table v2 is styled in blue, can we make both table border in grey?\r\n\r\n## Screenshot\r\nPivot table\r\n<img width=\"1111\" alt=\"Screen Shot 2021-07-21 at 2 16 01 PM\" src=\"https://user-images.githubusercontent.com/81597121/126561821-2623687f-0373-4b9d-899c-4bffeaf77eff.png\">\r\n\r\nPivot table v2\r\n<img width=\"1117\" alt=\"Screen Shot 2021-07-21 at 2 16 20 PM\" src=\"https://user-images.githubusercontent.com/81597121/126561769-61352469-491a-4599-a7ae-3df70ef58730.png\">\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "973148343",
	"issue_number": "16305",
	"issue_state": "opened",
	"issue_title": "[sort by][time series bart chart v2]Sort by is not working for time series bar chart v2",
	"issue_body": "Sort by is not working for time series bar chart v2\r\n\r\n### Expected results\r\nWhen Sort DESCENDING is select, data is return in descending \r\n \r\n### Actual results\r\n\r\nWhen Sort DESCENDING is select, data is not \r\n\r\n\r\n#### Screenshots\r\n\r\n<img width=\"1785\" alt=\"Screen Shot 2021-08-17 at 4 54 04 PM\" src=\"https://user-images.githubusercontent.com/81597121/129815528-349a2027-ffbb-46bf-bf20-8b7cf65d3c71.png\">\r\n<img width=\"1787\" alt=\"Screen Shot 2021-08-17 at 4 54 14 PM\" src=\"https://user-images.githubusercontent.com/81597121/129815532-c32be1f2-9426-4228-ad0e-cb2c132d1bcd.png\">\r\nreturn in descending \r\n\r\n#### How to reproduce the bug\r\n\r\n1. create a time series bar  chart, select SORT BY and select Sort DESCENDING\r\n2. observe data panel\r\n3. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: lastest master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "890882217",
	"issue_number": "14612",
	"issue_state": "opened",
	"issue_title": "[cosmetic] 3 dot menu of the chart in dashboard dislocated",
	"issue_body": "## Screenshot\r\n<img width=\"576\" alt=\"Screen Shot 2021-05-11 at 8 24 31 PM\" src=\"https://user-images.githubusercontent.com/81597121/118106323-57871600-b392-11eb-8f1b-626931c205ec.png\">\r\n\r\n\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "944014418",
	"issue_number": "15673",
	"issue_state": "opened",
	"issue_title": "[dashboard] can not discard changes in a empty dashboard when create new dashboard through global + button or +dashboard button",
	"issue_body": "After create a new dashboard through through global + button or +dashboard button, click on 'DISCARD CHANGE' has no effect\r\n\r\n### Expected results\r\n\r\nclick on 'DISCARD CHANGE' will bring user out of dashboard edit mode\r\n\r\n### Actual results\r\n\r\nclick on 'DISCARD CHANGE' has no effect, user still at dashboard edit mode\r\n\r\n#### Screenshots\r\n\r\n\r\nhttps://user-images.githubusercontent.com/81597121/125559236-ebb18f6a-851f-4206-a88c-fde7ab410335.mov\r\n\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Click on global + button and create new dashboard or click on +dashboard in dashboard page\r\n2. Do not add anything to the new dashboard and click on 'DISCARD CHANGE' in dashboard edit mode\r\n3.See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "951779695",
	"issue_number": "15872",
	"issue_state": "opened",
	"issue_title": "[dashboard] 'Download as image' in chart 3 dot menu on dashboard did not work",
	"issue_body": "'Download as image' in chart 3 dot menu on dashboard did not work\r\n\r\n### Expected results\r\n\r\nChart can be downloaded as image when select\r\n\r\n### Actual results\r\nnothing is downloaded\r\n\r\n#### Screenshots\r\n\r\n<img width=\"1199\" alt=\"Screen Shot 2021-07-23 at 10 34 30 AM\" src=\"https://user-images.githubusercontent.com/81597121/126820243-a5f81aa2-b15b-4b91-bad2-0013f27a01de.png\">\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Go to  dashboard \r\n2. Open 3 dot menu of a chart on dashboard\r\n3. Select ''Download as image'\r\n4. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "950433239",
	"issue_number": "15834",
	"issue_state": "opened",
	"issue_title": "[dashboard edit] edit URL SLUG is not reflected right after change and click into the dashboard will lead to error",
	"issue_body": "Edit URL SLUG is not reflected right after change and click into the dashboard will lead to error. Dashboard URL did not update to the newly change until refresh\r\n\r\n### Expected results\r\n\r\nDashboard URL will reflect the change right after edit\r\n\r\n### Actual results\r\n\r\nDashboard URL did not reflect the change right after edit\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/126612119-f8f5ba3a-17db-4200-8e12-14c69018d937.mov\r\n\r\n\r\n\r\n#### How to reproduce the bug\r\nPrecondition: user set URL SLUG for a dashboard \r\n1. Go to dashboard edit\r\n2. edit URL SLUG, save change\r\n3. without refresh page, click the edited dashboard\r\n4. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "1005134799",
	"issue_number": "16808",
	"issue_state": "opened",
	"issue_title": "[native filter] datetime data in value filter is not readable in filter indicator",
	"issue_body": "Datetime data in value filter is not readable in filter indicator\r\n\r\n### Expected results\r\n\r\nDatetime data in value filter is readable in filter indicator\r\n\r\n### Actual results\r\n\r\nDatetime data in value filter is not readable in filter indicator\r\n\r\n#### Screenshots\r\n<img width=\"1789\" alt=\"Screen Shot 2021-09-23 at 1 05 50 AM\" src=\"https://user-images.githubusercontent.com/81597121/134473837-ab2201d0-b354-4759-9b0c-3ad597ad6dc6.png\">\r\n\r\n#### How to reproduce the bug\r\n\r\n1. create value filter with datatime column \r\n2. applied filter on charts\r\n3. open indicator and observe\r\n4. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- browser type and version:\r\n- superset version: master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "957808568",
	"issue_number": "16014",
	"issue_state": "opened",
	"issue_title": "[Drag & drop]Enable cross field drag and drop ",
	"issue_body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently in many charts, 'Filter' can accept drag and drop from cross field, but for some charts (histogram for example) do not support drag and drop from cross field. And 'Sort by' do not support cross field drag and drop also, these behavior are inconsistent and cause confusion for user. \r\n\r\n**Describe the solution you'd like**\r\nCan we enable cross field drag and drop for 'Filter' and 'Sort by' for all charts?\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "973301078",
	"issue_number": "16316",
	"issue_state": "opened",
	"issue_title": "[cosmetic][pivot table v2] missing table line of the last metric when apply metric on row",
	"issue_body": "## Description\r\nWhen apply metric on row, last metric is missing the bottom line of the table.\r\n\r\n## Screenshot\r\n<img width=\"1786\" alt=\"Screen Shot 2021-08-17 at 10 53 51 PM\" src=\"https://user-images.githubusercontent.com/81597121/129845372-eacc823c-6d35-4d1f-b876-4c069b99f5f5.png\">\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "956478895",
	"issue_number": "15968",
	"issue_state": "opened",
	"issue_title": "[Advanced Analytics][line chart]",
	"issue_body": "2nd time shift option is not shown on the chart, but tooltip show information\r\n\r\n### Expected results\r\n2nd time shift also shown on the chart and tooltip show correct value\r\n\r\n### Actual results\r\n\r\n2nd time shift not shown on the chart and tooltip show same value as 1st time shift\r\n\r\n#### Screenshots\r\n\r\n<img width=\"1792\" alt=\"Screen Shot 2021-07-29 at 7 55 19 PM\" src=\"https://user-images.githubusercontent.com/81597121/127616121-18a19d9a-b29b-4f03-8faa-aeb8535f3431.png\">\r\n\r\n#### How to reproduce the bug\r\n\r\n1. use 'cleaned_sales_data', create line chart with Sum(sales)\r\n2. in Advance Analytics, choose time shift \"1 year ago\" and \"1 year later\", and show actual value\r\n3. observe error on the chart\r\n\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master`\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "957781035",
	"issue_number": "16013",
	"issue_state": "opened",
	"issue_title": "[cosmetic][heatmap] information and instant effect icon too closed to the edge at DATA panel default size",
	"issue_body": "In heatmap, information and instant effect icons too closed to the edge at DATA panel default size, instant effect icon completely cut at default size.\r\n<img width=\"1788\" alt=\"Screen Shot 2021-08-01 at 10 58 15 PM\" src=\"https://user-images.githubusercontent.com/81597121/127811715-8f708112-f395-48c2-9a6a-8250101259b9.png\">\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "925118922",
	"issue_number": "15266",
	"issue_state": "opened",
	"issue_title": "[explore][radar chart]'Legend' title is duplicated in CUSTOMIZE panel",
	"issue_body": "## Screenshot\r\n\r\n<img width=\"1790\" alt=\"Screen Shot 2021-06-18 at 11 26 05 AM\" src=\"https://user-images.githubusercontent.com/81597121/122602806-4764f500-d028-11eb-8e3a-976fd7ac8cc8.png\">\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "1010507467",
	"issue_number": "16887",
	"issue_state": "opened",
	"issue_title": "[native filter] when user undo delete of a native filter, the options under column is gone",
	"issue_body": "For value filter, when user undo delete of a native filter, the options under column is gone, however if user go to another filter and come back, the options will appear again\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Create a value native filter\r\n2. Click on delete and then undo delete\r\n3. open dropdown menu for column\r\n4. See error\r\n\r\n### Expected results\r\n\r\nWhen user undo delete, the options in column dropdown list will not disappear\r\n\r\n### Actual results\r\n\r\nWhen user undo delete, the options in column dropdown list will disappear\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/135208961-d9acdead-f57a-4ae7-9283-82e613bf3486.mov\r\n\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- browser type and version:\r\n- superset version:  superset master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n- any feature flags active:\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "951756177",
	"issue_number": "15871",
	"issue_state": "opened",
	"issue_title": "[native filter] new time range filter initially show advance section then re-edit filer see advance section gone",
	"issue_body": "In preset 2021.29.0 dev, New time range filter initially show advance section then re-edit filer see advance section gone. Checked in superset master, also see advance section for time range filter, and this section stay when user re-edit time filter.\r\n\r\n### Expected results\r\nTime range filter do not have advance section\r\n\r\n### Actual results\r\n\r\nTime range filter have advance section initially, then edit the filter the advance section is gone\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/126816833-8e882f30-ac5c-4295-bd6b-d7b6156f9ca8.mov\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Create a time range filler\r\n2. Observe the Configuration\r\n3. Save time range filter and re-edit\r\n4. In Preset (2021.29.0 dev) the advance section is gone, for superset master, advance section still there\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: `master\r\n- python version: `python --version`\r\n- node.js version: `node -v`\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "904023187",
	"issue_number": "14879",
	"issue_state": "opened",
	"issue_title": "[cosmetic][filter box] columns overlap in filter configuration in filter box chart",
	"issue_body": "## Screenshot\r\n<img width=\"1792\" alt=\"Screen Shot 2021-05-26 at 4 11 51 PM\" src=\"https://user-images.githubusercontent.com/81597121/119871813-b04cc780-bed7-11eb-89a7-4a25a11f00fd.png\">\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "977267163",
	"issue_number": "16406",
	"issue_state": "opened",
	"issue_title": "[explore][save] user able to save chart when is not owner",
	"issue_body": "when user is not the owner of the chart, still able to save the change of that chart\r\n\r\n### Expected results\r\nuser CAN NOT  save the change of the chart when is not owner\r\n\r\n### Actual results\r\n\r\nuser can save the change of the chart when is not owner\r\n\r\n#### Screenshots\r\n\r\nhttps://user-images.githubusercontent.com/81597121/130492041-53801b29-7c35-42e3-8f4e-4ea31ca4f4b9.mov\r\n\r\n\r\n\r\n#### How to reproduce the bug\r\n\r\n1. Go to a chart that is not owner \r\n2. change chart type\r\n3. save the chart\r\n4. See error\r\n\r\n### Environment\r\n\r\n(please complete the following information):\r\n\r\n- superset version: master\r\n\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [ ] I have reproduced the issue with at least the latest released version of superset.\r\n- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "jinghua-qa",
	"repo_name": "apache/superset",
	"issue_id": "929640779",
	"issue_number": "15375",
	"issue_state": "opened",
	"issue_title": "[native filter] 'Clear All' for time range filter with required option will make red high light without error message ",
	"issue_body": "'Clear All' for time range filter with required option will make red high light without error message\r\n\r\n### Screenshot or Video\r\nhttps://user-images.githubusercontent.com/81597121/123336949-6a494a80-d4fb-11eb-99db-ba0746353875.mov\r\n\r\n### Repo steps\r\n1, create a time range filter with 'Required ' option selected\r\n2, go to the dashboard and click ' Clear All'\r\n3, observe the time range filter\r\n\r\n### Expected result\r\n'time range is required' error message showed when 'Clear All' of required time range filter\r\n\r\n### Actual result\r\n'Clear All' of required time range filter only make red highlight of the filter but not indicator the error\r\n\r\n### Environment\r\n\r\n\r\n- superset version: `master`\r\n\r\n\r\n### Checklist\r\n\r\nMake sure to follow these steps before submitting your issue - thank you!\r\n\r\n- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.\r\n- [x] I have reproduced the issue with at least the latest released version of superset.\r\n- [x] I have checked the issue tracker for the same issue and I haven't found one similar.\r\n\r\n### Additional context\r\n\r\nAdd any other context about the problem here.\r\n",
	"issue_comments": "0"
},
{
	"login": "overvenus",
	"repo_name": "pingcap/tidb",
	"issue_id": "145347292",
	"issue_number": "1046",
	"issue_state": "opened",
	"issue_title": "Incorrect cast date to int",
	"issue_body": "1. What version of Go are you using (`go version`)?\r\n\r\n `go version go1.5.3 linux/amd64`\r\n\r\n2. What operating system and processor architecture are you using (`go env`)?\r\n\r\n ```sh\r\n$ go env\r\nGOARCH=\"amd64\"\r\nGOBIN=\"\"\r\nGOEXE=\"\"\r\nGOHOSTARCH=\"amd64\"\r\nGOHOSTOS=\"linux\"\r\nGOOS=\"linux\"\r\nGOPATH=\"/home/neil/repo/gopath\"\r\nGORACE=\"\"\r\nGOROOT=\"/usr/local/go\"\r\nGOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\r\nGO15VENDOREXPERIMENT=\"\"\r\nCC=\"gcc\"\r\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0\"\r\nCXX=\"g++\"\r\nCGO_ENABLED=\"1\"\r\n\r\n$ tidb-server/tidb-server -h\r\nWelcome to the TiDB.\r\nVersion:\r\nGit Commit Hash: 8aa1055ceb3db20785957056375787be7cf73709\r\nUTC Build Time:  2016-04-02 07:26:11\r\n...\r\n```\r\n\r\n3. What did you do?\r\n\r\n ```\r\ntidb> select current_date, current_date+1;\r\n+--------------+----------------+\r\n| current_date | current_date+1 |\r\n+--------------+----------------+\r\n| 2016-04-02   | 20160402000001 |\r\n+--------------+----------------+\r\n1 row in set (0.00 sec)\r\n```\r\n\r\n4. What did you expect to see?\r\n\r\n ```\r\nmysql> select current_date, current_date+1;\r\n+--------------+----------------+\r\n| current_date | current_date+1 |\r\n+--------------+----------------+\r\n| 2016-04-02   |       20160403 |\r\n+--------------+----------------+\r\n1 row in set (0.00 sec)\r\n```\r\n\r\n5. What did you see instead?\r\n\r\n see Q.3",
	"issue_comments": "0"
},
{
	"login": "seanpoulter",
	"repo_name": "facebook/jest",
	"issue_id": "279452112",
	"issue_number": "5017",
	"issue_state": "closed",
	"issue_title": "Let stdin be passed through to jest-cli",
	"issue_body": "**Do you want to request a _feature_ or report a _bug_?** A feature\r\n\r\n**What is the current behavior?**\r\nWhen Jest runs in watch mode, `jest-cli` only listens for input from text terminals that send characters one at a time in \"raw mode\". This dependency on [`tty.ReadStream#setReadMode`](https://nodejs.org/docs/latest-v8.x/api/tty.html#tty_readstream_setrawmode_mode) in [`jest/packages/jest-cli/src/watch.js`](https://github.com/facebook/jest/blob/v21.2.1/packages/jest-cli/src/watch.js#L253) prevents anyone who's spawned Jest as a child process from interacting with the  watcher (e.g.: IDE extensions like `vscode-jest`).\r\n\r\n**What is the expected behaviour?**\r\nHow do you feel about using `setRawMode` when it's available, and letting whatever data through if a feature toggle is set (e.g.: a CLI arg or `process.env`)? Any thoughts on the feature toggle?\r\n\r\n**Suggested change**:\r\n_From_:\r\n```js\r\n  if (typeof stdin.setRawMode === 'function') {\r\n    stdin.setRawMode(true);\r\n    stdin.resume();\r\n    stdin.setEncoding('hex');\r\n    stdin.on('data', onKeypress);\r\n  }\r\n```\r\n\r\n_To_:\r\n```js\r\n  const useRawInput = typeof stdin.setRawMode === 'function';\r\n\r\n  if (useRawInput) {\r\n    stdin.setRawMode(true);\r\n  }\r\n  if (useRawInput || roughEdgeFeatureToggle) {\r\n    stdin.resume();\r\n    stdin.setEncoding('hex');\r\n    stdin.on('data', onKeypress);\r\n  }\r\n```\r\n\r\nOn my end it's the lowest overhead of:\r\n* using `stdin` that's piped in\r\n* kill/respawn Jest processes when things in the \"globalConfig\" change\r\n* refactor `watch.js` to extract the dependency on input method\r\n\r\nThanks!",
	"issue_comments": "2"
},
{
	"login": "dubzzz",
	"repo_name": "facebook/jest",
	"issue_id": "412144114",
	"issue_number": "7937",
	"issue_state": "opened",
	"issue_title": "`toStrictEqual` does not consider arrays with objects having undefined values correctly",
	"issue_body": "<!-- Love Jest? Please consider supporting our collective: \ud83d\udc49  https://opencollective.com/jest/donate -->\r\n\r\n## \ud83d\udca5 Regression Report\r\n\r\n`toStrictEqual` does not consider arrays with objects having undefined values correctly.\r\n\r\nStarting at 24.0.0, `[{a: undefined}]` is strict equal to `[{}]` - _while `{a: undefined}` and `{}` are not strict equal_.\r\n\r\n## Last working version\r\n\r\nWorked up to version: 23.6.0\r\n\r\nStopped working in version: 24.0.0\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```js\r\n// Fails starting at 24.0.0\r\nexpect([{a: undefined}]).not.toStrictEqual([{}]);\r\n\r\n// While the following is still true\r\nexpect({a: undefined}).not.toStrictEqual({});\r\n```\r\n\r\n## Expected behavior\r\n\r\nThe following assertion should not fail:\r\n\r\n```js\r\nexpect([{a: undefined}]).not.toStrictEqual([{}]);\r\n```\r\n\r\nIndeed `{a: undefined}` is not `{}`.\r\n\r\n## Run `npx envinfo --preset jest`\r\n\r\nPaste the results here:\r\n\r\n```bash\r\n$ npx envinfo --preset jest\r\nnpx : 1 install\u00e9(s) en 4.679s\r\n\r\n  System:\r\n    OS: Windows 10\r\n    CPU: (8) x64 Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\r\n  Binaries:\r\n    Node: 10.12.0 - C:\\Program Files\\nodejs\\node.EXE\r\n    Yarn: 1.10.1 - ~\\AppData\\Roaming\\npm\\yarn.CMD\r\n    npm: 6.7.0 - C:\\Program Files\\nodejs\\npm.CMD\r\n```\r\n",
	"issue_comments": "0"
},
{
	"login": "iosmanthus",
	"repo_name": "pingcap/tidb",
	"issue_id": "504470866",
	"issue_number": "12571",
	"issue_state": "opened",
	"issue_title": "bugs in `DATETIME` related session mode: `NO_ZERO_IN_DATE`",
	"issue_body": "## Bug Report\r\n\r\n1. What did you do?\r\nenable `NO_ZERO_IN_DATE` and insert `2019-10-00` produces no warning.\r\n\r\n\r\n`TiDB`:\r\n```sql\r\nmysql root@127.0.0.1:test> create table t (a DATETIME)                                                                                                             \r\nQuery OK, 0 rows affected\r\nTime: 0.010s\r\nmysql root@127.0.0.1:test> set sql_mode = 'NO_ZERO_IN_DATE'                                                                                                        \r\nQuery OK, 0 rows affected\r\nTime: 0.001s\r\nmysql root@127.0.0.1:test> insert into t values ('2019-0-1')                                                                                                       \r\nQuery OK, 1 row affected\r\nTime: 0.010s\r\nmysql root@127.0.0.1:test> show warnings                                                                                                                           \r\n+-------+------+---------+\r\n| Level | Code | Message |\r\n+-------+------+---------+\r\n```\r\n\r\n\r\n\r\n2. What did you expect to see?\r\n`MySQL`:\r\n```sql\r\nmysql iosmanthus@(none):test> set sql_mode = 'NO_ZERO_IN_DATE'                   \r\nQuery OK, 0 rows affected\r\nTime: 0.001s\r\nmysql iosmanthus@(none):test> create table t (a DATETIME)                        \r\nQuery OK, 0 rows affected\r\nTime: 0.037s\r\nmysql iosmanthus@(none):test> insert into t values ('2019-0-1')                  \r\nQuery OK, 1 row affected\r\nTime: 0.011s\r\nmysql iosmanthus@(none):test> show warnings                                      \r\n1 row in set\r\nTime: 0.023s\r\nmysql iosmanthus@(none):test> show warnings                                                                                                   \r\n+---------+------+----------------------------------------+\r\n| Level   | Code | Message                                |\r\n+---------+------+----------------------------------------+\r\n| Warning | 1265 | Data truncated for column 'a' at row 1 |\r\n+---------+------+----------------------------------------+\r\n1 row in set\r\nTime: 0.024s\r\n\r\n```\r\n\r\n\r\n3. What version of TiDB are you using (`tidb-server -V` or run `select tidb_version();` on TiDB)?\r\n```\r\nRelease Version: v3.0.0-rc.1-71-g7deedf841-dirty\r\nGit Commit Hash: 7deedf8418c5c7f6d68cc3f0ea785cd83fefd3a8\r\nGit Branch: master\r\nUTC Build Time: 2019-05-15 03:14:01\r\nGoVersion: go version go1.12.4 linux/amd64\r\nRace Enabled: false\r\nTiKV Min Version: 2.1.0-alpha.1-ff3dd160846b7d1aed9079c389fc188f7f5ea13e\r\nCheck Table Before Drop: false\r\n\r\n```\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "lichunzhu",
	"repo_name": "pingcap/tidb",
	"issue_id": "636868251",
	"issue_number": "17960",
	"issue_state": "opened",
	"issue_title": "Support query cluster id through tidb sql",
	"issue_body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nWhen I get pd address and TiDB sql address and I want to check whether they belong to one cluster, I can get `cluster_id` from PD but I can't get cluster id through TiDB's sqls.\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\nSupport query cluster id through tidb sql\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Teachability, Documentation, Adoption, Migration Strategy:**\r\n<!-- If you can, explain some scenarios how users might use this, situations it would be helpful in. Any API designs, mockups, or diagrams are also helpful. -->\r\n",
	"issue_comments": "0"
},
{
	"login": "yqritc",
	"repo_name": "google/ExoPlayer",
	"issue_id": "202505563",
	"issue_number": "2361",
	"issue_state": "closed",
	"issue_title": "Support CENC ClearKey",
	"issue_body": "Hi, I'm trying to figure out how to play dash content using clearkey.\r\nIt seems mediadrm in Android Framework support clearkey.\r\nhttps://android.googlesource.com/platform/frameworks/av/+/master/drm/mediadrm/plugins/clearkey\r\n\r\nI've found widvine and plyaready samples in demo application, but I couldn't find clearykey one.\r\nExoPlayer does not support clearkey?\r\nIf not, any plan to support in the future?\r\n\r\nthanks",
	"issue_comments": "1"
},
{
	"login": "aljesusg",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "144651909",
	"issue_number": "7597",
	"issue_state": "opened",
	"issue_title": "Issue in git 7433",
	"issue_body": "There is a bug In test of report chargeback of a tenant of https://github.com/ManageIQ/manageiq/pull/7433 , that reports should check that when you make a report of a tenant that takes the vms of subtenants too.",
	"issue_comments": "0"
},
{
	"login": "davidtwco",
	"repo_name": "zulip/zulip",
	"issue_id": "419070405",
	"issue_number": "11843",
	"issue_state": "opened",
	"issue_title": "Add option to only show unread count for mentions in muted streams",
	"issue_body": "It would be nice to have an option so muted streams do not show an unread count, instead showing the number of unread mentions in that stream. This is useful if a user isn't interested in a stream's contents, but wants to be in it so that they can be pinged.\r\n\r\n*This is a feature request from a member of the Rust community that I'm submitting so it is visible and tracked.*",
	"issue_comments": "0"
},
{
	"login": "davidtwco",
	"repo_name": "zulip/zulip",
	"issue_id": "412402927",
	"issue_number": "11618",
	"issue_state": "opened",
	"issue_title": "Add links to run code snippets for supported languages",
	"issue_body": "When a user posts a code snippet in a message with a specific language, Zulip could provide a link to run that code using a service that supports that language - such as the [Rust Playground](https://play.rust-lang.org/) (Rust), or [godbolt](https://godbolt.org/) (C/C++/Rust/Swift/etc).\r\n\r\n#### Example\r\n\r\nGiven a code snippet like below (ie. code fence with a specified language):\r\n\r\n```rust\r\nuse std::collections::HashMap;\r\n\r\nfn main() {\r\n    let timber_resources: HashMap<&str, i32> =\r\n    [(\"Norway\", 100),\r\n     (\"Denmark\", 50),\r\n     (\"Iceland\", 10)]\r\n     .iter().cloned().collect();\r\n    // use the values stored in map\r\n}\r\n```\r\n\r\nA link to [the playground](https://play.rust-lang.org/?code=%23!%5Ballow(unused)%5D%0Ause%20std%3A%3Acollections%3A%3AHashMap%3B%0A%0Afn%20main()%20%7B%0A%20%20%20%20let%20timber_resources%3A%20HashMap%3C%26str%2C%20i32%3E%20%3D%0A%20%20%20%20%5B(%22Norway%22%2C%20100)%2C%0A%20%20%20%20%20(%22Denmark%22%2C%2050)%2C%0A%20%20%20%20%20(%22Iceland%22%2C%2010)%5D%0A%20%20%20%20%20.iter().cloned().collect()%3B%0A%20%20%20%20%2F%2F%20use%20the%20values%20stored%20in%20map%0A%7D) could be created that runs the code (the code is encoded and part of the URL). \r\n\r\n#### Details\r\n\r\nIdeally the user would be able to pick from the supported services which they prefer. Admins should have the option of disabling certain services and adding their own providers (this would avoid proprietary code being sent to the public Godbolt instance, but would allow companies to add their own instances).\r\n\r\n#### Mockup\r\n\r\n![image](https://user-images.githubusercontent.com/1295100/53092006-76780400-350b-11e9-903f-e09bc0337587.png)\r\n",
	"issue_comments": "0"
},
{
	"login": "justinmakaila",
	"repo_name": "Moya/Moya",
	"issue_id": "115780866",
	"issue_number": "290",
	"issue_state": "opened",
	"issue_title": "Send string in body of request",
	"issue_body": "Currently, with the way that the `MoyaTarget` protocol is written, there's no straightforward way to send a string as the body of the request (i.e. GraphQL query).\r\n\r\nAny suggestions from the community?\r\n\r\ncc: @Moya/contributors",
	"issue_comments": "0"
},
{
	"login": "justinmakaila",
	"repo_name": "Moya/Moya",
	"issue_id": "160691111",
	"issue_number": "510",
	"issue_state": "closed",
	"issue_title": "Custom/Default HTTP headers",
	"issue_body": "Hi. I am trying to build network layer for my app with moya, but i have this issue. I have like 25-30 endpoints and i need a custom header for almost all of them. (headers which containing token etc.). \r\nCan I set a default header or return header for all endpoints from TargetType enumaration? \r\n\r\nOr do I have to create a endpoint closure for all of them? ",
	"issue_comments": "4"
},
{
	"login": "zhangjinpeng1987",
	"repo_name": "pingcap/tidb",
	"issue_id": "170320063",
	"issue_number": "1576",
	"issue_state": "opened",
	"issue_title": "support percona tool mydumper&&myloader",
	"issue_body": "1) how to use these tools.\r\n2) checkout why tidb out of memory when use myloader import data",
	"issue_comments": "0"
},
{
	"login": "ekexium",
	"repo_name": "pingcap/tidb",
	"issue_id": "677536861",
	"issue_number": "19155",
	"issue_state": "opened",
	"issue_title": "Incompatibility with MySQL in BETWEEN operation in where clause",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n\r\n<!-- a step by step guide for reproducing the bug. -->\r\n\r\n### 2. What did you expect to see? (Required)\r\n\r\n### 3. What did you see instead (Required)\r\n\r\n### 4. What is your TiDB version? (Required)\r\n\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "444626368",
	"issue_number": "15660",
	"issue_state": "closed",
	"issue_title": "exhaustive-deps: Require specifying dependencies",
	"issue_body": "Originally posted this here: https://github.com/yannickcr/eslint-plugin-react/issues/2277\r\n\r\nConsider adding a boolean option **requireDeps**, which if true disallows not specifying deps in **useEffect, useMemo, useCallback and useLayoutEffect**. Default value should be **false** .\r\n\r\nI believe it's for the better to always specify dependencies in hooks because of unnecessary side-effects when props or state changes unexpectedly. \r\n\r\n### Option: requireDeps: true\r\nExample of **incorrect** code\r\n```javascript\r\n/* eslint react-hooks/exhaustive-deps: [\"error\", { requireDeps: true }] */\r\nfunction MyComp(props) {\r\n  useEffect(() => { ... });\r\n  ...\r\n}\r\n```\r\n\r\nExamples of **correct** code\r\n```javascript\r\n/* eslint react-hooks/exhaustive-deps: [\"error\", { requireDeps: true }] */\r\nfunction MyComp(props) {\r\n  useEffect(() => { ... }, []);\r\n  ...\r\n}\r\n```\r\n\r\n\r\n```javascript\r\n/* eslint react-hooks/exhaustive-deps: [\"error\", { requireDeps: true }] */\r\nfunction MyComp(props) {\r\n  useEffect(() => { ... props.foo; ... }, [ props.foo ]);\r\n  ...\r\n}\r\n```\r\n\r\n### Option: requireDeps: false\r\nExamples of **correct** code\r\n```javascript\r\n/* eslint react-hooks/exhaustive-deps: [\"error\", { requireDeps: false }] */\r\nfunction MyComp(props) {\r\n  useEffect(() => { ... });\r\n  ...\r\n}\r\n```",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "429195201",
	"issue_number": "15318",
	"issue_state": "closed",
	"issue_title": "Get class based components REF with lazy import",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\n\r\n- Feature request\r\n\r\n**What is the current behavior?**\r\n\r\n- Can't get components REF.\r\n\r\nIssue is:\r\n\r\nI have ComplexGrid that extends React.PureComponent.\r\nI want to load this component dynamically.\r\n\r\nReact version = 16.8.5\r\nEg:\r\n\r\n`\r\nconst ComplexGrid  = React.lazy(() => import('@cc/grid/ComplexGrid'));\r\n`\r\n\r\nThen inside constructor I create `this.gridRef = React.createRef();`\r\n\r\nThen JSX part:\r\n\r\n`\r\n<React.Suspense fallback={<div>Loading</div>}>\r\n       <ComplexGrid\r\n               ref={this.gridRef}\r\n              {...some props here}\r\n       />\r\n</React.Suspense>\r\n`\r\n\r\nAnd then I get warning about React.forwardRef.\r\nThe problem:\r\n\r\n- My ComplexGrid  component has some methods (UpdateColumnMetrics, ...etc)\r\n- I need ref to call these methods.\r\n- I don't need to forward ref to 'div' element (or others), I need component's **instance**\r\n- I need normal ref behavior, like with static imports\r\n\r\nIs here any solution?\r\n\r\ncodesandbox example:\r\n\r\nhttps://codesandbox.io/embed/ojkk2z5335",
	"issue_comments": "17"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "413664549",
	"issue_number": "14937",
	"issue_state": "closed",
	"issue_title": "Feature request: Add an optional parameter \"enable\" to all Hooks.",
	"issue_body": "Currently, there's no support for \"conditional Hook\", i mean we couldn't enable/disable Hook based on  a javascript value.\r\n\r\nSuggestion: Allow for all Hooks to have an optional `enable` paramenter , which default value set to `true`.\r\nSo if a user set `enable: false` , like \r\n```js\r\nconst shouldRunState = false\r\nconst [count, setCount] = useState({enable: shouldRunState})\r\n```\r\nthe Hooks will simply have no effect at all, as if it's not there.\r\n\r\nMy example is just to show what the feature look like.\r\nThis feature should be backward compatible with current Hooks API.\r\n\r\nCommon use case is allow a Component/Parent to control Hooks based on `props/context`, so it'll make Hooks more flexible to use.\r\n",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "437905241",
	"issue_number": "15518",
	"issue_state": "closed",
	"issue_title": "License for Source Code Examples & Tutorials on https://reactjs.org",
	"issue_body": "\r\nWhat is the license for the tutorials and examples on https://reactjs.org?",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "444728857",
	"issue_number": "15667",
	"issue_state": "closed",
	"issue_title": "Valid use of hooks in HOC doesn't pass lint",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nBug\r\n\r\n**What is the current behavior?**\r\nErroneous lint error thrown when using hooks inside an HOC\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\n\r\nReproduction:\r\n[Newly scaffolded react app](https://github.com/micburks/hooks-in-hoc)\r\n[Component in question](https://github.com/micburks/hooks-in-hoc/blob/master/src/App.js#L13-L20)\r\n\r\n**What is the expected behavior?**\r\nNo error\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n[react 16.8.6](https://github.com/micburks/hooks-in-hoc/blob/master/yarn.lock#L8316-L8317)\r\n[eslint-plugin-react-hooks 1.6.0](https://github.com/micburks/hooks-in-hoc/blob/master/yarn.lock#L3869-L3870)\r\n\r\nI was looking for a simple way to migrate the logic in some existing HOCs without breaking their usage. Turns out this pattern works fine, but is failed by the eslint plugin.",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "410203584",
	"issue_number": "14846",
	"issue_state": "closed",
	"issue_title": "@types\\react-dom v.16.8.1 : Error TS2314: Generic type 'ReactElement<P>' requires 1 type argument(s)",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nbug\r\n**What is the current behavior?**\r\ntypescript error\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\n\r\n**What is the expected behavior?**\r\nbuild wiothout ts errors\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\nIt worked with previous version of @types\\react-dom. ",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "442978146",
	"issue_number": "15622",
	"issue_state": "closed",
	"issue_title": "[eslint-plugin-react-hooks]: Can't call hooks on component returned from function",
	"issue_body": "Wrapping a component in a function, returning the component.\r\n\r\n\r\ntl;dr\r\n```javascript\r\nexport function Home() {\r\n    return function() {\r\n        const [ items, setItems ] = useState([])\r\n        return <div>nothing</div>\r\n    } \r\n}\r\n\r\nconst root = document.getElementById('root')\r\nReactDOM.render(React.createElement(Home()), root)\r\n```\r\n\r\nResults in the following error:\r\n\r\n```\r\nReact Hook \"useState\" cannot be called inside a callback. React Hooks must be called in a React function component or a custom React Hook function\r\n```\r\n\r\nHowever this works:\r\n\r\n```javascript\r\nexport function Home() {\r\n        const [ items, setItems ] = useState('')\r\n        return <div>nothing</div>\r\n}\r\n\r\nconst root = document.getElementById('root')\r\nReactDOM.render(React.createElement(Home), root)\r\n```\r\n\r\n",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "411148728",
	"issue_number": "14874",
	"issue_state": "closed",
	"issue_title": "Feature Request: React filter",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\n\r\nfeature\r\n\r\n**What is the current behavior?**\r\n\r\nwish to use `filter` in React\r\n\r\n**What is the expected behavior?**\r\n\r\nsupport `filter` in React\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n\r\nI did a repo [react-jsx-filter](https://github.com/chiaweilee/react-jsx-filter) which makes `filter` support in React JSX.\r\nIt base on [babel-plugin-transform-react-jsx-filter](https://github.com/chiaweilee/react-jsx-filter/tree/master/packages/babel-plugin-transform-react-jsx-filter).\r\n\r\n**Example**\r\n\r\n```react.js\r\n// <div>React</div>\r\n<div>{ 'react' | capitalize }</div>\r\n```\r\n\r\n```react.js\r\n// <div>3</div>\r\n<div>{ 1 | addOne | addOne | addOne }</div>\r\n```\r\n\r\n```react.js\r\n// <div>\u4f60\u597d</div>\r\n<div>{ 'hello' | translate('zh-cn') }</div>\r\n```\r\n\r\n```react.js\r\n// with lodash\r\n<div>{ this.state.data | _.filter({ 'active': true }) | this.renderTable }</div>\r\n```\r\n",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "330447029",
	"issue_number": "12995",
	"issue_state": "opened",
	"issue_title": "can't yield children from a generator in render()",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\n\r\nbug.\r\n\r\n**What is the current behavior?**\r\n\r\nvia this thread https://twitter.com/aweary/status/1004837394439290880\r\npassing the result of a generator as a child doesn't 'work'. it renders no children, without an error or warning. \r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\n\r\nrepro - https://codesandbox.io/s/5zp0j8389x\r\n\r\n\r\n**What is the expected behavior?**\r\n\r\nfor the above example, a hundred `<span>`s, numbered 100 -> 1\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n\r\n16.x, all browsers \r\n\r\n\r\n(It appears the validation logic drains the iterator, so when we finally try to 'get' the children again, it returns nothing.) ",
	"issue_comments": "0"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "431476560",
	"issue_number": "15370",
	"issue_state": "closed",
	"issue_title": "TestUtils.renderIntoDocument returns `null` when valid functional component passed.",
	"issue_body": "**Do you want to request a *feature* or report a *bug*?**\r\nI want to report a bug.\r\n\r\n**What is the current behavior?**\r\nCurrently when valid functional component is passed to **TestUtils.renderIntoDocument** it returns a **null** and raise no error.\r\n\r\n**Demo**\r\nThis behavior was reproduced in a sandbox: https://codesandbox.io/s/1zpvll4j24\r\n\r\nCheck the console, to see **TestUtils.renderIntoDocument** output of prepared sample components.\r\n\r\n**Workarounds**\r\nWorkaround that satisfies both SFC and FC is wrapping component into container:\r\n```\r\nconst FCCounter = () => {\r\n  const [count, setCount] = useState(0);\r\n\r\n  return (\r\n    <div>\r\n      <div>{count}</div>\r\n      <button onClick={() => setCount(count + 1)}>+1</button>\r\n    </div>\r\n  );\r\n};\r\n\r\nTestUtils.renderIntoDocument(\r\n  <div>\r\n    <FCCounter />\r\n  </div>\r\n);\r\n```\r\n\r\n**What is the expected behavior?**\r\n\r\n- To render a functional component.\r\n- In worst case - providing an error.\r\n\r\n**Which versions of React are affected by this issue?**\r\nReact version: 16.8.6\r\n",
	"issue_comments": "4"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "408942139",
	"issue_number": "14823",
	"issue_state": "closed",
	"issue_title": "Hook Error:  Hooks can only be called inside the body of a function component",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nBug\r\n\r\n**What is the current behavior?**\r\nWhen using `useState()` hook in a functional component, I get the following error:\r\n\r\n> Hooks can only be called inside the body of a function component\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem.**\r\nThe functional component where the hook is being used:\r\n```\r\nconst AuthForm = () => {\r\n  const [value, setValue] = useState(1);\r\n\r\n  return (\r\n    <Paper square>\r\n      <Tabs\r\n        value={value}\r\n        indicatorColor=\"primary\"\r\n        textColor=\"primary\"\r\n        onChange={() => setValue(value)}\r\n      >\r\n        <Tab label=\"Active\" />\r\n        <Tab label=\"Active\" />\r\n      </Tabs>\r\n    </Paper>\r\n  );\r\n};\r\n```\r\npackage.json:\r\n```\r\n{\r\n  \"main\": \"index.js\",\r\n  \"scripts\": {\r\n    \"dev\": \"nodemon index.js --ignore client\"\r\n  },\r\n  \"dependencies\": {\r\n    \"@babel/core\": \"^7.0.0\",\r\n    \"@babel/preset-env\": \"^7.0.0\",\r\n    \"@babel/preset-react\": \"^7.0.0\",\r\n    \"@material-ui/core\": \"^3.9.2\",\r\n    \"apollo-boost\": \"^0.1.27\",\r\n    \"axios\": \"^0.18.0\",\r\n    \"babel-loader\": \"^8.0.5\",\r\n    \"bcrypt-nodejs\": \"0.0.3\",\r\n    \"body-parser\": \"^1.16.0\",\r\n    \"connect-mongo\": \"^2.0.3\",\r\n    \"express\": \"^4.16.4\",\r\n    \"express-graphql\": \"^0.7.1\",\r\n    \"express-session\": \"^1.15.6\",\r\n    \"graphql\": \"^14.1.1\",\r\n    \"html-webpack-plugin\": \"^3.2.0\",\r\n    \"lodash\": \"^4.17.4\",\r\n    \"mongoose\": \"^5.4.11\",\r\n    \"passport\": \"^0.4.0\",\r\n    \"passport-local\": \"^1.0.0\",\r\n    \"react\": \"16.8.1\",\r\n    \"react-apollo\": \"^2.4.1\",\r\n    \"react-dom\": \"16.8.1\",\r\n    \"react-router\": \"^4.3.1\",\r\n    \"react-router-dom\": \"^4.3.1\",\r\n    \"webpack\": \"^4.29.3\",\r\n    \"webpack-dev-middleware\": \"^3.5.2\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@babel/core\": \"^7.0.0\",\r\n    \"@babel/plugin-proposal-class-properties\": \"^7.3.0\",\r\n    \"@babel/plugin-transform-react-jsx\": \"^7.3.0\"\r\n  }\r\n}\r\n```\r\n\r\n**What is the expected behavior?**\r\nApp should run without any errors.\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\nReact: 16.8.1\r\nReactDOM: 16.8.1\r\nChrome: 71.0.3578.98",
	"issue_comments": "4"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "445923718",
	"issue_number": "15680",
	"issue_state": "closed",
	"issue_title": "Can we simplify type annotation in line 364?",
	"issue_body": "https://github.com/facebook/react/blob/31487dd82e82ef62243806b2e76b23a6fb21d0bc/packages/react-reconciler/src/ReactFiberHooks.js#L362-L365\r\n\r\n\r\nbabel outputs same code for  above and\r\n```\r\n hookTypesDev = \r\n   current !== null \r\n     ? (current._debugHookTypes: Array<HookType>)\r\n     : null; \r\n```\r\n",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "437575033",
	"issue_number": "15508",
	"issue_state": "closed",
	"issue_title": "`static getDerivedStateFromProps()` does not works same as componentWillReceiveProps  ",
	"issue_body": "<!--\r\n  Note: if the issue is about documentation or the website, please file it at:\r\n  https://github.com/reactjs/reactjs.org/issues/new\r\n-->\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\n   bug\r\n**What is the current behavior?**\r\n `static getDerivedStateFromProps()` is not a replacement for `componentWillReceiveProps`\r\n\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\n\r\n**What is the expected behavior?**\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n\r\n16\r\n\r\n\r\nHi I'm trying to implement `toasterNotificationcards` which will be displayed when a user save an item, stating `item saved successfully`\r\n\r\nbelow is my code I'm using `componentWillReceiveProps` which is depreciated I tried `static getDerivedStateFromProps()` but it didn't work \r\n\r\nhow can I removed `componentWillReceiveProps` , assuming the close button shouldn't be in parent component(whichever is calling `notificationcomponent`)\r\n\r\n[jsfiddle working example ](https://jsfiddle.net/munsp36f/)\r\nrequirement:\r\n\r\n  On click of the button show `Notificationcard`\r\n  On click on close hide `Notificationcard`\r\n\r\n```jsx\r\nclass Notification extends React.Component {\r\n  constructor(props) {\r\n    super(props);\r\n    this.state = {\r\n      open: true\r\n    };\r\n  }\r\n\r\n  componentWillReceiveProps(props) {\r\n    this.setState({ open: props.show });\r\n    // setTimeout(this.handleClick.bind(this), 8000);\r\n  }\r\n\r\n  handleClick() {\r\n    this.setState({ open: false });\r\n  }\r\n\r\n  componentDidMount() {\r\n    //setTimeout(this.handleClick.bind(this), 8000);\r\n  }\r\n\r\n  render() {\r\n    if (!this.state.open) {\r\n      return null;\r\n    }\r\n\r\n    return (\r\n      <div>\r\n        <br />\r\n        <div>Item saved successfully</div>\r\n        <div className=\"cls--btn\" onClick={() => this.handleClick()}>\r\n          &#10006;\r\n        </div>\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nclass Test extends React.Component {\r\n  handleClick() {\r\n    this.setState({ show: true });\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div>\r\n        <button onClick={this.handleClick.bind(this)}>click</button>\r\n        <Notification show={true} />\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nReactDOM.render(<Test name=\"World\" />, document.getElementById(\"container\"));\r\n```",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "437016972",
	"issue_number": "15494",
	"issue_state": "closed",
	"issue_title": "Declarative vs. imperative coding style using Hooks",
	"issue_body": "_If this should be asked on Stack Overflow instead, please let me know and feel free to close the issue._\r\n\r\nConsider a component that fetches some data in a custom hook, saves the fetched data in a state hook, and notifies the user that data has been fetched using a prop callback.\r\n\r\nNotifying the user can be done imperatively:\r\n\r\n```js\r\nfunction Component(props) {\r\n  const [ data, setData ] = useState(null);\r\n\r\n  useApi(\"/api/data\")\r\n    .then(setData)\r\n    .then(props.onFetched);\r\n\r\n  return dataToElements(data);\r\n}\r\n```\r\n\r\nor declaratively using an effect hook:\r\n\r\n```js\r\nfunction Component(props) {\r\n  const [ data, setData ] = useState(null);\r\n\r\n  useApi(\"/api/data\")\r\n    .then(setData);\r\n\r\n  useEffect(() => {\r\n    if (data) {\r\n      props.onFetched();\r\n    }\r\n  }, [ data ]);\r\n\r\n  return dataToElements(data);\r\n}\r\n```\r\n\r\nReact seems to promote a declarative approach. But what I've found is that when components grow large and complex, using declarative effect hooks makes the flow of data and actions quite hard to follow. If you're not careful, a lot of things start to depend on a lot of other things, and the predicted results become non-intuitive and hard to wrap your head around.\r\n\r\nI would like to know other peoples' opinions on this matter, and whether or not an imperative approach might sometimes be better. ",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "443998166",
	"issue_number": "15648",
	"issue_state": "closed",
	"issue_title": "React.lazy has problem in hot reload",
	"issue_body": "**Do you want to request a *feature* or report a *bug*?**\r\nbug\r\n\r\n**What is the current behavior?**\r\n\r\nI use React.lazy in routing but when I change my code and I'm in route A, hot reload doesn't work in other routes(route B, route C) and I have to refresh my page\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n   \"react\": \"^16.8.6\",\r\n  \"react-scripts\": \"2.1.8\",\r\n   os : windows\r\n",
	"issue_comments": "1"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "439019719",
	"issue_number": "15547",
	"issue_state": "closed",
	"issue_title": "React breaks on empty nesting",
	"issue_body": "**Do you want to request a *feature* or report a *bug*?**\r\nA bug\r\n\r\n**What is the current behavior?**\r\nReact breaks\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**\r\nI wasn't able to create a jsfiddle but this is what's going on:\r\nI am setting up a template for a way I want to build my site, this is (a part of) my structure:\r\n\r\n- src\r\n    - components\r\n        - frames\r\n            - `index.js`\r\n        - pages\r\n            - `index.js`\r\n    - `App.js`\r\n    - `index.js`\r\n\r\nIn `index.js` I import `App.js` and then render it to the DOM\r\n\r\n```javascript\r\nimport React from \"react\";\r\nimport ReactDOM from \"react-dom\";\r\nimport App from \"./App\";\r\n\r\nReactDOM.render(<App />, document.getElementById(\"root\"));\r\n```\r\n\r\nIn `App.js` I import my frame\r\n\r\n```js\r\nimport React from \"react\";\r\nimport Frame from \"./components/frames\";\r\n\r\nconst App = () => <Frame />;\r\n\r\nexport default App;\r\n```\r\n\r\nIn the index of the frames folder I import a page\r\n```js\r\nimport React from \"react\";\r\nimport Page from \"../pages\";\r\n\r\nconst Frame = () => <Page />;\r\n\r\nexport default Frame;\r\n```\r\nin that index I actually do something\r\n\r\n```js\r\nimport React from \"react\";\r\n\r\nconst Page = () => <div>Hello, world</div>;\r\n\r\nexport default Page;\r\n```\r\n\r\nAt this point a little cumbersome, but still, pretty straight forward. Whenever I do this, my dev server won't load and will eventually give a 'page not responding' error. When I was messing around with it I got it to work once, but then, when I went back to my actual structure (even more deeply nested, exactly like I do above) it will break again.\r\n\r\n**What is the expected behavior?**\r\nReact rendering normally\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\n\r\nReact 16.8.6\r\nApp with create-react-app on windows 10\r\n",
	"issue_comments": "4"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "425773306",
	"issue_number": "15223",
	"issue_state": "closed",
	"issue_title": "In some cases, maybe we should lie to React about deps of useEffect",
	"issue_body": "**Do you want to request a *feature* or report a *bug*?**\r\nfeature\r\n\r\n\r\n**What is the current behavior?**\r\nWe must specify everything used in `useEffect` into the deps array.\r\n\r\n\r\n**To see the special case:**\r\nhttps://codesandbox.io/s/l29rj9n86m\r\n\r\n\r\n**What is the expected behavior?**\r\nI don't know, maybe find a way to avoid lying about the deps, or just make the rule looser(better not). The key is that I want to \"remember\" the state `data` and `newProps.number - data` *only* whenever the prop `number` change.\r\n\r\n\r\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\r\nReact: 16.8.3\r\nBrower: chrome\r\nNo\r\n",
	"issue_comments": "5"
},
{
	"login": "threepointone",
	"repo_name": "facebook/react",
	"issue_id": "411953090",
	"issue_number": "14889",
	"issue_state": "closed",
	"issue_title": "Safari won't let me type on a text input",
	"issue_body": "I wrote a simple search box that works fine on Chrome and Firefox, but in Safari is another story. It let me type a single character and won't update any more.\r\n\r\n![2019-02-19 11 25 05](https://user-images.githubusercontent.com/42145089/53022321-b8d11080-3439-11e9-89e7-6dca97a2611c.gif)\r\n\r\nHere is the code\r\n\r\n```javascript\r\nfunction Header({ history }) {\r\n  const [q, setQ] = useState(\"\");\r\n\r\n  const onSubmit = e => {\r\n    e.preventDefault();\r\n    history.push({\r\n      pathname: \"/buscar\",\r\n      search: `q=${encodeURIComponent(q.trim())}`,\r\n    });\r\n  };\r\n\r\n  return (\r\n    <header className={styles.Header}>\r\n      <div className={styles.Container}>\r\n        <form className={styles.Form} onSubmit={onSubmit}>\r\n          <input\r\n            autoCapitalize=\"off\"\r\n            autoComplete=\"off\"\r\n            autoCorrect=\"off\"\r\n            autoFocus\r\n            className={styles.Input}\r\n            onChange={e => setQ(e.target.value)}\r\n            placeholder=\"Buscar por nombre, dni o cuit\"\r\n            spellCheck=\"false\"\r\n            type=\"search\"\r\n            value={q}\r\n          />\r\n          <button type=\"submit\" className={styles.Submit}>\r\n            Buscar\r\n          </button>\r\n        </form>\r\n      </div>\r\n    </header>\r\n  );\r\n}\r\n```\r\n\r\nAm I missing something? Is this a known bug?",
	"issue_comments": "5"
},
{
	"login": "Titaniumtown",
	"repo_name": "allinurl/goaccess",
	"issue_id": "657005365",
	"issue_number": "1843",
	"issue_state": "opened",
	"issue_title": "Yet another log format issue",
	"issue_body": "So i run apache web server, with the logformat: \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-agent}i\\\"\" combined\r\n\r\n\r\n107.145.175.222 - - [14/Jul/2020:21:31:05 -0400] \"GET /log.html HTTP/1.1\" 304 - \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\"\r\n\r\n\r\n\r\none example: ``` goaccess /mnt/tb_hdd/logs/access_log_apache.txt --date-format='%d/%b/%Y' --time-format=%H:%M:%S  -o /mnt/hdd/http_share/log.html ```\r\noutputs: \r\n```\r\nParsed 1 lines producing the following errors:\r\n\r\nToken 'xx.xxx.xxx.xxx' doesn't match specifier '%h'\r\n```\r\nnote the ip address blocked out above seems to have the first character cut off.\r\n\r\nwhat log-format do i use? I tried log-format \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-agent}i\\\"\" and a bunch of other stuff. it just doesnt seem to work! Please help! I would love to use this tool!",
	"issue_comments": "0"
},
{
	"login": "MuxZeroNet",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "198883652",
	"issue_number": "739",
	"issue_state": "opened",
	"issue_title": "UnboundLocalError: local variable 'json_row' referenced before assignment",
	"issue_body": "```\r\nSite:1MeFqF..q7nH Json merged-ZeroMe/1[...]/data/users/1[...]/content.json load error:\r\nUnboundLocalError: local variable 'json_row' referenced before assignment\r\nin SiteStorage.py line 223 > Db.py line 362\r\n```",
	"issue_comments": "0"
},
{
	"login": "tbm",
	"repo_name": "rclone/rclone",
	"issue_id": "620742093",
	"issue_number": "4251",
	"issue_state": "opened",
	"issue_title": "rclone config: renew token expiry without running through config",
	"issue_body": "#### What is your current rclone version (output from `rclone version`)?\r\n\r\n1.51.0\r\n\r\n#### What problem are you are trying to solve?\r\n\r\nMy token expired because I hadn't used rclone in months.  Running `rclone config` allows me to get a new token.\r\n\r\nHowever, I have to run through all the configuration steps again.\r\n\r\n#### How do you think rclone should be changed to solve that?\r\n\r\nI already configured rclone.  I don't want to run through the config again.  I have no clue how to answer most of the questions.  But I had a working config before... presumably my config from a year ago still works (yes, confirmed, it does).\r\n\r\nI *just* want to get a new token.  Can we have an option to renew a token without running through the whole config menu again?\r\n",
	"issue_comments": "0"
},
{
	"login": "yaacov",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "164055888",
	"issue_number": "9624",
	"issue_state": "opened",
	"issue_title": "Hawkular metrics reading regression",
	"issue_body": "The current call for hawkular-client initializer uses a URI object, in v2.2.0 it requires an implicit conversion to string.\r\n\r\nWhen reading metrics with hawkular-client v2.2.0 we get the error:\r\n```\r\nNoMethodError: undefined method `gsub' for #<URI::HTTPS:0x00557242b2f278>\r\n\tfrom /usr/local/lib/ruby/gems/2.2.0/gems/hawkular-client-2.2.0/lib/hawkular/base_client.rb:142:in `normalize_entrypoint_url'\r\n```",
	"issue_comments": "0"
},
{
	"login": "yaacov",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "167355206",
	"issue_number": "10027",
	"issue_state": "opened",
	"issue_title": "Random order of authentications in ems summary status",
	"issue_body": "**Description**\r\nThe order of authentication displayed in the summary status page is random.\r\n\r\n**What happen**\r\nIn the summary page on the status card, authentications are displayed in random order.\r\n\r\n**What should happen**\r\nThe authentications are always displayed in the same order. \r\n\r\n**Screen shots**\r\nAuthentications are sometimes displayed alphabetically and sometimes not.  \r\n![sort-asc](https://cloud.githubusercontent.com/assets/2181522/17101332/95be8c7c-527c-11e6-9f62-a5636d80c541.png)\r\n![sort-desc](https://cloud.githubusercontent.com/assets/2181522/17101335/9a3a4714-527c-11e6-9332-f82753aa9108.png)\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "yaacov",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "157383511",
	"issue_number": "9024",
	"issue_state": "closed",
	"issue_title": "Metrics seems to fail when not defining a Hawkular Endpoint.",
	"issue_body": "Metrics seems to fail when not defining a Hawkular Endpoint.\r\n\r\n_What happen:_\r\nWhen not defining a Hawkular hostname metric collection fails.\r\n_What should happen:_\r\nIt should fallback to the providers hostname.",
	"issue_comments": "3"
},
{
	"login": "yaacov",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "165258186",
	"issue_number": "9768",
	"issue_state": "closed",
	"issue_title": "Regression in EMS Form validation",
	"issue_body": "**Description**\r\nEMS Form validation can not create new ems container with bearer (default) authentication.\r\n\r\n**What happen**\r\nIn Add New Containers Provider form when trying to validate the **bearer** (default) endpoint\r\na. add the name, type, hosname, port and bearer_token\r\nb. we get a `Missing credentials` error\r\n\r\n**What should happen**\r\nIn Add New Containers Provider form when trying to validate the **bearer** (default) endpoint\r\na. add the name, type, hosname, port and bearer_token\r\nb. we get a result of an authentication test (e.g. bearer_token valid or not valid)\r\n\r\n**Screenshots**\r\n![screenshot-bearer](https://cloud.githubusercontent.com/assets/2181522/16795643/3bf8f1d0-48e7-11e6-92ff-b8aed3fafb2c.png)\r\n![screenshot-hawkular](https://cloud.githubusercontent.com/assets/2181522/16795646/4281605a-48e7-11e6-8e61-5637b69fe7c3.png)\r\n\r\n\r\n",
	"issue_comments": "7"
},
{
	"login": "yaacov",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "158087038",
	"issue_number": "9096",
	"issue_state": "opened",
	"issue_title": "TypeError Exception when reading hawkular metrics",
	"issue_body": "**When reading hawkular metrics we can get a TypeError Exception.**\r\n\r\n_What happen_:\r\nIf the Hawkular data struct is empty we get an the error.\r\n\r\n_What should happen_:\r\nWe should check for empty data structs.\r\n\r\n_Examples_:\r\nFull data struct:\r\n```\r\n{\"start\"=>1464856440000,\r\n  \"end\"=>1464856460000,\r\n  \"min\"=>13548162076446.0,\r\n  \"avg\"=>13548162076446.0,\r\n  \"median\"=>13548162076446.0,\r\n  \"max\"=>13548162076446.0,\r\n  \"sum\"=>13548162076446.0,\r\n  \"samples\"=>1,\r\n  \"empty\"=>false}\r\n```\r\nEmpty data struct:\r\n` {\"start\"=>1464856460000, \"end\"=>1464856480000, \"empty\"=>true}`",
	"issue_comments": "0"
},
{
	"login": "zhuo-zhi",
	"repo_name": "pingcap/tidb",
	"issue_id": "862506473",
	"issue_number": "24162",
	"issue_state": "opened",
	"issue_title": "Correctness testing 2: test direct reading with other operators",
	"issue_body": "## Development Task\r\n\r\nSubitems from #24150 \r\n\r\n- [ ]  <code>BatchGet</code> and <code>PointGet</code>\r\n- [ ]  <code>Order</code> + <code>Limit</code>\r\n- [ ]  All kinds of Joins, especially <code>IndexLookUpJoin</code>\r\n- [ ]  All kinds of Aggregations",
	"issue_comments": "0"
},
{
	"login": "arcanis",
	"repo_name": "facebook/react",
	"issue_id": "109631671",
	"issue_number": "5047",
	"issue_state": "opened",
	"issue_title": "Default lifecycle methods on React.Component ?",
	"issue_body": "Just a small API detail: would it make sense to implement default (empty) lifecycle methods in the base React.Component class? It would allow to have homogenous implementations as far as super() calls are concerned.\r\n\r\nFor example, the following will throw due to the missing `componentDidMount` implementation in the parent class:\r\n\r\n```\r\nclass Foo extends React.Component {\r\n    componentDidMount( ) {\r\n        super.componentDidMount( );\r\n    }\r\n};\r\n```\r\n\r\nHowever, when overloading the `Foo` class, a missing super call might introduce some bugs. That's what got me to think that maybe it was safer to always put the super-call, and then I discovered that it was not possible when heriting from the base class.\r\n",
	"issue_comments": "0"
},
{
	"login": "olix0r",
	"repo_name": "twitter/finagle",
	"issue_id": "73437086",
	"issue_number": "377",
	"issue_state": "opened",
	"issue_title": "./sbt fails to download sbt-launch.jar",
	"issue_body": "    $ rm sbt-launch.jar \r\n\r\n    $ ./sbt            \r\n    downloading sbt-launch.jar\r\n    bad sbt-launch.jar.  delete sbt-launch.jar and run ./sbt again.\r\n\r\n    $ cat sbt-launch.jar \r\n    <html>\r\n    <head><title>302 Found</title></head>\r\n    <body bgcolor=\"white\">\r\n    <center><h1>302 Found</h1></center>\r\n    <hr><center>nginx/1.8.0</center>\r\n    </body>\r\n    </html>\r\n\r\n    curl -v http://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.8/sbt-launch.ja\r\n    > GET /typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.8/sbt-launch.jar HTTP/1.1\r\n    > User-Agent: curl/7.37.1\r\n    > Host: repo.typesafe.com\r\n    > Accept: */*\r\n    > \r\n    < HTTP/1.1 302 Moved Temporarily\r\n    < Content-Type: text/html\r\n    < Date: Tue, 05 May 2015 21:26:52 GMT\r\n    < Location: http://dl.bintray.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.8/sbt-launch.jar\r\n    < Server: nginx/1.8.0\r\n    < Content-Length: 160\r\n\r\nI think this is trivial to fix by adding the `-L` flag to curl?  I'l prep a PR...",
	"issue_comments": "0"
},
{
	"login": "blacktear23",
	"repo_name": "pingcap/tidb",
	"issue_id": "248294305",
	"issue_number": "4057",
	"issue_state": "opened",
	"issue_title": "TiDB crash by nil pointer dereference",
	"issue_body": "Please answer these questions before submitting your issue. Thanks!\r\n\r\n1. What did you do?\r\n\r\nRun TiDB rc4 on my laptop, then sleep my laptop for two days then open my laptop see running TiDB crashed.\r\n\r\nbelow is crash log.\r\n\r\n```\r\n2017/08/05 03:29:08 schema_validator.go:158: [info] the schema validator's latest schema version 0 is expired\r\npanic: runtime error: invalid memory address or nil pointer dereference\r\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1872bfc]\r\n\r\ngoroutine 214 [running]:\r\ngithub.com/pingcap/tidb/domain.(*schemaValidator).Update(0xc420072280, 0x576bae42b140003, 0xd, 0xd, 0x0, 0x0, 0x0)\r\n\t/Users/rainli/goprojs/src/github.com/pingcap/tidb/domain/schema_validator.go:111 +0x56c\r\ngithub.com/pingcap/tidb/domain.(*Domain).Reload(0xc420366480, 0x0, 0x0)\r\n\t/Users/rainli/goprojs/src/github.com/pingcap/tidb/domain/domain.go:299 +0x318\r\ngithub.com/pingcap/tidb/domain.(*Domain).loadSchemaInLoop(0xc420366480, 0x2540be400)\r\n\t/Users/rainli/goprojs/src/github.com/pingcap/tidb/domain/domain.go:321 +0x192\r\ncreated by github.com/pingcap/tidb/domain.NewDomain\r\n\t/Users/rainli/goprojs/src/github.com/pingcap/tidb/domain/domain.go:443 +0x4aa\r\n```\r\n\r\n2. What did you expect to see?\r\n\r\n\r\n\r\n3. What did you see instead?\r\n\r\n\r\n\r\n4. What version of TiDB are you using (`tidb-server -V`)?\r\n\r\n```\r\nGit Commit Hash: 6e0ff81269d49ffec39066d5110ee28f7fe67f2f\r\nUTC Build Time:  2017-08-04 03:47:00\r\n```\r\n",
	"issue_comments": "0"
},
{
	"login": "cyphase",
	"repo_name": "zulip/zulip",
	"issue_id": "439049291",
	"issue_number": "12239",
	"issue_state": "opened",
	"issue_title": "Linkifier URL validation regex is broken",
	"issue_body": "The linkifier validation regex doesn't allow things like ampersands (for query parameters) or forward slashes following the last placeholder.\r\n\r\nAmpersand example: https://example.com/?foo=bar&id=%(id)s\r\nForward slash example: https://example.com/product/%(id)s/details\r\n\r\nEither of those results in a validation error saying \"Invalid URL format string\".\r\n\r\n[Here's the relevant function as of the latest commit](https://github.com/zulip/zulip/blob/272ed9068590e575e09c5abaeffca48040164873/zerver/models.py#L635):\r\n\r\n```python\r\ndef filter_format_validator(value: str) -> None:\r\n    regex = re.compile(r'^([\\.\\/:a-zA-Z0-9#_?=-]+%\\(([a-zA-Z0-9_-]+)\\)s)+[a-zA-Z0-9_-]*$')\r\n\r\n    if not regex.match(value):\r\n        raise ValidationError(_('Invalid URL format string.'))\r\n```\r\n\r\nNote that in the first character set, which is for \"what comes before a placeholder\", there's no ampersand (or semi-colon), and in the third character set, which is for what comes after the last placeholder, there's less; not even a forward slash, which is what blocks the second example above.\r\n\r\nThe second character set is for the placeholder names. This is also broken in practice, because it allows hyphens. While placeholders are allowed to have hyphens in Python, named groups in regular expressions are not, since they have to be valid Python identifiers. This could come up if someone tries to use a name with a hyphen, only gets a validation error for the regex, and mistakenly changes it only there, not in both places.\r\n\r\nWhich segues into something that should probably be its own issue, since it goes beyond the regex itself, but I'll mention it here. It's possible to have non-paired named groups and placeholders. If there are named groups that don't have a matching placeholder, they're just silently dropped, which isn't breakage but may not be ideal. However, if there are placeholders that don't have a matching named group, the message isn't sent, although it still appears in the sending client instance, with the target string linkified with the unfilled placeholder still visible in the URL. In the web and desktop clients, there are red Retry and Cancel buttons on the right when hovering over the message; Retry has no obvious effect, and Cancel removes the message. In the mobile client (on Android, but I assume it's the same on iOS), there's a spinner that isn't moving to the right of the message. Long pressing bring up the menu with an option to Delete, but since I'm an admin on this instance I can do that anyway, so I don't know if that's equivalent to Cancel from the web/desktop clients.\r\n\r\n---\r\n\r\nHere's the CZO thread that led to opening this issue: https://chat.zulip.org/#narrow/stream/9-issues/topic/linkifier.20URL.20issues\r\n\r\n@timabbott mentioned a workaround that can be used in the interim to bypass the restrictive aspect of the validation regex:\r\n\r\n> You can bypass that validator locally by using the Django command line (`manage.py shell`), e.g.:\r\n> `realm_filter = RealmFilter.objects.create(realm_id=2, pattern='pattern', url_format_string='format string')`",
	"issue_comments": "0"
},
{
	"login": "NE-SmallTown",
	"repo_name": "facebook/react",
	"issue_id": "211568735",
	"issue_number": "9099",
	"issue_state": "opened",
	"issue_title": "Why don't convert the third and later arguments of React.createElement to an array",
	"issue_body": "Same as [#5403](https://github.com/babel/babel/issues/5403) of babel.The member of babel doesn't know too much about this.So I want to know your thoughts about this.Thanks.",
	"issue_comments": "0"
},
{
	"login": "NE-SmallTown",
	"repo_name": "facebook/react",
	"issue_id": "211088614",
	"issue_number": "9086",
	"issue_state": "opened",
	"issue_title": "Maybe ref attribute usage maybe could cause performance problem?",
	"issue_body": "In the doc of [ref attribute](https://facebook.github.io/react/docs/refs-and-the-dom.html#adding-a-ref-to-a-dom-element):\r\n\r\n```\r\nreturn (\r\n      <div>\r\n        <input\r\n          type=\"text\"\r\n          ref={(input) => { this.textInput = input; }} />\r\n      </div>\r\n    );\r\n```\r\n\r\nI thinks it maybe cause performance problem just as the arrow function of event bind in [handle event](https://facebook.github.io/react/docs/handling-events.html)\r\n\r\n```\r\nrender() {\r\n    // This syntax ensures `this` is bound within handleClick\r\n    return (\r\n      <button onClick={(e) => this.handleClick(e)}>\r\n        Click me\r\n      </button>\r\n    );\r\n  }\r\n}\r\n\r\nthe doc mention the performance problem at below:\r\n\r\nThe problem with this syntax is that a different callback is created each time the LoggingButton renders. In most cases, this is fine. However, if this callback is passed as a prop to lower components, those components **might do an extra re-rendering**. We generally recommend binding in the constructor or using the property initializer syntax, to avoid this sort of performance problem.\r\n```\r\n\r\nBut in the [ref attribute](https://facebook.github.io/react/docs/refs-and-the-dom.html#adding-a-ref-to-a-dom-element) section,there are no tips.\r\n\r\nSo I want to know your thoughts on this.Thanks.",
	"issue_comments": "0"
},
{
	"login": "G-Rath",
	"repo_name": "facebook/jest",
	"issue_id": "433466714",
	"issue_number": "8334",
	"issue_state": "opened",
	"issue_title": "Jest suppresses errors & complains about describe callback returning a value when only running specific tests",
	"issue_body": "<!-- Love Jest? Please consider supporting our collective: \ud83d\udc49  https://opencollective.com/jest/donate -->\r\n\r\n## \ud83d\udc1b Bug Report\r\n\r\nIf you run a specific test (such as using `--testNamePattern` - there could be other ways, but this is how I found the bug), jest will eat any errors thrown outside of that test, skipping the test and sometimes complaining about a describe callback not returning a value.\r\n\r\nI did do a very minor dive into this a while ago, before I determined the cause (as when I first started jest I was getting these strange \"a describe callback must not return a value\", despite never returning a value) - somewhere internally something returns `null` instead of `undefined`, which `jest` doesn't know it's doing and hence complains to the developer.\r\n\r\n## To Reproduce\r\n\r\n1. Write a test file that errors outside of an `test`/`it` block, that is inside at least one `describe` block\r\n2. Run the test specifically using a parameter like `--testNamePatten`\r\n\r\n## Expected behavior\r\n\r\nJest tells me that the error happened, in the same manner it does when I run the `describe` block.\r\n\r\nJest also shouldn't complain about a describe callback shouldn't have a return value (which it does *even if* I'm running the `describe` block - let me know if you'd like me to make a separate issue for this)\r\n\r\n## Link to repl or repo (highly encouraged)\r\n\r\nPlease provide either a [repl.it demo](https://repl.it/languages/jest) or a minimal repository on GitHub.\r\n\r\nIssues without a reproduction link are likely to stall.\r\n\r\n## Run `npx envinfo --preset jest`\r\n\r\nPaste the results here:\r\n\r\n```bash\r\n  System:\r\n    OS: Windows 10\r\n    CPU: (8) x64 Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz\r\n  Binaries:\r\n    Node: 10.15.3 - C:\\nodejs\\node.EXE\r\n    Yarn: 1.13.0 - ~\\AppData\\Roaming\\npm\\yarn.CMD\r\n    npm: 6.9.0 - ~\\AppData\\Roaming\\npm\\npm.CMD\r\n```\r\n",
	"issue_comments": "0"
},
{
	"login": "fengou1",
	"repo_name": "pingcap/tidb",
	"issue_id": "968354905",
	"issue_number": "27154",
	"issue_state": "opened",
	"issue_title": "DBaaS import dumpling sql and Aurora Snapshot take a long time when tables = 10000",
	"issue_body": "## Enhancement\r\ntest result:\r\nNr of dbs | Nr of tables | Nr of records | Data size | Restore time | Average speed\r\n-- | -- | -- | -- | -- | --\r\n1 | 10000 | 2000 0000 | ~12 GB | 3 hours 38 mins | ?\r\n1 | 10000 | 2000 0000 | ~12 GB | 9 hours 38 mins | ?\r\n\r\nDBaaS test steps:\r\n\r\n1. Create Aurora MySQL\r\n2. Generate a test data (10K tables, 20M records)\r\n3. Dump Aurora MySQL to S3\r\n4. Create DBaaS cluster\r\n5. Import S3 dumpling sql file into DBaaS\r\n\r\n\r\nlog:\r\n[2021/08/10 08:17:16.863 +00:00] [INFO] [restore.go:2309] [\"analyze start\"] [table=`test_betting_0`.`unit1_82_game_bets_game_tag_1`]\r\n2021-08-10 16:17:16\t\r\n[2021/08/10 08:17:16.863 +00:00] [INFO] [restore.go:2304] [\"checksum pass\"] [table=`test_betting_0`.`unit1_82_game_bets_game_tag_1`] [local=\"{cksum=2039107447242499706,size=584059,kvs=5000}\"]\r\n2021-08-10 16:17:16\t\r\n[2021/08/10 08:17:16.863 +00:00] [INFO] [checksum.go:162] [\"remote checksum completed\"] [table=unit1_82_game_bets_game_tag_1] [takeTime=8.417914ms] []\r\n2021-08-10 16:17:16\t\r\n[2021/08/10 08:17:16.854 +00:00] [INFO] [checksum.go:159] [\"remote checksum start\"] [table=unit1_82_game_bets_game_tag_1]\r\n2021-08-10 16:17:16\t\r\n[2021/08/10 08:17:16.854 +00:00] [INFO] [restore.go:1745] [\"local checksum\"] [table=`test_betting_0`.`unit1_82_game_bets_game_tag_1`] [checksum=\"{cksum=2039107447242499706,size=584059,kvs=5000}\"]\r\n2021-08-10 16:17:16\t\r\n[2021/08/10 08:17:16.854 +00:00] [INFO] [restore.go:2311] [\"analyze completed\"] [table=`test_betting_0`.`unit1_30_game_bets_game_tag_12`] [takeTime=10.155496397s] []\r\n2021-08-10 16:17:08\t\r\n[2021/08/10 08:17:08.847 +00:00] [INFO] [restore.go:2309] [\"analyze start\"] [table=`test_betting_0`.`unit1_31_game_bets_game_tag_analysis_11`]\r\n2021-08-10 16:17:08\t\r\n[2021/08/10 08:17:08.847 +00:00] [INFO] [restore.go:2304] [\"checksum pass\"] [table=`test_betting_0`.`unit1_31_game_bets_game_tag_analysis_11`] [local=\"{cksum=11816087971824624526,size=685015,kvs=7000}\"]\r\n2021-08-10 16:17:08\t\r\n[2021/08/10 08:17:08.847 +00:00] [INFO] [checksum.go:162] [\"remote checksum completed\"] [table=unit1_31_game_bets_game_tag_analysis_11] [takeTime=10.346214ms] []\r\n2021-08-10 16:17:08\t\r\n[2021/08/10 08:17:08.836 +00:00] [INFO] [checksum.go:159] [\"remote checksum start\"] [table=unit1_31_game_bets_game_tag_analysis_11]\r\n\r\n\r\nthere is alternative solution is to expand 'checksum-table-concurrency' accordingly.\r\n",
	"issue_comments": "0"
},
{
	"login": "tangdou1",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "302945076",
	"issue_number": "1314",
	"issue_state": "opened",
	"issue_title": "[Suggestion] Add a button \"open in folder\" in the \"0\".",
	"issue_body": "",
	"issue_comments": "0"
},
{
	"login": "leoppro",
	"repo_name": "pingcap/tidb",
	"issue_id": "386080270",
	"issue_number": "8532",
	"issue_state": "opened",
	"issue_title": "Support to restore SQL text from a AST tree",
	"issue_body": "### See: [Proposal](https://github.com/pingcap/tidb/tree/master/docs/design/2018-11-29-ast-to-sql-text.md)\r\n\r\nOur main work is in [pingcap/parser/ast](https://github.com/pingcap/parser/tree/master/ast)\r\n\r\nThere are some sub tasks:\r\n\r\nStruct | Contributor | PR\r\n-------- | --------------- | ----\r\nall `ast.ExprNode` | |\r\nall `ast.FuncNode` | |\r\nall `ast.Node` in `stats.go` | |\r\nall `ast.Node` in `misc.go` | |\r\n`ast.CreateTableStmt`,`ast.CreateIndexStmt` and it's child nodes | |\r\n`ast.CreateViewStmt`,`ast.AlterTableStmt` and it's child nodes | |\r\nany other `ast.Node` in `ddl.go` | | \r\n`ast.SelectStmt`,`ast.DeleteStmt` and it's child nodes | |\r\n`ast.InsertStmt`,`ast.UpdateStmt` and it's child nodes | |\r\nany other `ast.Node` in `dml.go` | | \r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "drhill",
	"repo_name": "google/ExoPlayer",
	"issue_id": "154375704",
	"issue_number": "1522",
	"issue_state": "opened",
	"issue_title": "Some AC3 tracks in passthrough mode have issues with seeking (ShieldTV 6.0)",
	"issue_body": "On a few (at least one I can reproduce easily) shows with AC3 tracks being passed through to my receiver when I do a 30 second seek forward (or sometimes it takes 2-4 seeks) the current time becomes a horrible large number.\r\n\r\nThe problem occurs in exoplayer's AudioTrack.java AudioTrackUtil.getPlaybackHeadPosition() function here:\r\nif (lastRawPlaybackHeadPosition > rawPlaybackHeadPosition) {\r\n        // The value must have wrapped around.\r\n        rawPlaybackHeadWrapCount++;\r\n      }\r\n      lastRawPlaybackHeadPosition = rawPlaybackHeadPosition;\r\n      return rawPlaybackHeadPosition + (rawPlaybackHeadWrapCount << 32);\r\n\r\nThis is on an Nvidia Shield TV with 6.0 (API 23).  Whether I cheat and force needsPassthroughWorkaround = true (by removing the version check) or not.  My \"fix\" was to comment out the increment of rawPlaybackHeadWrapCount.  Not a good idea since I'm sure that is there for a good reason, but perhaps lastRawPlaybackHeadPosition should be checked to see if it is near a wrap threshold?\r\n\r\nI can provide an episode on Google Drive if needed.",
	"issue_comments": "0"
},
{
	"login": "WesleyAC",
	"repo_name": "zulip/zulip",
	"issue_id": "422510232",
	"issue_number": "11938",
	"issue_state": "opened",
	"issue_title": "Errors when changing password do not display",
	"issue_body": "I attempted to change my password to the string `\"Q|~>(I%$9r*IctB1yRBWJL\"|`. This does not change my password, but this is unclear from the UI. I think what might be happening is an error appears for a moment, but the page is immediately reloads, dismissing the error.",
	"issue_comments": "0"
},
{
	"login": "JRHeaton",
	"repo_name": "Moya/Moya",
	"issue_id": "110248618",
	"issue_number": "246",
	"issue_state": "opened",
	"issue_title": "Carthage installs require explicit dependency listing",
	"issue_body": "Hi there. I've noticed that this library is set up to resolve its own dependencies via CocoaPods, but shares the Pod project's framework targets to be built as shared so that Carthage can see them. So far so good.\r\n\r\nThe \"issue\" is that when installing Moya via Carthage, if you were to simply list Moya itself as a dependency, it will not fetch for example, Alamofire, which is a mandatory dependency of Moya. I think this can _possibly_ be remedied by including a Cartfile for Moya in the root of the repository that lists the dependencies. It won't need to be used obviously during development of Moya, but will provide a way for Carthage to know which deps to download + build.",
	"issue_comments": "0"
},
{
	"login": "rllola",
	"repo_name": "HelloZeroNet/ZeroNet",
	"issue_id": "299825398",
	"issue_number": "1301",
	"issue_state": "opened",
	"issue_title": "[CLI option] Timeout fileserver option on publish",
	"issue_body": "By default when publishing new content sing the CLI commnd sitePublish it will last 60sec. Not enought time to download the new files. \r\n\r\nIt could be usefull to be able to pass as an option the time we want the file server to stay active.\r\n\r\nOr even better if pulish could verify that it has sent all the files modified. So when we just publish and close Zeronet we are sure that someone somewhere has the new content.",
	"issue_comments": "0"
},
{
	"login": "joccau",
	"repo_name": "pingcap/tidb",
	"issue_id": "964538754",
	"issue_number": "27046",
	"issue_state": "opened",
	"issue_title": "br-backup: The performance and the memory consumption about full-backup in tools",
	"issue_body": "## General Question\r\nThe code logic for full backup is:\r\n///////////////Part of the logic in the code////////////////////\r\nStartWriteMetasAsyn()\r\nBackup range()\r\nFinishWriteMetas()\r\n\r\nStartWriteMetasAsync()\r\nBackup architecture()\r\nFinishWriteMetas()\r\n///////////////////////////////////\r\n\r\nIt has two problems\r\n(1) FinishWriteMetas() will repeatedly refresh proto.Marshal(writer.backupMeta) to backupmeta. The impact of multiple refreshes on performance should be considered\r\n(2) The huge amount of data will lead to too much range/region, and the MetaWriter structure will take up a lot of memory\r\n\r\n\r\n<!--\r\n\r\nBefore asking a question, make sure you have:\r\n\r\n- Searched existing Stack Overflow questions.\r\n- Googled your question.\r\n- Searched open and closed [GitHub issues](https://github.com/pingcap/tidb/issues?utf8=%E2%9C%93&q=is%3Aissue)\r\n- Read the documentation:\r\n  - [TiDB Readme](https://github.com/pingcap/tidb)\r\n  - [TiDB Doc](https://github.com/pingcap/docs)\r\n\r\n-->\r\n",
	"issue_comments": "0"
},
{
	"login": "Tjianke",
	"repo_name": "pingcap/tidb",
	"issue_id": "797314470",
	"issue_number": "22627",
	"issue_state": "opened",
	"issue_title": "Fix the benchmark for window function",
	"issue_body": "## Development Task\r\n\r\nFunction `BenchmarkWindowFunctionsWithSlidingWindow` in `executor/benchmark_test.go` failed on master branch.\r\n\r\n```\r\ngo test -v -benchmem -bench=BenchmarkWindowFunctionsWithSlidingWindow  -run=BenchmarkWindowFunctionsWithSlidingWindow\r\n\r\ngoos: darwin\r\ngoarch: amd64\r\npkg: github.com/pingcap/tidb/executor\r\nBenchmarkWindowFunctionsWithSlidingWindow\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:sum,_aggColType:float,_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:sum,_aggColType:float,_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8                151           7390369 ns/op         7475284 B/op       6535 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:sum,_aggColType:decimal(10,0),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:sum,_aggColType:decimal(10,0),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8         87          14369208 ns/op         8859247 B/op       4259 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:count,_aggColType:int(11),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:count,_aggColType:int(11),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8            163           7219211 ns/op         7428094 B/op       6532 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:avg,_aggColType:float,_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:avg,_aggColType:float,_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8                163           7376047 ns/op         7516243 B/op       6537 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:avg,_aggColType:decimal(10,0),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:avg,_aggColType:decimal(10,0),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8         34          34557702 ns/op        11887266 B/op     103938 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:bit_xor,_aggColType:int(11),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:bit_xor,_aggColType:int(11),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8          165           7357622 ns/op         7571454 B/op       6537 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:max,_aggColType:int(11),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:max,_aggColType:int(11),_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)-8               24          48646361 ns/op        20222958 B/op     211876 allocs/op\r\nBenchmarkWindowFunctionsWithSlidingWindow/(func:max,_aggColType:float,_numFunc:1,_ndv:100,_rows:100000,_sorted:true,_concurrency:1)\r\npanic: remove a not exist value\r\n\r\ngoroutine 215 [running]:\r\ngithub.com/pingcap/tidb/executor/aggfuncs.(*maxMinHeap).Remove(...)\r\n        /Users/damn/go/tidb/executor/aggfuncs/func_max_min.go:79\r\ngithub.com/pingcap/tidb/executor/aggfuncs.(*maxMin4Float32Sliding).Slide(0xc00012a480, 0x6cd6540, 0xc000464ae0, 0xc001fb6000, 0x3fe, 0x400, 0x36, 0x4b, 0x1, 0x1, ...)\r\n        /Users/damn/go/tidb/executor/aggfuncs/func_max_min.go:594 +0x4f1\r\ngithub.com/pingcap/tidb/executor.(*rowFrameWindowProcessor).appendResult2Chunk(0xc0004219a0, 0x6cd6540, 0xc000464ae0, 0xc001fb6000, 0x3fe, 0x400, 0xc00070a230, 0x3bd, 0x400, 0x0, ...)\r\n        /Users/damn/go/tidb/executor/window.go:338 +0x60f\r\ngithub.com/pingcap/tidb/executor.(*WindowExec).consumeGroupRows(0xc00016b790, 0xc001fb6000, 0x3fe, 0x400, 0x201, 0xc001fb6000)\r\n        /Users/damn/go/tidb/executor/window.go:140 +0x1e3\r\ngithub.com/pingcap/tidb/executor.(*WindowExec).consumeOneGroup(0xc00016b790, 0x6c89140, 0xc0001a0008, 0x1, 0xc0010b8b60)\r\n        /Users/damn/go/tidb/executor/window.go:120 +0x4d9\r\ngithub.com/pingcap/tidb/executor.(*WindowExec).Next(0xc00016b790, 0x6c89140, 0xc0001a0008, 0xc0004219f0, 0x0, 0xc00038c060)\r\n        /Users/damn/go/tidb/executor/window.go:56 +0xa5\r\ngithub.com/pingcap/tidb/executor.benchmarkWindowExecWithCase(0xc000457d40, 0xc0007b2c00)\r\n        /Users/damn/go/tidb/executor/benchmark_test.go:640 +0x37d\r\ngithub.com/pingcap/tidb/executor.baseBenchmarkWindowFunctionsWithSlidingWindow.func1(0xc000457d40)\r\n        /Users/damn/go/tidb/executor/benchmark_test.go:793 +0x34\r\ntesting.(*B).runN(0xc000457d40, 0x1)\r\n        /usr/local/Cellar/go/1.15.5/libexec/src/testing/benchmark.go:191 +0xeb\r\ntesting.(*B).run1.func1(0xc000457d40)\r\n        /usr/local/Cellar/go/1.15.5/libexec/src/testing/benchmark.go:231 +0x57\r\ncreated by testing.(*B).run1\r\n        /usr/local/Cellar/go/1.15.5/libexec/src/testing/benchmark.go:224 +0x7f\r\nexit status 2\r\nFAIL    github.com/pingcap/tidb/executor        14.431s\r\n\r\n```",
	"issue_comments": "0"
},
{
	"login": "Tjianke",
	"repo_name": "pingcap/tidb",
	"issue_id": "789669649",
	"issue_number": "22447",
	"issue_state": "opened",
	"issue_title": "Bug in signed minus unsigned builtin function, result forced to signed",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n```\r\nset sql_mode='NO_UNSIGNED_SUBTRACTION';      \r\nselect 9223372036854775808 - cast(-1 as unsigned)\r\n```\r\n<!-- a step by step guide for reproducing the bug. -->\r\n\r\n### 2. What did you expect to see? (Required)\r\n```\r\n+--------------------------------------------+\r\n| 9223372036854775808 - cast(-1 as unsigned) |\r\n+--------------------------------------------+\r\n| -9223372036854775807                       |\r\n+--------------------------------------------+\r\n```\r\n### 3. What did you see instead (Required)\r\n```\r\n(1690, \"BIGINT UNSIGNED value is out of range in '(9223372036854775808 - 18446744073709551615)'\")\r\n```\r\n### 4. What is your TiDB version? (Required)\r\n\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n```\r\n+-------------------------------------------------------------------+\r\n| tidb_version()                                                    |\r\n+-------------------------------------------------------------------+\r\n| Release Version: v4.0.0-beta.2-2016-g3dd842f50                    |\r\n| Edition: Community                                                |\r\n| Git Commit Hash: 3dd842f50a75ebbf9a4f9d7b30fb2ce8a8dd4b37         |\r\n| Git Branch: master                                                |\r\n| UTC Build Time: 2021-01-13 14:08:28                               |\r\n| GoVersion: go1.15.5                                               |\r\n| Race Enabled: false                                               |\r\n| TiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306 |\r\n| Check Table Before Drop: false                                    |\r\n+-------------------------------------------------------------------+\r\n```\r\n",
	"issue_comments": "0"
},
{
	"login": "Tjianke",
	"repo_name": "pingcap/tidb",
	"issue_id": "785673332",
	"issue_number": "22389",
	"issue_state": "opened",
	"issue_title": "Bug in signed minus unsigned builtin function, force signed",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n```\r\nset sql_mode='NO_UNSIGNED_SUBTRACTION';  \r\ncreate table tb5(a bigint, b bigint);\r\ninsert into tb5 values (10, -9223372036854775808);\r\nselect a - b from tb5;\r\n```\r\n<!-- a step by step guide for reproducing the bug. -->\r\n\r\n### 2. What did you expect to see? (Required)\r\n```\r\n(1690, \"BIGINT value is out of range in '(`employees`.`tb5`.`a` - `employees`.`tb5`.`b`)'\")\r\n```\r\n\r\n### 3. What did you see instead (Required)\r\n```\r\n+----------------------+\r\n| a - b                |\r\n+----------------------+\r\n| -9223372036854775798 |\r\n+----------------------+\r\n```\r\n\r\n### 4. What is your TiDB version? (Required)\r\n\r\n\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n\r\n```\r\n+-------------------------------------------------------------------+\r\n| tidb_version()                                                    |\r\n+-------------------------------------------------------------------+\r\n| Release Version: v4.0.0-beta.2-2016-g3dd842f50                    |\r\n| Edition: Community                                                |\r\n| Git Commit Hash: 3dd842f50a75ebbf9a4f9d7b30fb2ce8a8dd4b37         |\r\n| Git Branch: master                                                |\r\n| UTC Build Time: 2021-01-13 14:08:28                               |\r\n| GoVersion: go1.15.5                                               |\r\n| Race Enabled: false                                               |\r\n| TiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306 |\r\n| Check Table Before Drop: false                                    |\r\n+-------------------------------------------------------------------+\r\n```",
	"issue_comments": "0"
},
{
	"login": "IanChilds",
	"repo_name": "facebook/fresco",
	"issue_id": "64798507",
	"issue_number": "13",
	"issue_state": "closed",
	"issue_title": "can't open file in assets folder",
	"issue_body": "I tried SimpleDraweeView.setImageURI and set a file:///android_asset resource.\r\n> xx.setImageURI(Uri.parse(\"file:///android_asset/....jpg\"));\r\nBut it shows an error:\r\n> can't open '/android_asset/xxx.jpg' \r\nAnd if I use:\r\n> xx.setImageDrawable(new BitmapDrawable(getAssets().open(\"xxx.jpg\")));\r\nThis is correct.\r\nI am new to android. Do I make some mistakes? If there are some problems, please let me know. :-)\r\n",
	"issue_comments": "3"
},
{
	"login": "TheSavior",
	"repo_name": "facebook/react",
	"issue_id": "119328103",
	"issue_number": "5562",
	"issue_state": "opened",
	"issue_title": "A way to error if props are passed that aren't in PropTypes",
	"issue_body": "I've found that I've been specifying a few components with props that aren't being used in those components. \r\n\r\nIt would be nice if there was a way to have a runtime check for React.PropTypes that didn't allow additional props being passed.",
	"issue_comments": "0"
},
{
	"login": "lucasponce",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "135708320",
	"issue_number": "6876",
	"issue_state": "opened",
	"issue_title": "Integrate metrics from hawkular into MiQ",
	"issue_body": "",
	"issue_comments": "0"
},
{
	"login": "selmanj",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "143371082",
	"issue_number": "7523",
	"issue_state": "opened",
	"issue_title": "GCE Cloud Provider doesn't display volumes or snapshots",
	"issue_body": "There appears to be code for parsing/handling a disk in GCE, but this information isn't being surfaced in the UI.",
	"issue_comments": "0"
},
{
	"login": "sylzd",
	"repo_name": "pingcap/tidb",
	"issue_id": "759119338",
	"issue_number": "21551",
	"issue_state": "opened",
	"issue_title": "Whitelist not working in lvs",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### 1. Minimal reproduce step (Required)\r\n\r\n<!-- a step by step guide for reproducing the bug. -->\r\n1. add: lvs_ip -> tidb_ip\r\n2. connect: mysql -h lvs_ip -uroot\r\n3. output:\r\nAccess denied for user 'lvs_test'@'some_ip'\r\n\r\n### 2. What did you expect to see? (Required)\r\nwhite list like user@[allow_ip] work.\r\n\r\n\r\n### 3. What did you see instead (Required)\r\n\r\n### 4. What is your TiDB version? (Required)\r\nv4.0.8\r\n\r\n<!-- Paste the output of SELECT tidb_version() -->\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "Gittenburg",
	"repo_name": "zulip/zulip",
	"issue_id": "635979993",
	"issue_number": "15289",
	"issue_state": "opened",
	"issue_title": "Display allowed domains on the registration page",
	"issue_body": "Restricting registration to a list of domains currently introduces a user experience problem with the registration page. The form just says \"Email\" giving no clue that only some domains are allowed and when a user attempts to sign up with a domain that isn't allowed they get the following error message:\r\n\r\n>Your email address, {email}, is not in one of the domains that are allowed to register for accounts in this organization.\r\n\r\nThis is not very helpful because it still doesn't tell you which domains are allowed.\r\n\r\nThe best solution would be to display something like `Sign up is restricted to @example.com and @example.org email addresses.` below the Email label right from the start.",
	"issue_comments": "0"
},
{
	"login": "adambirds",
	"repo_name": "zulip/zulip",
	"issue_id": "265612446",
	"issue_number": "7018",
	"issue_state": "opened",
	"issue_title": "Integrations logos not showing on /integrations/ page.",
	"issue_body": "On the /integrations/ page, not all the logos display correctly as in the below screenshot:\r\n![image](https://user-images.githubusercontent.com/13500254/31590198-2da05966-b204-11e7-8228-65ee01a77659.png)\r\nThe below shows in Chrome Dev Tools:\r\n![image](https://user-images.githubusercontent.com/13500254/31590212-56a2f12a-b204-11e7-80fb-3aa9b9a9653c.png)\r\nWe get the below errors in the nginx error.log file:\r\n```\r\n2017/10/15 22:57:44 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/airbrake.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/airbrake.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/appfollow.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/appfollow.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/asana.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/asana.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/bitbucket.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/bitbucket.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/basecamp.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/basecamp.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/capistrano.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/capistrano.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/codeship.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/codeship.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/gogs.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/gogs.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/gitlab.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/gitlab.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/crashlytics.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/crashlytics.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/freshdesk.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/freshdesk.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/git.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/git.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/delighted.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/delighted.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/github.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/github.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/email.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/email.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/circleci.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/circleci.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:44 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/codebase.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/codebase.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/greenhouse.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/greenhouse.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/google-calendar.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/google-calendar.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/gosquared.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/gosquared.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/helloworld.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/helloworld.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/hellosign.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/hellosign.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/homeassistant.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/homeassistant.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/ifttt.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/ifttt.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/heroku.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/heroku.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/jenkins.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/jenkins.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/jira.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/jira.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/librato.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/librato.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/mention.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/mention.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/mercurial.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/mercurial.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/nagios.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/nagios.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/newrelic.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/newrelic.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/openshift.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/openshift.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/pagerduty.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/pagerduty.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/papertrail.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/papertrail.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/perforce.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/perforce.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/phabricator.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/phabricator.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/pingdom.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/pingdom.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/pivotal.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/pivotal.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/puppet.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/puppet.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/redmine.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/redmine.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/rss.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/rss.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/semaphore.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/semaphore.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/sentry.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/sentry.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/slack.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/slack.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/solano.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/solano.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/splunk.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/splunk.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/subversion.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/subversion.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:45 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/taiga.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/taiga.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/teamcity.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/teamcity.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/trac.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/trac.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/transifex.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/transifex.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/travis.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/travis.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/trello.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/trello.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/updown.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/updown.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/twitter.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/twitter.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/wordpress.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/wordpress.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/yo.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/yo.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/zapier.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/zapier.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/zendesk.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/zendesk.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/assembla.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/assembla.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/bonusly.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/bonusly.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1767 open() \"/home/zulip/prod-static/images/integrations/logos/chartbeat.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/chartbeat.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1771 open() \"/home/zulip/prod-static/images/integrations/logos/google-hangouts.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/google-hangouts.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1768 open() \"/home/zulip/prod-static/images/integrations/logos/mailchimp.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/mailchimp.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1766 open() \"/home/zulip/prod-static/images/integrations/logos/google-translate.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/google-translate.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n2017/10/15 22:57:46 [error] 18785#18785: *1769 open() \"/home/zulip/prod-static/images/integrations/logos/youtube.png\" failed (2: No such file or directory), client:  1.1.1.1, server: , request: \"GET /static/images/integrations/logos/youtube.png HTTP/1.1\", host: \"chat.adbtechltd.co.uk\", referrer: \"https://chat.adbtechltd.co.uk/integrations/\"\r\n```\r\n",
	"issue_comments": "0"
},
{
	"login": "plamenko",
	"repo_name": "facebook/fresco",
	"issue_id": "65182626",
	"issue_number": "38",
	"issue_state": "closed",
	"issue_title": "I have problem with use Uri scheme for local app res",
	"issue_body": "my code:\r\n'Uri uri =  Uri.parse(\"res://\"+getResources().getResourcePackageName(R.raw.local_img));'\r\n\r\nerror:\r\n'Caused by: com.facebook.imagepipeline.request.ImageRequestBuilder$BuilderException: Invalid request builder: Resource URI path must be a resource id.\r\n            at com.facebook.imagepipeline.request.ImageRequestBuilder.validate(ImageRequestBuilder.java:217)\r\n            at com.facebook.imagepipeline.request.ImageRequestBuilder.build(ImageRequestBuilder.java:188)\r\n            at com.facebook.imagepipeline.request.ImageRequest.fromUri(ImageRequest.java:59)'\r\n",
	"issue_comments": "2"
},
{
	"login": "plamenko",
	"repo_name": "facebook/fresco",
	"issue_id": "64980397",
	"issue_number": "27",
	"issue_state": "closed",
	"issue_title": "Playing animations",
	"issue_body": "The docs say : \r\n\r\n```java\r\nUri uri;\r\nImageRequest request = ImageRequestBuilder.newBuilderWithSource(uri)\r\n    .setAutoPlayAnimation(true)\r\n    . // other setters\r\n    .build();\r\n    \r\n```\r\nBut ImageRequestBuilder class has no method named setAutoPlayAnimation()\r\n\r\n",
	"issue_comments": "1"
},
{
	"login": "plamenko",
	"repo_name": "facebook/fresco",
	"issue_id": "64898009",
	"issue_number": "18",
	"issue_state": "closed",
	"issue_title": "Using OkHttp -- Docs clarification...",
	"issue_body": "So I'm reading the docs on using OkHttp and it indicates that my gradle file should not have ```compile 'com.facebook.fresco:fresco:0.1.0+'``` if I'm trying to use Fresco with OkHttp. However, unless I add that dependency, I have no Fresco to initialize.\r\n\r\nShould I be including three dependencies as follows? If so, I think the docs could be clearer...\r\n```\r\n    compile 'com.facebook.fresco:fresco:0.1.0+'\r\n    compile \"com.facebook.fresco:drawee:0.1.0+\"\r\n    compile \"com.facebook.fresco:imagepipeline-okhttp:0.1.0+\"\r\n```\r\n\r\nhttp://frescolib.org/docs/using-other-network-layers.html#_",
	"issue_comments": "1"
},
{
	"login": "jeysal",
	"repo_name": "facebook/jest",
	"issue_id": "307243716",
	"issue_number": "5845",
	"issue_state": "opened",
	"issue_title": "deterministic output mode for snapshotting jest's output",
	"issue_body": "<!-- \r\nTHIS IS NOT A HELP FORUM. \r\nIf you are experiencing problems with setting up Jest, please make sure to visit our Help page: \r\nhttps://facebook.github.io/jest/help.html\r\n-->\r\n\r\n<!-- \r\nBefore creating an issue please check the following:\r\n* you are using the latest version of Jest\r\n* try re-installing your node_modules folder \r\n* run Jest once with `--no-cache` to see if that fixes the problem you are experiencing. \r\n-->\r\n\r\n**Do you want to request a _feature_ or report a _bug_?**\r\nfeature\r\n\r\n**What is the current behavior?**\r\nDuring a test run, Jest's output contains various volatile elements that are either platform-specific or vary based on timing, even with `--noStackTrace`.\r\nWhen capturing Jest's output in an integration test for a testing tool, parts of the output must be replaced before snapshotting, e.g.:\r\nhttps://github.com/jeysal/babel-plugin-spock/blob/3712102/test/integration/jest.test.ts#L17-L23\r\n* `./asdf` vs `.\\\\asdf` on windows\r\n* different unicode characters for ticks and `x`s\r\n* `(42ms)`\r\n* `Time: ...`\r\n\r\nJest also [does something like that](https://github.com/facebook/jest/blob/v23.0.0-alpha.0/integration-tests/Utils.js#L146-L153) in its own integration tests.\r\n\r\n**What is the expected behavior?**\r\nJest could have a CLI flag that suppresses the output of timing information and special characters and causes paths to be normalized to a consistent format.\r\nThe integration tests could then be rewritten to do without these workarounds.\r\n\r\nI might be able to invest some time and implement this soon-ish, if such a feature is wanted.\r\n@cpojer ",
	"issue_comments": "0"
},
{
	"login": "hsong-rh",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "98011914",
	"issue_number": "3650",
	"issue_state": "opened",
	"issue_title": "Fleecing on openstack instance:  Failed to create evm snapshot with EMS. Error: [Excon::Errors::Conflict]: [Expected([200, 202]) <=> Actual(409 Conflict)",
	"issue_body": "The SmartState Analysis failed on one openstack instance Joe_cfme53 because its 'Task State' was in an intermediate state 'image_snapshot' (see below) after shut down. After reset it into None, job succeeded without any errors. \r\n \r\n> nova list\r\n+--------------------------------------+----------------+---------+----------------+-------------+------------------------------------------+\r\n| ID                                   | Name           | Status  | Task State     | Power State | Networks                                 |\r\n+--------------------------------------+----------------+---------+----------------+-------------+------------------------------------------+\r\n| 19ae83f8-dc9e-44d6-b159-019637836610 | JoeV_1130549   | SHUTOFF | None           | Shutdown    | public=10.8.97.10; private=192.168.100.2 |\r\n| 7e0d9ce9-cb3c-4e61-9c70-ef6fe41f4410 | Joe_cfme53     | SHUTOFF | image_snapshot | Shutdown    | public=10.8.97.11; private=192.168.100.4 |\r\n| 5370140b-ca6e-4310-9179-725644f9e9d4 | lucy_rhos_test | SHUTOFF | None           | Shutdown    | public=10.8.97.13                        |\r\n+--------------------------------------+----------------+---------+----------------+-------------+------------------------------------------+\r\n\r\n========= evm.log ============\r\n...............\r\n[----] E, [2015-07-29T10:15:03.983524 #4942:521994] ERROR -- : Q-task_id([28d29092-35fc-11e5-9bc0-000c29b57ed5]) MIQ(VmScan#call_snapshot_create) Failed to create evm snapshot with EMS. Error: [Excon::Errors::Conflict]: [Expected([200, 202]) <=> Actual(409 Conflict)\r\nexcon.error.response\r\n  :body          => \"{\\\"conflictingRequest\\\": {\\\"message\\\": \\\"Cannot 'createImage' while instance is in task_state image_snapshot\\\", \\\"code\\\": 409}}\"\r\n  :headers       => {  \r\n    \"Content-Length\"       => \"119\" \r\n    \"Content-Type\"         => \"application/json; charset=UTF-8\"\r\n    \"Date\"                 => \"Wed, 29 Jul 2015 14:15:03 GMT\"\r\n    \"X-Compute-Request-Id\" => \"req-912d022f-0cad-4b0a-b6c2-5d70f3a73e88\"\r\n  }\r\n  :local_address => \"192.168.142.135\"\r\n  :local_port    => 50458 \r\n  :reason_phrase => \"Conflict\"\r\n  :remote_ip     => \"10.8.96.4\"\r\n  :status        => 409\r\n  :status_line   => \"HTTP/1.1 409 Conflict\\r\\n\"\r\n]\r\n[----] I, [2015-07-29T10:15:03.991680 #4942:521994]  INFO -- : Q-task_id([28d29092-35fc-11e5-9bc0-000c29b57ed5]) MIQ(MiqEvent.raise_evm_event) Event Raised [vm_scan_abort]\r\n[----] I, [2015-07-29T10:15:03.997414 #4942:521994]  INFO -- : Q-task_id([28d29092-35fc-11e5-9bc0-000c29b57ed5]) MIQ(MiqEvent.raise_evm_event) Alert for Event [vm_scan_abort]\r\n[----] I, [2015-07-29T10:15:03.997494 #4942:521994]  INFO -- : Q-task_id([28d29092-35fc-11e5-9bc0-000c29b57ed5]) MIQ(MiqAlert.evaluate_alerts) [vm_scan_abort] Target: VmOpenstack Name: [Joe_cfme53], Id: [3038]\r\n[----] E, [2015-07-29T10:15:03.997637 #4942:521994] ERROR -- : Q-task_id([28d29092-35fc-11e5-9bc0-000c29b57ed5]) MIQ(VmScan#process_abort) job aborting, Failed to create evm snapshot with EMS. Error: [Excon::Errors::Conflict]: [Expected([200, 202]) <=> Actual(409 Conflict)\r\n",
	"issue_comments": "0"
},
{
	"login": "Lyla-Fischer",
	"repo_name": "zulip/zulip",
	"issue_id": "295640825",
	"issue_number": "8313",
	"issue_state": "opened",
	"issue_title": "Remove keyboard shortcut hint from user card",
	"issue_body": "When you click on a user, and the user card pops up, you have an option to \"Send private message (R)\", even though that particular shortcut is not very useful when you are already in a mouse-using mode. We should remove the keyboard shortcut hint and add it to the actions popover menu instead (which is where it is most likely to be actually used.) https://chat.zulip.org/#narrow/stream/feedback/subject/keyboard.20shortcut.20for.20private.20messages\r\n\r\n",
	"issue_comments": "0"
},
{
	"login": "akashnimare",
	"repo_name": "zulip/zulip",
	"issue_id": "144331565",
	"issue_number": "603",
	"issue_state": "opened",
	"issue_title": "Not able to upload attachment ",
	"issue_body": "![zulip](https://cloud.githubusercontent.com/assets/2263909/14116841/666f5d72-f5ff-11e5-876a-b3156c08197a.gif)\r\n\r\nI am not able to upload any files via attachment feature. This bug can be reproduced on Ubuntu 14.04 and OSX. ",
	"issue_comments": "0"
},
{
	"login": "aryanshridhar",
	"repo_name": "zulip/zulip",
	"issue_id": "685685162",
	"issue_number": "16198",
	"issue_state": "opened",
	"issue_title": "Overlapping text while creating new Organization",
	"issue_body": "Hi all , \r\nEncountered this error of <strong>alert</strong> message and text message overlapping while creating a new organization .\r\n\r\nTo Produce this error , head over <a href = 'https://zulipchat.com/accounts/register/' target = '_blank'>here</a> ( After receiving email )\r\nFor reference , I am attaching an image for the same .\r\n\r\n![Screenshot from 2020-08-25 23-02-44](https://user-images.githubusercontent.com/53977614/91208528-f5b14e00-e727-11ea-9bc2-d92ece43ac73.png)\r\n",
	"issue_comments": "0"
},
{
	"login": "amitdo",
	"repo_name": "tesseract-ocr/tesseract",
	"issue_id": "100179278",
	"issue_number": "76",
	"issue_state": "opened",
	"issue_title": "OpenMP support",
	"issue_body": "\r\nIn ccmain/par_control.cpp you can see this code:\r\n\r\n#pragma omp parallel for num_threads(10)\r\nfor (int b = 0; b < blobs.size(); ++b) {\r\n...\r\n}\r\n\r\nconfigure.ac should have an option to activate OpenMP in tesseract code (maybe with AC_OpenMP?).",
	"issue_comments": "0"
},
{
	"login": "morgo",
	"repo_name": "pingcap/tidb",
	"issue_id": "348353630",
	"issue_number": "7307",
	"issue_state": "opened",
	"issue_title": "server crash on GROUP BY indexed enum",
	"issue_body": "Please answer these questions before submitting your issue. Thanks!\r\n\r\n1. What did you do?\r\n\r\n```\r\nDROP TABLE IF EXISTS t1;\r\n\r\nCREATE TABLE t1 (\r\n id INT NOT NULL PRIMARY KEY auto_increment,\r\n b varchar(255) NOT NULL,\r\n c ENUM('a', 'b', 'c', 'd', 'e'),\r\n INDEX (c)\r\n);\r\n\r\nINSERT INTO t1 VALUES \r\n (NULL, REPEAT('b', 255), 'a'),\r\n (NULL, REPEAT('b', 255), 'b'),\r\n (NULL, REPEAT('b', 255), 'c'),\r\n (NULL, REPEAT('b', 255), 'd'),\r\n (NULL, REPEAT('b', 255), 'e');\r\n \r\nSELECT c FROM t1 GROUP BY c;\r\n\r\n```\r\n\r\n2. What did you expect to see?\r\n\r\nNot crash.\r\n\r\n3. What did you see instead?\r\n\r\n```\r\n2018/08/07 14:43:43.857 conn.go:427: [error] lastCmd SELECT c FROM t1 GROUP BY c, runtime error: slice bounds out of range, goroutine 38207 [running]:\r\ngithub.com/pingcap/tidb/server.(*clientConn).Run.func1(0xc42087b2b0, 0xc4209f5dff)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:425 +0x10e\r\npanic(0x1155280, 0x1e09700)\r\n        /usr/local/go/src/runtime/panic.go:502 +0x229\r\ngithub.com/pingcap/tidb/server.(*clientConn).writeResultset.func1(0x0, 0x1445c00, 0xc420b0f2c0, 0xc4209f5bf8, 0xc42087b2b0)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:943 +0x325\r\npanic(0x1155280, 0x1e09700)\r\n        /usr/local/go/src/runtime/panic.go:502 +0x229\r\ngithub.com/pingcap/tidb/util/chunk.Row.getNameValue(0xc420aaeca0, 0x0, 0x0, 0x400, 0x573d1b, 0xc42096602a)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/util/chunk/row.go:106 +0x126\r\ngithub.com/pingcap/tidb/util/chunk.Row.GetEnum(0xc420aaeca0, 0x0, 0x0, 0xc4209f5978, 0x1, 0x9)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/util/chunk/row.go:112 +0x3f\r\ngithub.com/pingcap/tidb/server.dumpTextRow(0xc420625000, 0x4, 0x400, 0xc421869c80, 0x1, 0x1, 0xc420aaeca0, 0x0, 0x50, 0x121a620, ...)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/util.go:326 +0xcfe\r\ngithub.com/pingcap/tidb/server.(*clientConn).writeChunks(0xc42087b2b0, 0x7f4649c81130, 0xc420f02d00, 0x1445c00, 0xc420b0f2c0, 0xc400005b00, 0xc42087b2b0, 0x0)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:1015 +0x2c5\r\ngithub.com/pingcap/tidb/server.(*clientConn).writeResultset(0xc42087b2b0, 0x7f4649c81130, 0xc420f02d00, 0x1445c00, 0xc420b0f2c0, 0xc400007c00, 0x0, 0x0, 0x0)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:956 +0x1bc\r\ngithub.com/pingcap/tidb/server.(*clientConn).handleQuery(0xc42087b2b0, 0x7f4649c81130, 0xc420f02d00, 0xc42003c681, 0x1b, 0x0, 0x0)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:873 +0x124\r\ngithub.com/pingcap/tidb/server.(*clientConn).dispatch(0xc42087b2b0, 0xc42003c681, 0x1c, 0x1c, 0x0, 0x0)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:612 +0x4f9\r\ngithub.com/pingcap/tidb/server.(*clientConn).Run(0xc42087b2b0)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/conn.go:470 +0x1be\r\ngithub.com/pingcap/tidb/server.(*Server).onConn(0xc4207168a0, 0x14478e0, 0xc421869888)\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/server.go:324 +0x22b\r\ncreated by github.com/pingcap/tidb/server.(*Server).Run\r\n        /home/jenkins/workspace/build_tidb_master/go/src/github.com/pingcap/tidb/server/server.go:264 +0x4dc\r\n\r\n```\r\n\r\n4. What version of TiDB are you using (`tidb-server -V` or run `select tidb_version();` on TiDB)?\r\n\r\n```\r\nMySQL [(none)]> select tidb_version()\\G\r\n*************************** 1. row ***************************\r\ntidb_version(): Release Version: v2.1.0-beta-156-g5e7aa1d\r\nGit Commit Hash: 5e7aa1d97d6459843949ae3587c9b5ac6661bb37\r\nGit Branch: master\r\nUTC Build Time: 2018-08-01 02:49:37\r\nGoVersion: go version go1.10.2 linux/amd64\r\nRace Enabled: false\r\nTiKV Min Version: 2.1.0-alpha.1-ff3dd160846b7d1aed9079c389fc188f7f5ea13e\r\n1 row in set (0.00 sec)\r\n\r\n```",
	"issue_comments": "0"
},
{
	"login": "Shreeshrii",
	"repo_name": "tesseract-ocr/tesseract",
	"issue_id": "140915244",
	"issue_number": "271",
	"issue_state": "opened",
	"issue_title": "tessdata location",
	"issue_body": "I git cloned the tesseract-ocr repositories on ubuntu 14.04 with the following structure\r\n\r\ntesseract-ocr\r\ntesseract-ocr/tesseract\r\ntesseract-ocr/tessdata\r\ntesseract-ocr/langdata\r\n\r\nThe build process (autogen, make, sudo make install, sudo ldconfig)  put the tessdata files with configs and tessconfigs subdirectories and pdf.ttf in  /usr/local/share/tessdata\r\n\r\nThis puts tessdata related files in two locations:\r\ntesseract-ocr/tessdata\r\nand\r\n/usr/local/share/tessdata\r\n(in addition to the source in tesseract-ocr/tesseract/tessdata)\r\n\r\nAs a regular user I cannot copy the tesddata files to  /usr/local/share/tessdata\r\n\r\n$ cp ./tessdata/san.traineddata /usr/local/share/tessdata\r\ncp: cannot create regular file \u2018/usr/local/share/tessdata/san.traineddata\u2019: Permission denied\r\n\r\n____________________________________\r\n\r\n$ export TESSDATA_PREFIX=/home/shree/tesseract-ocr\r\n$ echo $TESSDATA_PREFIX\r\n/home/shree/tesseract-ocr\r\n\r\nIf I use the above tessdata prefix, then tesseract does not find the config files ..\r\n\r\n$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3\r\nTesseract Open Source OCR Engine v3.05.00dev with Leptonica\r\n$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3 pdf\r\nread_params_file: Can't open pdf\r\nTesseract Open Source OCR Engine v3.05.00dev with Leptonica\r\n$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3 tsv\r\nread_params_file: Can't open tsv\r\n\r\n_____________________________________________\r\n\r\n$ export TESSDATA_PREFIX=/usr/local/share/tessdata\r\n$ echo $TESSDATA_PREFIX\r\n/usr/local/share/tessdata\r\n\r\nIf I use the above then tesseract does not find the traineddata files even when tessdata-dir is pointing to the correct location\r\n\r\n$  tesseract --tessdata-dir=../  testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3\r\nError opening data file /usr/local/share/tessdata/eng.traineddata\r\nPlease make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your \"tessdata\" directory.\r\nFailed loading language 'eng'\r\nTesseract couldn't load any languages!\r\nCould not initialize tesseract.\r\n\r\n$ tesseract --tessdata-dir=/home/shree/tesseract-ocr  testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3\r\nError opening data file /usr/local/share/tessdata/eng.traineddata\r\nPlease make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your \"tessdata\" directory.\r\nFailed loading language 'eng'\r\nTesseract couldn't load any languages!\r\nCould not initialize tesseract.\r\n\r\n_______________________________\r\nI can get around it by copying configs, tessconfigs and pdf.ttf to\r\n/home/shree/tesseract-ocr/tessdata directory.\r\n\r\nBut this should not be required. What am I missing in the process?",
	"issue_comments": "0"
},
{
	"login": "Shreeshrii",
	"repo_name": "tesseract-ocr/tesseract",
	"issue_id": "138783822",
	"issue_number": "252",
	"issue_state": "opened",
	"issue_title": "pdf.ttx is missing ",
	"issue_body": "from\r\nhttps://github.com/tesseract-ocr/tesseract/tree/master/tessdata",
	"issue_comments": "0"
},
{
	"login": "MatrixManAtYrService",
	"repo_name": "apache/airflow",
	"issue_id": "894929011",
	"issue_number": "15931",
	"issue_state": "closed",
	"issue_title": "`$ airflow connections import` fails with `AttributeError`",
	"issue_body": "Apache Airflow version\r\n\r\n6f8c204\r\n\r\nEnvironment\r\n\r\nOS (e.g. from /etc/os-release): Mac OS 11.3\r\nKernel: Darwin Kernel Version 20.4.0\r\nInstall tools: pip install -e .\r\n\r\n\r\n**What happened**:\r\n\r\nTried to import valid connection json via the cli.  Got an error:\r\n\r\n```\r\n\u276f echo '{\"sqlite_conn_id\": {\r\n    \"conn_type\": \"sqlite\",\r\n    \"description\": \"\",\r\n    \"host\": \"localhost\",\r\n    \"login\": \"\",\r\n    \"password\": null,\r\n    \"schema\": \"/usr/local/airflow/test.db\",\r\n    \"port\": null,\r\n    \"extra\": \"\"\r\n  }}' | jq . > connections.json\r\n\r\n\u276f airflow connections import connections.json\r\nTraceback (most recent call last):\r\n  File \"/Users/matt/src/airflow/venv/bin/airflow\", line 33, in <module>\r\n    sys.exit(load_entry_point('apache-airflow', 'console_scripts', 'airflow')())\r\n  File \"/Users/matt/src/airflow/airflow/__main__.py\", line 40, in main\r\n    args.func(args)\r\n  File \"/Users/matt/src/airflow/airflow/cli/cli_parser.py\", line 48, in command\r\n    return func(*args, **kwargs)\r\n  File \"/Users/matt/src/airflow/airflow/utils/cli.py\", line 91, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"/Users/matt/src/airflow/airflow/cli/commands/connection_command.py\", line 244, in connections_import\r\n    _import_helper(args.file)\r\n  File \"/Users/matt/src/airflow/airflow/cli/commands/connection_command.py\", line 272, in _import_helper\r\n    key: value for key, value in conn_values.items() if key in allowed_fields\r\nAttributeError: 'Connection' object has no attribute 'items'\r\n```\r\n\r\nSeveral of the tests assume that `load_connections_dict` returns a dict of dicts\r\nhttps://github.com/apache/airflow/blob/6f8c204b21d6c01a192bda524db72517d41bf6e9/tests/cli/commands/test_connection_command.py#L790\r\n\r\nActually, `load_connections_dict` returns a dict of `Connection`s\r\nhttps://github.com/apache/airflow/blob/6f8c204b21d6c01a192bda524db72517d41bf6e9/airflow/secrets/local_filesystem.py#L278\r\n\r\nWhen we call `.items()` on the `Connection`, it fails.\r\n\r\n**What you expected to happen**:\r\n\r\nThe import is sucessful.\r\n\r\n**How to reproduce it**:\r\n\r\nSee commands above.\r\n\r\n**Anything else we need to know**:\r\n\r\nThis commit fixes it (I think): https://github.com/MatrixManAtYrService/airflow/commit/51590596f96f079f166d6949a520c1b0a53f475a\r\n\r\nI started making a PR, but while trying to make the tests pass I started to worry that I was on the wrong path, so I made an issue instead.",
	"issue_comments": "3"
},
{
	"login": "qw4990",
	"repo_name": "pingcap/tidb",
	"issue_id": "393800494",
	"issue_number": "8779",
	"issue_state": "opened",
	"issue_title": "some errors which should be checked are ignored",
	"issue_body": "## Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n1. What did you do?\r\nIf possible, provide a recipe for reproducing the error.\r\n\r\nSome errors which should be checked are ignored, which may leads some bugs;\r\n\r\nThese errors are in this [report](https://goreportcard.com/report/github.com/pingcap/tidb#ineffassign) (search key word \"assignment to err\" in this page);\r\n\r\n2. What did you expect to see?\r\n\r\nThese errors should be checked;\r\n\r\n\r\n3. What did you see instead?\r\n\r\nThese errors are ignored;\r\n\r\n\r\n4. What version of TiDB are you using (`tidb-server -V` or run `select tidb_version();` on TiDB)?\r\n\r\nRelease Version: v2.1.0-rc.3-354-g062267674\r\nGit Commit Hash: 06226767499f33a34b5cdce08ef7749dc2426c62\r\nGit Branch: ignored_err\r\nUTC Build Time: 2018-12-24 02:36:24\r\nGoVersion: go version go1.11.3 darwin/amd64\r\nRace Enabled: false\r\nTiKV Min Version: 2.1.0-alpha.1-ff3dd160846b7d1aed9079c389fc188f7f5ea13e\r\nCheck Table Before Drop: false\r\n",
	"issue_comments": "0"
},
{
	"login": "chalettu",
	"repo_name": "ManageIQ/manageiq",
	"issue_id": "205926972",
	"issue_number": "13790",
	"issue_state": "opened",
	"issue_title": "Set services retired column to false by default",
	"issue_body": "This request is to ensure that we set the retired DB column to false by default for services.  We will need the data migration + default_value_for in the Services model",
	"issue_comments": "0"
},
{
	"login": "timuthy",
	"repo_name": "gardener/gardener",
	"issue_id": "348998606",
	"issue_number": "310",
	"issue_state": "opened",
	"issue_title": "Nginx Ingress Configuration Returns HTTP-400 on AWS",
	"issue_body": "We've been observing an issue with the Nginx Ingress Controller in Shoot clusters **on AWS**:\r\n\r\n**Failure description:**\r\nWhenever a Ingress resource with a corresponding URL is created, a request against it ends up with a HTTP 400 error message.\r\nIn addition, a request to a non existing Ingress URL or to the AWS load balancer directly also returns HTTP 400 instead of being redirected to the default backend.\r\n\r\n**Expected behavior:**\r\nThe request is forwarded to the configured Service or the default backend respectively.\r\n\r\n**Steps to reproduce:**\r\n\r\n1. Create a Shoot cluster on AWS / take an existing one\r\n2. Apply Yaml file (please adjust Host information)\r\n\r\n```\r\napiVersion: extensions/v1beta1\r\nkind: Ingress\r\nmetadata:\r\n  name: test-ingress\r\n  namespace: default\r\n  annotations:\r\n    nginx.ingress.kubernetes.io/rewrite-target: /\r\nspec:\r\n  rules:\r\n  - host: <Your Host>\r\n    http:\r\n      paths:\r\n      - backend:\r\n          serviceName: nginx-service\r\n          servicePort: 80\r\n---\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: nginx-deployment\r\n  namespace: default\r\n  labels:\r\n    app: nginx\r\nspec:\r\n  replicas: 1\r\n  selector:\r\n    matchLabels:\r\n      app: nginx\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: nginx\r\n    spec:\r\n      containers:\r\n      - name: nginx\r\n        image: nginx:1.15.1\r\n        ports:\r\n        - containerPort: 80\r\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  name: nginx-service\r\n  namespace: default\r\nspec:\r\n  type: NodePort\r\n  ports:\r\n  - port: 80\r\n    protocol: TCP\r\n  selector:\r\n    app: nginx\r\n---\r\n```",
	"issue_comments": "0"
}]